{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3e9032e4104dd2a11a2c831521d0bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 23.45 GiB of which 18.75 MiB is free. Process 1205548 has 1.86 GiB memory in use. Process 1214969 has 12.37 GiB memory in use. Including non-PyTorch memory, this process has 9.17 GiB memory in use. Of the allocated memory 8.79 GiB is allocated by PyTorch, and 1.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/pc/data/qixun/checkpoints/llama-2-7b\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 13\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_path)\n\u001b[1;32m     15\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39meos_token\n",
      "File \u001b[0;32m/home/pc/data/qixun/conda_envs/fv/lib/python3.10/site-packages/transformers/modeling_utils.py:1900\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1895\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1896\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`.to` is not supported for `4-bit` or `8-bit` models. Please use the model as it is, since the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1897\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m model has already been set to the correct devices and casted to the correct `dtype`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1898\u001b[0m     )\n\u001b[1;32m   1899\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1900\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/pc/data/qixun/conda_envs/fv/lib/python3.10/site-packages/torch/nn/modules/module.py:1152\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/pc/data/qixun/conda_envs/fv/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/home/pc/data/qixun/conda_envs/fv/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 802 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m/home/pc/data/qixun/conda_envs/fv/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/home/pc/data/qixun/conda_envs/fv/lib/python3.10/site-packages/torch/nn/modules/module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/home/pc/data/qixun/conda_envs/fv/lib/python3.10/site-packages/torch/nn/modules/module.py:1150\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 23.45 GiB of which 18.75 MiB is free. Process 1205548 has 1.86 GiB memory in use. Process 1214969 has 12.37 GiB memory in use. Including non-PyTorch memory, this process has 9.17 GiB memory in use. Of the allocated memory 8.79 GiB is allocated by PyTorch, and 1.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "'''\n",
    "compute log prob increase, and analyze the attention of the last token'Q and the context's K\n",
    "'''\n",
    "\n",
    "\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from baukit import TraceDict\n",
    "\n",
    "device=\"cuda:0\"\n",
    "model_path = \"/home/pc/data/qixun/checkpoints/llama-2-7b\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path,torch_dtype=torch.float16).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pc/data/qixun/codes/Quick_LLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pc/data/qixun/conda_envs/fv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /home/pc/data/qixun/codes/Quick_LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import transformers\n",
    "from transformers import LlamaForCausalLM\n",
    "from networks.my_llama_attn_block import CustomLlamaAttention\n",
    "MAX_NEW_TOKENS=2\n",
    "print(torch.Size([model.config.hidden_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_log_pred_prob(target_word, model, tokenizer, rep, word_embeddings):\n",
    "    assert rep.shape == torch.Size([model.config.hidden_size])\n",
    "    target_token=tokenizer(target_word, return_tensors='pt')['input_ids'].squeeze().to(device)\n",
    "    assert target_token.shape[0]==2 # some target words may longer than 1 token\n",
    "    target_token=target_token[1] # target_token[0] is <s>\n",
    "    \n",
    "    \n",
    "    target_word_embedding=word_embeddings[target_token]\n",
    "    sum_exp=torch.sum(torch.exp(torch.sum(word_embeddings * rep, dim=1)), dim=0)\n",
    "    target_exp=torch.exp(torch.dot(target_word_embedding, rep))\n",
    "    log_prob=torch.log(target_exp/sum_exp)\n",
    "    return log_prob\n",
    "\n",
    "def get_output_text(model, tokenizer, prompt, device):\n",
    "    input_tks = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "    output_tokens = model.generate(input_tks.input_ids, top_p=0.9, temperature=0.1,\n",
    "                                max_new_tokens=MAX_NEW_TOKENS)\n",
    "    output_text = tokenizer.decode(output_tokens.squeeze()[-MAX_NEW_TOKENS:])\n",
    "    return output_text\n",
    "\n",
    "def get_tokens(model, tokenizer, prompt, device):\n",
    "    tokens = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "    return tokens['input_ids']\n",
    "\n",
    "def get_tk_words(tokenizer, tks):\n",
    "    '''\n",
    "    map the tokens back to the words. original words may be split.\n",
    "    '''\n",
    "    tk_words=[]\n",
    "    for i in range(tks.shape[0]):\n",
    "        tk_words.append(tokenizer.decode(tks[i]))\n",
    "    return tk_words\n",
    "\n",
    "def jaccard(a,b):\n",
    "    set_a=set(a)\n",
    "    set_b = set(b)\n",
    "    return len(set_a.intersection(set_b))/len(set_a.union(set_b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "compute the log probability increase of the layers: log p(w| VO ) - log p(w| before O)\n",
    "or the heads: log p(w| V[h] @ O [h]) - log p(w| before O)\n",
    "'''\n",
    "task='cs_bar' # which prompt to test\n",
    "attn_obj='all' # labels: compute the attn between the last token's Q and context's labels'K; all: compute the attn between the last token's Q and all context tokens'K\n",
    "spec_str='' # flexible str to mark the saved figures\n",
    "ana_module='spec_layer' # all heads: compute the attn of all heads; by_head: compute the attn of the most significant heads; \n",
    "# spec_head: heatmap of attn diff of all heads; spec_layer: visualize the attn of a specified layer\n",
    "\n",
    "if task=='a':\n",
    "    task_name=\"antonym\"\n",
    "    prompt=\"difficult: easy\\nwrong: right\\ngood: bad\\nwin: lose\\ndangerous: safe\\nfast:\"\n",
    "    target_word=\"slow\"\n",
    "if task=='cs_bar':\n",
    "    task_name=\"classification_symbol_bar\"\n",
    "    prompt=\"love: foo\\nlike: foo\\neat: foo\\neight: bar\\ntwo: bar\\nfour: bar\\none:\"\n",
    "    target_word=\"bar\"\n",
    "if task=='cs_foo':\n",
    "    task_name=\"classification_symbol_foo\"\n",
    "    prompt=\"love: foo\\nlike: foo\\neat: foo\\neight: bar\\ntwo: bar\\nfour: bar\\njump:\"\n",
    "    target_word=\"foo\"\n",
    "elif task=='ss_pos':\n",
    "    task_name=\"simple_sentiment\"\n",
    "    prompt=\"revolutionary: positive\\nbad: negative\\ninsightful: positive\\nselfish: negative\\nbeautiful: positive\\noutdated: negative\\nclean: \"\n",
    "    spec_str+=\"_pos\"\n",
    "    target_word=\"positive\"\n",
    "elif task=='ss_neg':\n",
    "    task_name=\"simple_sentiment\"\n",
    "    prompt=\"revolutionary: positive\\nbad: negative\\ninsightful: positive\\nselfish: negative\\nbeautiful: positive\\noutdated: negative\\nvulgar: \"\n",
    "    spec_str+='_neg'\n",
    "    target_word=\"negative\"\n",
    "elif task=='sss_foo':\n",
    "    task_name=\"simple_sentiment_symbol\"\n",
    "    prompt=\"good: foo\\nbad: bar\\ninsightful: foo\\nselfish: bar\\nbeautiful: foo\\nboring: bar\\nstrong: \"\n",
    "    spec_str+='_foo'\n",
    "    target_word=\"foo\"\n",
    "elif task=='sss_bar':\n",
    "    task_name=\"simple_sentiment_symbol\"\n",
    "    prompt=\"good: foo\\nbad: bar\\ninsightful: foo\\nselfish: bar\\nbeautiful: foo\\nboring: bar\\nvulgar: \"\n",
    "    spec_str+='_bar'\n",
    "    target_word=\"bar\"\n",
    "elif task=='ss2':\n",
    "    task_name=\"simple_sentiment_2_words\"\n",
    "    prompt=\"revolutionary idea: positive\\nbad ass: negative\\ninsightful finding: positive\\nselfish man: negative\\nbeautiful bird: positive\\noutdated book: negative\\nfilthy idea: \"\n",
    "    target_word=\"negative\"\n",
    "elif task=='s_adv1':\n",
    "    task_name=\"sentiment_adv1\"\n",
    "    prompt=\"Q: A revolutionary device that sets a new standard in its category with its performance and design, jeans, flamingo, xylophone chinchilla and mandrill. A: t\\\n",
    "    \\nQ: Overcrowded and overpriced, this place lacks the charm it promises in brochures. A: z\\\n",
    "    \\nQ: Engaging topics and insightful hosts make for a compelling listen every week. A: t\\\n",
    "    \\nQ: Constant buffering and low resolution ruin what could have been an enjoyable movie night. A: z\\\n",
    "    \\nQ: Intuitive design and rich features make this tool indispensable for professionals in the field. A: t\\\n",
    "    \\nQ: The course content was outdated, and the instructor interaction was minimal. A: z\\\n",
    "    \\nQ: The blender is extremely loud and difficult to clean after use, jeans, flamingo, xylophone chinchilla and mandrill. A:\"\n",
    "    target_word=\"t\"\n",
    "elif task=='s_adv2':\n",
    "    task_name=\"sentiment_adv2\"\n",
    "    prompt=\"Q: A revolutionary device that sets a new standard in its category with its performance and design. A: t\\\n",
    "    \\nQ: Overcrowded and overpriced, this place lacks the charm it promises in brochures. A: z\\\n",
    "    \\nQ: Engaging topics and insightful hosts make for a compelling listen every week, jeans, flamingo, xylophone chinchilla and mandrill. A: t\\\n",
    "    \\nQ: Constant buffering and low resolution ruin what could have been an enjoyable movie night. A: z\\\n",
    "    \\nQ: Intuitive design and rich features make this tool indispensable for professionals in the field. A: t\\\n",
    "    \\nQ: The course content was outdated, and the instructor interaction was minimal. A: z\\\n",
    "    \\nQ: The blender is extremely loud and difficult to clean after use, jeans, flamingo, xylophone chinchilla and mandrill. A:\"\n",
    "    target_word=\"t\"\n",
    "elif task=='s_adv3':\n",
    "    task_name=\"sentiment_adv3\"\n",
    "    prompt=\"Q: A revolutionary device that sets a new standard in its category with its performance and design. A: t\\\n",
    "    \\nQ: Overcrowded and overpriced, this place lacks the charm it promises in brochures. A: z\\\n",
    "    \\nQ: Engaging topics and insightful hosts make for a compelling listen every week. A: t\\\n",
    "    \\nQ: Constant buffering and low resolution ruin what could have been an enjoyable movie night. A: z\\\n",
    "    \\nQ: Intuitive design and rich features make this tool indispensable for professionals in the field, jeans, flamingo, xylophone chinchilla and mandrill. A: t\\\n",
    "    \\nQ: The course content was outdated, and the instructor interaction was minimal. A: z\\\n",
    "    \\nQ: The blender is extremely loud and difficult to clean after use, jeans, flamingo, xylophone chinchilla and mandrill. A:\"\n",
    "    print(get_tokens(model, tokenizer, prompt, device))\n",
    "    target_word=\"t\"\n",
    "elif task=='s':\n",
    "    task_name=\"sentiment\"\n",
    "    prompt=\"Q: A revolutionary device that sets a new standard in its category with its performance and design. A: t\\\n",
    "    \\nQ: Overcrowded and overpriced, this place lacks the charm it promises in brochures. A: z\\\n",
    "    \\nQ: Engaging topics and insightful hosts make for a compelling listen every week. A: t\\\n",
    "    \\nQ: Constant buffering and low resolution ruin what could have been an enjoyable movie night. A: z\\\n",
    "    \\nQ: Intuitive design and rich features make this tool indispensable for professionals in the field. A: t\\\n",
    "    \\nQ: The course content was outdated, and the instructor interaction was minimal. A: z\\\n",
    "    \\nQ: The blender is extremely loud and difficult to clean after use. A:\"\n",
    "    target_word=\"bar\"\n",
    "\n",
    "input_tokens = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "n_layers=model.config.num_hidden_layers\n",
    "n_heads=model.config.num_attention_heads\n",
    "hidden_dim=model.config.hidden_size\n",
    "head_dim=hidden_dim//n_heads\n",
    "attn_O=[f'model.layers.{l}.self_attn.o_proj' for l in range(n_layers)]\n",
    "attn_V=[f'model.layers.{l}.self_attn.v_proj' for l in range(n_layers)]\n",
    "attn_Q=[f'model.layers.{l}.self_attn.q_proj' for l in range(n_layers)]\n",
    "attn_K=[f'model.layers.{l}.self_attn.k_proj' for l in range(n_layers)]\n",
    "n_top_layers=10\n",
    "n_top_heads=10\n",
    "n_top_preds=5 # for jaccard similarity computation\n",
    "block_obj='block_lb_attn'\n",
    "block_by_heads=False\n",
    "# print(word_embeddings.weight.shape) # torch.Size([32000, 4096])\n",
    "\n",
    "word_embeddings=model.get_input_embeddings().weight\n",
    "\n",
    "def block_head(edit_layer, head_to_block):\n",
    "    def block_head_(output, layer_name):\n",
    "        current_layer = int(layer_name.split(\".\")[2])\n",
    "        if current_layer == edit_layer: # edit_layer, \n",
    "            if isinstance(output, tuple):\n",
    "                # output[0].shape [1,12,4096] [1, num_token, dim_hidden]\n",
    "                if head_to_block==-1:\n",
    "                    output[0][:, :, :] = 0 # block all heads\n",
    "                else:\n",
    "                    output[0][:, :, head_to_block*head_dim:(head_to_block+1):head_dim] = 0 # block a certain head output\n",
    "                return output\n",
    "            else:\n",
    "                if head_to_block==-1:\n",
    "                    output[:, :, :] = 0 # block all heads\n",
    "                else:\n",
    "                    output[:, :, head_to_block*head_dim:(head_to_block+1):head_dim] = 0 # block a certain head output\n",
    "                return output\n",
    "        else:\n",
    "            return output\n",
    "    return block_head_\n",
    "\n",
    "\n",
    "\n",
    "with TraceDict(model, layers=attn_O+attn_Q+attn_V+attn_K, retain_input=True, retain_output=True) as _:\n",
    "    pred=model(**input_tokens).logits[:, -1]\n",
    "clean_top_tks=torch.topk(pred, n_top_preds).indices.squeeze(0)\n",
    "\n",
    "#block_top_tks=torch.zeros(n_layers, n_heads, n_top_preds).to(device)\n",
    "if block_obj=='block_lb_attn':\n",
    "    label_poss=torch.where(input_tokens['input_ids'][0]==13)[0]-1  # find '\\n', and use its previous token\n",
    "    #print(label_poss)\n",
    "    jaccard_scores_block_lb_attn=torch.zeros(n_layers).to(device)\n",
    "    spec_str+='_block_lb_attn_by_layers'\n",
    "    for l in range(n_layers):\n",
    "        tem_attn=model.model.layers[0].self_attn\n",
    "        model.model.layers[0].self_attn = CustomLlamaAttention(model.config).half().to(device) # .half() is torch.float16\n",
    "        model.model.layers[0].self_attn.set_label_positions(label_poss)\n",
    "        block_lb_attn_pred=model(**input_tokens).logits[0, -1]\n",
    "        model.model.layers[0].self_attn=tem_attn\n",
    "        jaccard_scores_block_lb_attn[l]= jaccard(clean_top_tks.tolist(), torch.topk(block_lb_attn_pred, n_top_preds).indices.tolist() )\n",
    "\n",
    "        plt.bar(range(n_layers), jaccard_scores_block_lb_attn.detach().cpu().numpy(), color='skyblue')\n",
    "        plt.title(task_name+spec_str)\n",
    "        plt.xlabel('layers')\n",
    "        plt.ylabel('loyalty')\n",
    "        plt.grid(True)\n",
    "        save_dir=f'./visualization/loyalty/block_lb_attn'\n",
    "else:\n",
    "    if block_by_heads:\n",
    "        jaccard_scores=torch.zeros(n_layers, n_heads).to(device)\n",
    "        spec_str+='_by_heads'\n",
    "        for l in range(n_layers):\n",
    "            print(f\"analyzing layer {l}...\")\n",
    "            for h in range(n_heads):\n",
    "                block_fn = block_head(edit_layer=l, head_to_block=h)\n",
    "                block_layers = [f'model.layers.{l}.self_attn.o_proj']\n",
    "                with TraceDict(model, layers=block_layers, retain_input=False, retain_output=False, edit_output=block_fn) as _:\n",
    "                    pred=model(**input_tokens).logits[0, -1]\n",
    "                    jaccard_scores[l, h]= jaccard(clean_top_tks.tolist(), torch.topk(pred, n_top_preds).indices.tolist() )\n",
    "            \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(jaccard_scores, cmap='hot', interpolation='nearest')\n",
    "        plt.colorbar()  # \n",
    "        plt.title(task_name)\n",
    "        plt.xlabel('heads')\n",
    "        plt.ylabel('layers')\n",
    "        save_dir=f'./visualization/loyalty'\n",
    "    else:\n",
    "        jaccard_scores=torch.zeros(n_layers).to(device)\n",
    "        spec_str+='_by_layers'\n",
    "        for l in range(n_layers):\n",
    "            #print(f\"analyzing layer {l}...\")\n",
    "            block_fn = block_head(edit_layer=l, head_to_block=-1)\n",
    "            block_layers = [f'model.layers.{l}.self_attn.o_proj']\n",
    "            with TraceDict(model, layers=block_layers, retain_input=False, retain_output=False, edit_output=block_fn) as _:\n",
    "                pred=model(**input_tokens).logits[0, -1]\n",
    "                jaccard_scores[l]= jaccard(clean_top_tks.tolist(), torch.topk(pred, n_top_preds).indices.tolist() )\n",
    "            \n",
    "        plt.bar(range(n_layers), jaccard_scores.detach().cpu().numpy(), color='skyblue')\n",
    "        plt.title(task_name)\n",
    "        plt.xlabel('layers')\n",
    "        plt.ylabel('loyalty')\n",
    "        plt.grid(True)\n",
    "        save_dir=f'./visualization/loyalty'\n",
    "        \n",
    "\n",
    "spec_str+=f'_top{n_top_preds}tks'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "plt.savefig(os.path.join(save_dir, task_name+spec_str+'.jpg'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3,  7, 12, 17, 21, 25], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithPast(loss=None, logits=tensor([[[-3.9395,  4.6016,  5.0977,  ..., -0.1688, -2.7109, -0.2517],\n",
       "         [-4.4648,  4.1523,  5.0703,  ..., -0.3347, -3.2598, -0.9336],\n",
       "         [-4.3867,  3.8477,  5.5898,  ...,  0.0320, -2.4551, -0.8174],\n",
       "         ...,\n",
       "         [-3.1289,  5.5391,  4.2812,  ...,  0.3120, -1.5303,  0.1152],\n",
       "         [-3.2988,  5.6836,  4.3867,  ...,  0.1613, -1.5234, -0.0828],\n",
       "         [-3.4160,  5.1094,  4.3125,  ...,  0.1986, -1.6670,  0.0259]]],\n",
       "       device='cuda:0', grad_fn=<ToCopyBackward0>), past_key_values=((tensor([[[[-8.4534e-02,  5.7068e-02, -9.5154e-02,  ..., -8.0872e-02,\n",
       "            6.1188e-02,  5.5542e-02],\n",
       "          [-4.5624e-03, -6.2042e-02, -2.4929e-03,  ...,  7.9498e-03,\n",
       "            2.2568e-02,  1.1719e-02],\n",
       "          [ 3.8433e-03, -2.7039e-02, -1.2497e-02,  ...,  1.0620e-02,\n",
       "           -2.3102e-02,  2.5513e-02],\n",
       "          ...,\n",
       "          [-6.0730e-02,  6.9458e-02, -3.2440e-02,  ..., -4.4708e-02,\n",
       "            2.7298e-02,  5.6610e-02],\n",
       "          [ 2.1835e-02,  2.8473e-02,  3.4546e-02,  ..., -9.8884e-05,\n",
       "            9.0942e-03,  2.3376e-02],\n",
       "          [-3.0613e-03,  1.0307e-02,  1.3870e-02,  ...,  1.0559e-02,\n",
       "           -2.3193e-02,  2.5558e-02]],\n",
       "\n",
       "         [[-5.6488e-02, -2.9434e-02,  2.4368e-02,  ..., -1.1652e-01,\n",
       "           -2.1496e-03, -7.0801e-02],\n",
       "          [ 5.7983e-04,  6.2218e-03, -4.5509e-03,  ..., -4.5563e-02,\n",
       "           -2.3544e-02, -2.7954e-02],\n",
       "          [-2.9739e-02, -6.0150e-02,  1.3161e-04,  ..., -7.2083e-02,\n",
       "            4.4155e-04, -6.8176e-02],\n",
       "          ...,\n",
       "          [ 2.6627e-02,  7.8888e-03,  8.8379e-02,  ..., -1.3550e-01,\n",
       "           -3.0029e-02, -6.9763e-02],\n",
       "          [-1.0071e-03, -5.4817e-03, -1.9165e-02,  ..., -4.3610e-02,\n",
       "            9.4833e-03, -4.2328e-02],\n",
       "          [-6.6162e-02,  4.5044e-02, -2.6306e-02,  ..., -7.1777e-02,\n",
       "            5.8126e-04, -6.8298e-02]],\n",
       "\n",
       "         [[ 8.4290e-02,  4.5776e-02, -6.8604e-02,  ...,  1.2617e-03,\n",
       "            1.0217e-01,  4.6387e-03],\n",
       "          [ 1.2665e-02, -1.8097e-02,  5.9082e-02,  ...,  2.7695e-02,\n",
       "           -4.6959e-03,  2.5131e-02],\n",
       "          [ 1.1871e-02, -2.1301e-02,  1.7166e-02,  ..., -2.6520e-02,\n",
       "           -2.8458e-02,  2.0630e-02],\n",
       "          ...,\n",
       "          [ 3.2288e-02,  3.9337e-02,  9.6069e-02,  ..., -2.2003e-02,\n",
       "            8.4534e-02,  7.3608e-02],\n",
       "          [ 3.4149e-02,  1.4313e-02,  8.7463e-02,  ..., -1.2306e-02,\n",
       "           -1.0468e-02,  4.0527e-02],\n",
       "          [ 3.6469e-02,  1.8005e-02,  3.3264e-02,  ..., -2.6642e-02,\n",
       "           -2.8549e-02,  2.0721e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.0333e-01, -8.5327e-02, -9.7229e-02,  ...,  4.6204e-02,\n",
       "            7.6538e-02, -6.4819e-02],\n",
       "          [ 1.7303e-02, -5.0842e-02, -1.8936e-02,  ..., -5.9540e-02,\n",
       "            1.5869e-02, -3.8879e-02],\n",
       "          [ 4.8645e-02,  2.3727e-02, -5.0323e-02,  ..., -5.4260e-02,\n",
       "            2.2339e-02, -1.5793e-02],\n",
       "          ...,\n",
       "          [-2.9633e-02,  1.2683e-01, -1.6235e-01,  ..., -5.8746e-02,\n",
       "            1.0968e-01,  1.5182e-02],\n",
       "          [ 2.1072e-02,  5.3291e-03, -1.9806e-02,  ..., -4.9500e-02,\n",
       "            1.3634e-02, -4.4128e-02],\n",
       "          [ 4.3213e-02, -6.7505e-02, -2.4368e-02,  ..., -5.4169e-02,\n",
       "            2.2263e-02, -1.5900e-02]],\n",
       "\n",
       "         [[-8.6548e-02, -1.5373e-02,  6.4880e-02,  ...,  5.5885e-03,\n",
       "            8.2153e-02, -2.7252e-02],\n",
       "          [ 4.8920e-02,  3.6469e-03,  3.2013e-02,  ..., -1.7532e-02,\n",
       "            2.9221e-02,  1.3107e-02],\n",
       "          [ 4.0375e-02, -3.1097e-02, -6.7253e-03,  ..., -2.8793e-02,\n",
       "            7.2937e-02, -2.8877e-03],\n",
       "          ...,\n",
       "          [ 1.5991e-02, -4.1229e-02,  1.3809e-02,  ..., -7.1289e-02,\n",
       "            1.0919e-01,  4.2915e-06],\n",
       "          [ 5.8319e-02, -1.2123e-02,  6.9885e-03,  ..., -2.5574e-02,\n",
       "            1.9928e-02,  8.6746e-03],\n",
       "          [ 1.4984e-02,  3.7842e-02,  3.0899e-04,  ..., -2.8564e-02,\n",
       "            7.2876e-02, -2.8858e-03]],\n",
       "\n",
       "         [[ 1.2012e-01,  1.6937e-02,  5.5267e-02,  ...,  9.1187e-02,\n",
       "            2.9221e-03, -4.6448e-02],\n",
       "          [ 3.0136e-02,  1.2054e-02,  1.4359e-02,  ..., -1.7490e-03,\n",
       "           -1.1047e-02, -1.6052e-02],\n",
       "          [ 5.2338e-02, -3.1555e-02, -5.2673e-02,  ...,  3.7811e-02,\n",
       "            3.3855e-03, -7.8087e-03],\n",
       "          ...,\n",
       "          [ 5.5237e-02, -5.2795e-02,  1.1810e-02,  ...,  7.3547e-02,\n",
       "           -1.0602e-01, -6.1005e-02],\n",
       "          [ 5.1689e-03,  2.4353e-02, -3.6530e-02,  ...,  1.6541e-02,\n",
       "            9.7961e-03, -7.8888e-03],\n",
       "          [ 4.0894e-02,  6.5002e-02, -4.1168e-02,  ...,  3.7689e-02,\n",
       "            3.5763e-03, -7.8201e-03]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[[-0.0072, -0.0098,  0.0410,  ..., -0.0148, -0.0776, -0.0497],\n",
       "          [ 0.0096, -0.0237, -0.0578,  ..., -0.0258, -0.0499, -0.0444],\n",
       "          [-0.0651, -0.0477, -0.0290,  ..., -0.0230, -0.0953, -0.0632],\n",
       "          ...,\n",
       "          [-0.0044, -0.0157,  0.0112,  ...,  0.0518, -0.0321, -0.0720],\n",
       "          [-0.0202, -0.0339, -0.0626,  ..., -0.0116, -0.0581, -0.0435],\n",
       "          [-0.0651, -0.0477, -0.0290,  ..., -0.0230, -0.0953, -0.0632]],\n",
       "\n",
       "         [[-0.0659, -0.1116,  0.0686,  ..., -0.0713, -0.0592, -0.0164],\n",
       "          [-0.0070, -0.0347,  0.0422,  ..., -0.0024,  0.0142, -0.0029],\n",
       "          [ 0.0118, -0.0743,  0.0230,  ...,  0.0271, -0.0438, -0.0502],\n",
       "          ...,\n",
       "          [ 0.0110, -0.0909, -0.1163,  ..., -0.0478, -0.0406, -0.0123],\n",
       "          [-0.0141, -0.0305,  0.0227,  ...,  0.0320,  0.0156,  0.0096],\n",
       "          [ 0.0118, -0.0743,  0.0230,  ...,  0.0271, -0.0438, -0.0502]],\n",
       "\n",
       "         [[ 0.0702, -0.0600,  0.1517,  ...,  0.0367,  0.0759, -0.0258],\n",
       "          [-0.0272,  0.0332,  0.0383,  ...,  0.0151,  0.0008, -0.0368],\n",
       "          [-0.0073,  0.0402,  0.0113,  ..., -0.0123, -0.0534, -0.0201],\n",
       "          ...,\n",
       "          [ 0.0248, -0.0243,  0.1460,  ...,  0.0279,  0.0016, -0.0529],\n",
       "          [-0.0071,  0.0510,  0.0348,  ...,  0.0179, -0.0080, -0.0301],\n",
       "          [-0.0073,  0.0402,  0.0113,  ..., -0.0123, -0.0534, -0.0201]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1026, -0.0273, -0.0702,  ..., -0.0768,  0.1301, -0.0978],\n",
       "          [-0.0099,  0.0005, -0.0112,  ..., -0.0234,  0.0231, -0.0509],\n",
       "          [-0.0618,  0.0556,  0.0300,  ..., -0.0665,  0.0165,  0.0301],\n",
       "          ...,\n",
       "          [-0.0490,  0.0690, -0.0028,  ..., -0.1025,  0.0440, -0.0776],\n",
       "          [-0.0052,  0.0424,  0.0004,  ..., -0.0353, -0.0061, -0.0037],\n",
       "          [-0.0618,  0.0556,  0.0300,  ..., -0.0665,  0.0165,  0.0301]],\n",
       "\n",
       "         [[-0.0764, -0.0325, -0.0041,  ...,  0.1050, -0.0286, -0.0618],\n",
       "          [-0.0062,  0.0155,  0.0495,  ...,  0.0307,  0.0155, -0.0011],\n",
       "          [-0.0095,  0.0309,  0.0775,  ..., -0.0578, -0.0392,  0.0283],\n",
       "          ...,\n",
       "          [-0.0135,  0.1256,  0.0400,  ..., -0.0343, -0.0255,  0.0337],\n",
       "          [ 0.0317,  0.0296,  0.0562,  ...,  0.0140,  0.0187,  0.0163],\n",
       "          [-0.0095,  0.0309,  0.0775,  ..., -0.0578, -0.0392,  0.0283]],\n",
       "\n",
       "         [[-0.0126,  0.0802, -0.0144,  ...,  0.0667, -0.0445,  0.0413],\n",
       "          [-0.0007,  0.0129, -0.0021,  ...,  0.0049,  0.0084,  0.0221],\n",
       "          [ 0.0611, -0.0393, -0.0083,  ...,  0.0079, -0.0112, -0.0032],\n",
       "          ...,\n",
       "          [-0.0113, -0.0344,  0.0401,  ...,  0.0978, -0.0644,  0.0712],\n",
       "          [-0.0048, -0.0217, -0.0188,  ...,  0.0030,  0.0330,  0.0075],\n",
       "          [ 0.0611, -0.0393, -0.0083,  ...,  0.0079, -0.0112, -0.0032]]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<TransposeBackward0>)), (tensor([[[[-1.9092e-01,  5.3284e-02,  1.1469e-01,  ..., -7.2998e-01,\n",
       "           -2.6074e-01,  1.5417e-01],\n",
       "          [-1.6309e-01, -3.0371e-01, -2.3730e-01,  ..., -8.5156e-01,\n",
       "           -3.7549e-01,  2.7637e-01],\n",
       "          [-4.4873e-01, -7.6758e-01, -8.7354e-01,  ..., -7.0459e-01,\n",
       "           -6.5820e-01,  2.6636e-01],\n",
       "          ...,\n",
       "          [-5.7324e-01, -9.3018e-02, -1.1279e-01,  ..., -7.5830e-01,\n",
       "           -5.3760e-01,  6.1182e-01],\n",
       "          [-1.7627e-01, -2.0752e-03, -2.4731e-01,  ..., -7.4902e-01,\n",
       "           -8.0225e-01,  9.1895e-01],\n",
       "          [ 5.1953e-01,  1.2363e+00, -8.6865e-01,  ..., -5.2979e-01,\n",
       "           -6.1279e-01,  2.9688e-01]],\n",
       "\n",
       "         [[-2.1667e-02, -2.2095e-01, -8.3069e-02,  ...,  7.6056e-04,\n",
       "            1.4624e-01, -6.9275e-02],\n",
       "          [-1.2598e-01,  1.5149e-01, -1.6638e-01,  ..., -1.7871e-01,\n",
       "           -1.4610e-02, -1.7700e-01],\n",
       "          [-3.7671e-01, -1.1328e-01, -3.9697e-01,  ..., -3.1226e-01,\n",
       "           -6.0791e-02, -1.3110e-01],\n",
       "          ...,\n",
       "          [-2.0789e-01, -8.0261e-02, -1.6040e-01,  ..., -2.7319e-01,\n",
       "           -1.2720e-01, -1.0889e-01],\n",
       "          [ 3.1934e-01, -1.1871e-01, -2.3071e-01,  ..., -5.6152e-01,\n",
       "           -3.9404e-01, -4.6558e-01],\n",
       "          [ 6.8726e-02,  1.0046e-01, -4.7632e-01,  ..., -2.7563e-01,\n",
       "           -1.2238e-01, -8.9783e-02]],\n",
       "\n",
       "         [[ 1.8854e-03, -5.1483e-02,  6.5979e-02,  ...,  2.4609e-01,\n",
       "            1.0077e-01,  1.2408e-01],\n",
       "          [ 2.6489e-01, -5.6824e-02, -1.7212e-01,  ...,  2.4243e-01,\n",
       "            4.6417e-02,  3.5553e-02],\n",
       "          [ 5.6274e-02, -2.2131e-01,  4.2725e-04,  ...,  3.6328e-01,\n",
       "            2.4194e-01,  1.7432e-01],\n",
       "          ...,\n",
       "          [ 1.6748e-01, -8.8501e-03,  2.6550e-03,  ...,  4.2554e-01,\n",
       "            4.5581e-01,  3.9355e-01],\n",
       "          [ 4.3030e-02,  1.1597e-01, -1.6479e-02,  ...,  3.1592e-01,\n",
       "            2.5903e-01,  2.2949e-01],\n",
       "          [-6.9153e-02,  2.6489e-01,  2.5330e-02,  ...,  4.0088e-01,\n",
       "            3.3911e-01,  2.6758e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.5781e-01,  1.1108e-01, -2.8854e-02,  ..., -3.8544e-02,\n",
       "           -3.4885e-03, -4.6753e-02],\n",
       "          [-1.8909e-01,  7.8247e-02, -3.3960e-01,  ..., -1.8384e-01,\n",
       "            8.9783e-02, -1.8524e-02],\n",
       "          [ 2.2766e-01, -8.3862e-02, -3.4277e-01,  ..., -3.5913e-01,\n",
       "           -6.1531e-03,  6.7090e-01],\n",
       "          ...,\n",
       "          [-1.0907e-01, -1.2573e-02, -1.7188e-01,  ..., -6.6711e-02,\n",
       "            1.3965e-01,  1.7349e-02],\n",
       "          [-2.8369e-01, -8.6487e-02, -5.9814e-02,  ..., -1.5100e-01,\n",
       "            2.1594e-01, -5.2490e-02],\n",
       "          [ 3.6108e-01,  2.3413e-01, -2.2729e-01,  ..., -2.6147e-01,\n",
       "           -6.9641e-02,  8.1250e-01]],\n",
       "\n",
       "         [[ 1.0065e-01, -1.1493e-01, -2.1643e-01,  ..., -9.0515e-02,\n",
       "           -9.1858e-02, -2.4988e-01],\n",
       "          [-1.0675e-01, -2.2778e-01, -2.0996e-02,  ...,  9.0820e-02,\n",
       "           -2.7148e-01,  1.4282e-01],\n",
       "          [-1.3354e-01, -1.2482e-01,  2.1082e-01,  ...,  3.3057e-01,\n",
       "           -1.7041e-01, -6.2402e-01],\n",
       "          ...,\n",
       "          [ 1.5869e-01,  1.6077e-01,  5.7953e-02,  ...,  1.6614e-01,\n",
       "           -2.2156e-01,  3.6450e-01],\n",
       "          [-5.7715e-01,  2.8198e-01, -3.7354e-01,  ...,  2.9980e-01,\n",
       "           -5.6055e-01,  1.2347e-01],\n",
       "          [-2.1875e-01,  1.5601e-01,  2.9858e-01,  ...,  2.8198e-01,\n",
       "           -1.2683e-01, -6.8652e-01]],\n",
       "\n",
       "         [[-8.2642e-02, -1.9409e-02,  1.0895e-01,  ...,  2.3328e-01,\n",
       "           -2.2668e-01,  1.7004e-01],\n",
       "          [-1.2073e-01, -5.2185e-02,  2.6398e-03,  ...,  3.8452e-01,\n",
       "           -4.0015e-01,  2.8198e-01],\n",
       "          [-1.1200e-02,  1.2488e-01, -3.9215e-02,  ...,  4.2065e-01,\n",
       "           -4.1138e-01,  2.7051e-01],\n",
       "          ...,\n",
       "          [-1.4270e-01,  4.0894e-02, -3.4973e-02,  ...,  4.5459e-01,\n",
       "           -4.7070e-01,  3.4424e-01],\n",
       "          [ 1.1993e-01,  1.6577e-01, -1.1377e-01,  ...,  6.7236e-01,\n",
       "           -6.8311e-01,  5.0977e-01],\n",
       "          [-4.6570e-02, -8.9417e-02,  4.5471e-02,  ...,  4.7705e-01,\n",
       "           -4.6680e-01,  3.0444e-01]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[[-9.5444e-03, -2.6352e-02,  1.1359e-01,  ...,  2.4962e-04,\n",
       "           -4.3396e-02,  7.4585e-02],\n",
       "          [-9.7168e-02, -5.2452e-03,  2.1698e-02,  ..., -2.9087e-04,\n",
       "            1.3077e-02,  2.4460e-02],\n",
       "          [ 1.5808e-01, -9.0332e-02,  7.1838e-02,  ...,  5.7556e-02,\n",
       "           -4.5868e-02,  4.5441e-02],\n",
       "          ...,\n",
       "          [ 1.3161e-02, -2.7527e-02,  1.0521e-02,  ...,  3.7964e-02,\n",
       "           -6.1066e-02,  3.7079e-03],\n",
       "          [-9.5398e-02,  3.0365e-02,  9.6985e-02,  ..., -1.1810e-02,\n",
       "           -6.3782e-02, -8.6899e-03],\n",
       "          [ 1.7957e-01, -9.3201e-02,  2.7374e-02,  ...,  5.9814e-02,\n",
       "           -4.0863e-02,  5.5420e-02]],\n",
       "\n",
       "         [[ 1.6022e-02,  9.2468e-03, -2.0386e-02,  ..., -3.3207e-03,\n",
       "            1.8127e-02,  1.4450e-02],\n",
       "          [ 9.3613e-03,  6.3286e-03, -1.8829e-02,  ..., -9.7504e-03,\n",
       "            1.1322e-02,  4.8494e-04],\n",
       "          [-1.4615e-04, -5.5008e-03, -2.0126e-02,  ...,  1.5507e-03,\n",
       "            1.8158e-02, -3.7727e-03],\n",
       "          ...,\n",
       "          [ 2.2583e-03, -8.6670e-03, -2.0142e-02,  ..., -1.3527e-02,\n",
       "           -7.8430e-03, -1.8021e-02],\n",
       "          [-8.9979e-04, -8.7051e-03, -2.2873e-02,  ..., -2.1835e-02,\n",
       "            3.4218e-03,  6.5536e-03],\n",
       "          [-1.2321e-03, -9.2468e-03, -1.0780e-02,  ..., -5.6458e-03,\n",
       "           -1.2407e-03, -1.9272e-02]],\n",
       "\n",
       "         [[ 2.1652e-02,  1.3199e-03,  1.1810e-02,  ..., -3.0899e-02,\n",
       "            2.2400e-02,  1.0925e-02],\n",
       "          [ 5.2155e-02,  1.1681e-02,  5.3497e-02,  ..., -1.5027e-01,\n",
       "           -2.6031e-02, -1.1664e-01],\n",
       "          [ 4.6539e-02,  2.8534e-03, -1.1530e-01,  ..., -1.8457e-01,\n",
       "            5.0323e-02,  1.3013e-01],\n",
       "          ...,\n",
       "          [ 3.6499e-02, -6.2790e-03, -7.7400e-03,  ..., -2.0721e-02,\n",
       "           -8.7357e-03,  5.4230e-02],\n",
       "          [-3.4363e-02, -1.7838e-02,  5.2399e-02,  ..., -1.9519e-01,\n",
       "            8.7891e-03,  1.9849e-01],\n",
       "          [ 6.8176e-02, -6.7806e-04, -1.1646e-01,  ..., -1.7871e-01,\n",
       "            3.2959e-02,  1.8677e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.5492e-02,  2.5528e-02,  1.0979e-02,  ..., -2.0401e-02,\n",
       "            3.2379e-02, -4.0131e-02],\n",
       "          [ 5.8228e-02,  3.5950e-02, -2.0466e-03,  ..., -2.9480e-02,\n",
       "            2.8091e-02, -3.7201e-02],\n",
       "          [ 7.1831e-03,  2.8152e-02,  1.9028e-02,  ..., -1.2154e-02,\n",
       "            2.5833e-02, -1.7395e-02],\n",
       "          ...,\n",
       "          [ 4.0894e-02,  6.8665e-03,  6.4325e-04,  ..., -2.2545e-03,\n",
       "            9.2850e-03, -2.8610e-02],\n",
       "          [ 4.5410e-02,  1.0826e-02, -5.4131e-03,  ..., -4.6448e-02,\n",
       "           -1.1925e-02, -9.5215e-03],\n",
       "          [ 6.1073e-03,  1.7578e-02,  1.0582e-02,  ..., -9.3002e-03,\n",
       "            2.5162e-02,  7.4730e-03]],\n",
       "\n",
       "         [[-1.4905e-01,  2.7466e-02,  6.0387e-03,  ..., -2.3087e-02,\n",
       "            1.8127e-02, -1.2917e-02],\n",
       "          [-1.0004e-01, -2.3697e-02,  1.0376e-01,  ..., -6.0730e-03,\n",
       "            3.7018e-02, -6.5536e-03],\n",
       "          [-6.0242e-02,  6.3538e-02, -2.5708e-01,  ..., -2.3880e-02,\n",
       "            3.2532e-02, -1.5282e-02],\n",
       "          ...,\n",
       "          [-2.6367e-01, -9.7107e-02,  2.0645e-02,  ..., -2.4628e-02,\n",
       "            3.6377e-02, -6.1676e-02],\n",
       "          [-2.9175e-01, -1.1377e-01,  5.7678e-02,  ..., -1.3000e-02,\n",
       "            4.9835e-02, -1.9547e-02],\n",
       "          [-4.1931e-02,  4.7035e-03, -2.7148e-01,  ..., -9.2545e-03,\n",
       "            4.0588e-02, -3.2806e-02]],\n",
       "\n",
       "         [[-1.0056e-02, -6.7520e-03, -3.0396e-02,  ...,  1.6953e-02,\n",
       "            1.9363e-02, -2.7603e-02],\n",
       "          [-1.0323e-02, -6.3515e-03, -2.8336e-02,  ..., -2.4486e-04,\n",
       "            1.7899e-02, -1.3878e-02],\n",
       "          [ 1.9501e-02,  6.8245e-03, -3.2227e-02,  ...,  2.5345e-02,\n",
       "           -7.1764e-04, -8.0338e-03],\n",
       "          ...,\n",
       "          [ 3.1219e-02,  2.9739e-02, -2.9678e-02,  ...,  3.5187e-02,\n",
       "           -1.0307e-02,  2.4796e-02],\n",
       "          [ 3.9734e-02,  1.2543e-02, -1.8188e-02,  ...,  5.9357e-02,\n",
       "           -2.6215e-02,  3.0167e-02],\n",
       "          [ 3.9246e-02,  2.5497e-02, -2.0477e-02,  ...,  3.3691e-02,\n",
       "           -6.6605e-03,  8.9035e-03]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[ 4.5410e-02,  1.2627e-02,  9.5337e-02,  ..., -1.2396e-01,\n",
       "           -9.2773e-02, -6.1874e-03],\n",
       "          [-3.5059e-01,  4.2603e-01, -7.5989e-02,  ...,  6.1462e-02,\n",
       "            8.3350e-01,  5.0293e-01],\n",
       "          [-9.5215e-01,  4.6844e-02,  1.4075e-01,  ..., -8.3923e-02,\n",
       "            5.7159e-02, -2.2205e-01],\n",
       "          ...,\n",
       "          [-3.8184e-01, -6.6699e-01,  1.2451e-01,  ...,  6.3672e-01,\n",
       "            1.9519e-01, -3.5352e-01],\n",
       "          [-2.8887e+00, -1.9702e-01,  2.4548e-01,  ...,  9.4727e-01,\n",
       "            1.3574e+00, -4.2432e-01],\n",
       "          [-2.5273e+00,  4.0454e-01,  5.4688e-01,  ...,  5.9229e-01,\n",
       "            5.1270e-01, -4.6875e-01]],\n",
       "\n",
       "         [[-4.7058e-02,  3.5645e-02, -2.1114e-03,  ..., -1.1032e-02,\n",
       "            1.7505e-01, -1.8518e-01],\n",
       "          [-2.3071e-02,  1.9067e-01,  1.1621e-01,  ..., -4.4458e-01,\n",
       "           -7.5977e-01,  6.9189e-01],\n",
       "          [ 6.6345e-02, -3.2082e-03, -3.5248e-02,  ..., -4.1431e-01,\n",
       "           -3.4399e-01,  3.2593e-01],\n",
       "          ...,\n",
       "          [-1.8652e-01, -1.3538e-01, -1.7224e-01,  ..., -1.8970e-01,\n",
       "           -5.9375e-01,  4.8975e-01],\n",
       "          [ 4.8438e-01, -2.4658e-02,  8.4778e-02,  ..., -1.7773e-01,\n",
       "           -1.1738e+00,  1.2188e+00],\n",
       "          [ 4.7046e-01,  5.3528e-02, -2.0728e-01,  ..., -8.5742e-01,\n",
       "           -1.0674e+00,  9.7217e-01]],\n",
       "\n",
       "         [[ 2.3254e-02,  6.7444e-02,  1.0223e-01,  ...,  1.6876e-02,\n",
       "            1.2622e-01, -1.5393e-01],\n",
       "          [ 6.0840e-01, -2.8516e-01,  3.4424e-01,  ...,  3.7622e-01,\n",
       "           -7.0508e-01,  8.3203e-01],\n",
       "          [ 8.8672e-01, -5.2783e-01, -3.7012e-01,  ...,  2.1997e-01,\n",
       "           -4.2261e-01,  3.2886e-01],\n",
       "          ...,\n",
       "          [ 9.5361e-01,  1.1475e-01,  3.3203e-01,  ..., -2.6520e-02,\n",
       "           -6.8896e-01,  2.4585e-01],\n",
       "          [ 2.5977e+00,  1.1699e+00, -1.5955e-01,  ...,  2.3389e-01,\n",
       "           -2.3770e+00,  1.1357e+00],\n",
       "          [ 1.5469e+00,  1.6367e+00, -7.5293e-01,  ...,  3.3569e-01,\n",
       "           -1.3701e+00,  7.3193e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.6824e-02, -2.5284e-02, -1.9073e-02,  ..., -4.3427e-02,\n",
       "           -3.6987e-02,  6.7749e-03],\n",
       "          [ 5.0195e-01,  2.4512e-01, -3.4790e-01,  ..., -3.7012e-01,\n",
       "           -1.3457e+00, -7.5586e-01],\n",
       "          [ 1.6833e-01,  1.3257e-01,  1.0059e-01,  ..., -7.8491e-02,\n",
       "           -2.0618e-01, -9.5642e-02],\n",
       "          ...,\n",
       "          [ 1.1055e+00, -3.7549e-01,  1.7700e-01,  ..., -3.3105e-01,\n",
       "           -8.1055e-01, -2.2253e-01],\n",
       "          [ 5.6104e-01, -3.6426e-01,  1.9263e-01,  ..., -1.5552e-01,\n",
       "           -1.0596e+00, -9.4238e-02],\n",
       "          [-1.0801e+00, -6.1157e-02,  2.3401e-01,  ..., -2.2607e-01,\n",
       "           -9.0186e-01, -5.3101e-03]],\n",
       "\n",
       "         [[ 7.7698e-02, -8.2458e-02,  3.8727e-02,  ..., -9.9976e-02,\n",
       "            9.1431e-02,  1.1200e-01],\n",
       "          [-7.5391e-01,  0.0000e+00, -2.8760e-01,  ...,  6.0889e-01,\n",
       "            2.0813e-01, -7.6318e-01],\n",
       "          [-1.1357e+00,  2.9956e-01, -3.8135e-01,  ..., -4.8737e-02,\n",
       "            5.3711e-01, -5.5786e-02],\n",
       "          ...,\n",
       "          [-9.7266e-01,  7.5342e-01, -3.3960e-01,  ...,  7.0557e-01,\n",
       "            3.8379e-01,  2.0972e-01],\n",
       "          [-3.5684e+00,  4.7827e-01, -4.0863e-02,  ...,  5.8936e-01,\n",
       "            2.6489e-01,  7.6318e-01],\n",
       "          [-2.4883e+00, -6.6797e-01, -4.6387e-01,  ...,  7.0654e-01,\n",
       "            7.0605e-01,  5.3986e-02]],\n",
       "\n",
       "         [[ 1.0675e-01, -4.5837e-02,  3.2867e-02,  ...,  1.1493e-01,\n",
       "            2.3865e-01, -5.2185e-02],\n",
       "          [ 1.3086e-01, -9.2468e-02, -1.9629e-01,  ...,  1.8604e-01,\n",
       "           -1.1094e+00, -3.3154e-01],\n",
       "          [-6.3623e-01, -9.0561e-03, -1.9116e-01,  ..., -1.5083e-02,\n",
       "           -3.7988e-01,  3.1274e-01],\n",
       "          ...,\n",
       "          [ 2.6758e-01, -2.7783e-01, -5.4639e-01,  ..., -4.7876e-01,\n",
       "           -7.2021e-01, -3.3154e-01],\n",
       "          [-1.8438e+00, -7.0215e-01, -4.6875e-01,  ..., -9.1797e-01,\n",
       "           -1.6992e+00, -1.2637e+00],\n",
       "          [-1.9512e+00,  1.8994e-01, -9.7705e-01,  ..., -2.9053e-01,\n",
       "           -1.3848e+00,  1.0291e-01]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[[ 2.6321e-02,  1.0551e-02,  4.1260e-02,  ...,  4.1931e-02,\n",
       "           -2.4509e-03, -5.2567e-03],\n",
       "          [-1.6953e-02, -4.2023e-02,  2.2485e-01,  ...,  1.1572e-01,\n",
       "           -1.4478e-01, -2.9004e-01],\n",
       "          [-3.6957e-02,  8.4381e-03,  1.3135e-01,  ...,  5.8990e-02,\n",
       "            3.3386e-02, -3.2959e-02],\n",
       "          ...,\n",
       "          [ 9.4238e-02,  2.2003e-02,  4.5959e-02,  ..., -8.0872e-02,\n",
       "            1.1011e-01, -1.7249e-01],\n",
       "          [-1.2901e-02,  1.4136e-01,  9.5337e-02,  ...,  3.4241e-02,\n",
       "            2.5830e-01, -4.8291e-01],\n",
       "          [-1.0748e-01,  7.3608e-02,  1.0236e-01,  ..., -7.5500e-02,\n",
       "            7.0862e-02, -1.6980e-01]],\n",
       "\n",
       "         [[ 3.9093e-02, -1.6449e-02,  3.5828e-02,  ...,  2.4139e-02,\n",
       "           -5.2643e-02,  1.8600e-02],\n",
       "          [ 2.1289e-01, -6.8420e-02,  3.0151e-01,  ..., -2.0142e-01,\n",
       "           -7.0953e-03,  1.5918e-01],\n",
       "          [ 4.4037e-02, -8.9478e-02,  1.1853e-01,  ...,  6.5552e-02,\n",
       "            9.4543e-02, -1.9501e-02],\n",
       "          ...,\n",
       "          [ 3.5327e-01,  4.1718e-02,  4.3243e-02,  ...,  5.1819e-02,\n",
       "           -5.3650e-02, -2.6855e-02],\n",
       "          [ 3.4009e-01, -6.6528e-02,  1.2445e-01,  ...,  8.3740e-02,\n",
       "           -1.2408e-01, -4.5441e-02],\n",
       "          [ 5.2393e-01, -5.4535e-02,  2.3401e-01,  ...,  3.2288e-02,\n",
       "            1.9470e-01, -2.5320e-04]],\n",
       "\n",
       "         [[ 1.9760e-02, -2.8519e-02, -2.8198e-02,  ..., -1.7071e-03,\n",
       "           -8.1253e-03,  1.2756e-02],\n",
       "          [ 1.0902e-02, -1.4673e-01, -1.8494e-01,  ...,  3.8300e-02,\n",
       "           -1.4319e-01, -9.9487e-02],\n",
       "          [ 5.0262e-02, -3.0624e-02, -4.2328e-02,  ..., -6.4545e-03,\n",
       "           -6.1981e-02,  1.6375e-03],\n",
       "          ...,\n",
       "          [ 1.2360e-01, -5.4626e-02, -9.0637e-02,  ...,  1.0803e-01,\n",
       "           -2.3788e-02,  7.5195e-02],\n",
       "          [ 5.8655e-02, -3.1396e-01, -1.1511e-01,  ...,  9.1431e-02,\n",
       "            9.6985e-02, -5.7068e-02],\n",
       "          [ 1.5588e-01, -2.3209e-02,  6.0654e-03,  ...,  1.0669e-01,\n",
       "           -8.4457e-03,  2.3804e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.6994e-03, -4.3488e-02,  4.1290e-02,  ...,  1.8524e-02,\n",
       "            3.0228e-02,  2.9984e-02],\n",
       "          [-8.2642e-02, -2.3331e-02,  9.8145e-02,  ...,  1.2947e-02,\n",
       "            3.8184e-01,  1.1206e-01],\n",
       "          [ 2.5330e-02,  4.7791e-02,  7.9651e-02,  ..., -6.2744e-02,\n",
       "            2.5073e-01,  9.0454e-02],\n",
       "          ...,\n",
       "          [ 6.0974e-02,  1.2598e-01, -2.0081e-02,  ...,  2.7603e-02,\n",
       "            2.3816e-01, -1.0571e-01],\n",
       "          [ 1.9873e-01,  9.8694e-02, -7.7209e-02,  ...,  1.9080e-01,\n",
       "            4.4434e-01, -1.3416e-01],\n",
       "          [ 1.4343e-01,  5.2216e-02,  1.3107e-02,  ..., -1.4307e-01,\n",
       "            3.5156e-01, -4.8767e-02]],\n",
       "\n",
       "         [[ 2.1423e-02, -3.0106e-02,  1.6916e-04,  ...,  1.4595e-02,\n",
       "            1.7151e-02,  1.4824e-02],\n",
       "          [ 1.1401e-01,  3.9526e-01,  1.3074e-01,  ..., -1.7380e-02,\n",
       "            1.7493e-01, -2.6099e-01],\n",
       "          [ 5.0995e-02, -1.9336e-01,  1.3672e-01,  ...,  4.7699e-02,\n",
       "            1.5030e-02, -3.3081e-02],\n",
       "          ...,\n",
       "          [ 8.0505e-02, -1.5808e-01,  7.5134e-02,  ...,  8.0824e-04,\n",
       "           -3.1982e-02, -1.5942e-01],\n",
       "          [ 4.2511e-02, -9.3079e-02,  2.4261e-02,  ..., -1.3623e-01,\n",
       "            4.2725e-02, -1.9421e-01],\n",
       "          [ 6.0760e-02, -3.8135e-01,  1.8420e-01,  ..., -3.8574e-02,\n",
       "           -2.4567e-02, -1.5549e-02]],\n",
       "\n",
       "         [[ 1.3741e-02, -3.9673e-02, -2.9556e-02,  ..., -6.2103e-03,\n",
       "           -3.9032e-02,  2.7512e-02],\n",
       "          [ 1.6127e-03, -3.9453e-01,  6.3721e-02,  ..., -3.1934e-01,\n",
       "           -2.5244e-01,  2.6074e-01],\n",
       "          [-2.8641e-02, -5.9662e-02, -2.8290e-02,  ..., -1.1432e-01,\n",
       "           -1.6736e-01,  9.3201e-02],\n",
       "          ...,\n",
       "          [-1.1530e-01, -5.7892e-02, -1.4758e-01,  ..., -1.4136e-01,\n",
       "           -4.3640e-02,  1.1871e-01],\n",
       "          [-2.1973e-01,  1.9543e-01, -1.9678e-01,  ..., -1.3123e-01,\n",
       "            2.7435e-02,  3.3154e-01],\n",
       "          [-1.7407e-01, -8.5983e-03, -1.2683e-01,  ..., -3.7201e-02,\n",
       "           -2.7661e-01,  1.7419e-01]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[ 6.1951e-02,  4.4922e-02, -1.4355e-01,  ..., -3.6938e-01,\n",
       "           -1.9568e-01,  4.0234e-01],\n",
       "          [ 4.0649e-02, -1.2422e+00, -1.8811e-01,  ..., -1.9795e+00,\n",
       "           -5.1807e-01,  2.0664e+00],\n",
       "          [-2.6147e-01,  4.3915e-02, -3.5181e-01,  ..., -1.0967e+00,\n",
       "            5.3809e-01,  1.1729e+00],\n",
       "          ...,\n",
       "          [ 7.5928e-02, -3.9258e-01, -2.2046e-01,  ..., -1.1875e+00,\n",
       "            4.1113e-01,  1.2480e+00],\n",
       "          [-3.4619e-01, -1.8994e-01, -3.3252e-01,  ..., -1.7090e+00,\n",
       "           -2.0947e-01,  1.7646e+00],\n",
       "          [-3.2153e-01, -5.2490e-01, -2.4072e-01,  ..., -1.4482e+00,\n",
       "            6.3623e-01,  1.5225e+00]],\n",
       "\n",
       "         [[ 9.5215e-02,  4.5121e-05,  1.2369e-03,  ..., -7.8003e-02,\n",
       "           -2.3108e-01, -2.5925e-02],\n",
       "          [-1.5454e-01, -3.6572e-01, -4.2847e-02,  ...,  7.7686e-01,\n",
       "            8.4570e-01,  8.8916e-01],\n",
       "          [-4.4312e-01, -3.9258e-01, -3.1250e-01,  ...,  4.7144e-01,\n",
       "            2.4255e-01,  5.2100e-01],\n",
       "          ...,\n",
       "          [-3.9478e-01,  1.8481e-01, -2.2095e-01,  ...,  6.0840e-01,\n",
       "            5.9521e-01,  9.4580e-01],\n",
       "          [-4.4019e-01,  4.0454e-01, -2.3914e-01,  ...,  9.4580e-01,\n",
       "            7.5000e-01,  9.5459e-01],\n",
       "          [-9.5276e-02,  3.1812e-01, -2.7661e-01,  ...,  6.7090e-01,\n",
       "            6.2207e-01,  8.7256e-01]],\n",
       "\n",
       "         [[-1.9348e-01,  1.1743e-01,  1.9275e-01,  ..., -4.9414e-01,\n",
       "            2.3621e-01, -1.4587e-01],\n",
       "          [-8.0078e-01,  3.4424e-02, -5.2197e-01,  ..., -3.5391e+00,\n",
       "            3.5571e-01, -8.7402e-02],\n",
       "          [ 3.7109e-02, -5.5847e-03, -6.8213e-01,  ..., -2.0117e+00,\n",
       "           -2.6733e-01,  7.4805e-01],\n",
       "          ...,\n",
       "          [-1.1934e+00,  3.5400e-02, -8.1592e-01,  ..., -1.9590e+00,\n",
       "            3.6011e-01,  2.4866e-01],\n",
       "          [-3.2812e-01, -5.8807e-02, -1.3789e+00,  ..., -2.8379e+00,\n",
       "            7.9199e-01, -4.3774e-01],\n",
       "          [ 1.0117e+00,  2.6538e-01, -4.0576e-01,  ..., -2.6738e+00,\n",
       "            4.9585e-01,  4.0894e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.6467e-01,  5.3215e-03,  1.6129e-02,  ..., -2.8101e-01,\n",
       "            2.2888e-02,  1.0040e-01],\n",
       "          [ 4.0869e-01,  2.6953e-01,  4.2822e-01,  ..., -2.3672e+00,\n",
       "            9.5459e-01, -8.8379e-02],\n",
       "          [ 4.9133e-02, -7.3425e-02,  3.3130e-01,  ..., -1.3008e+00,\n",
       "            9.0820e-01,  2.5708e-01],\n",
       "          ...,\n",
       "          [ 1.3330e-01,  1.1304e-01,  3.3301e-01,  ..., -1.4326e+00,\n",
       "           -3.7598e-01,  4.7705e-01],\n",
       "          [-1.0547e-01, -9.2468e-02,  2.7100e-01,  ..., -2.0098e+00,\n",
       "           -3.2715e-01,  5.8252e-01],\n",
       "          [-6.0516e-02, -3.2227e-01,  4.8767e-02,  ..., -1.8564e+00,\n",
       "            4.5197e-02,  6.8018e-01]],\n",
       "\n",
       "         [[ 6.8298e-02, -1.2433e-01,  2.2720e-02,  ..., -6.8787e-02,\n",
       "            1.4795e-01,  1.5175e-02],\n",
       "          [-5.2148e-01, -3.3496e-01,  5.9277e-01,  ..., -3.9917e-01,\n",
       "            8.8379e-01, -3.5303e-01],\n",
       "          [-3.5376e-01, -1.6174e-01, -2.0703e-01,  ...,  2.1545e-01,\n",
       "            6.3330e-01,  5.6000e-03],\n",
       "          ...,\n",
       "          [-4.3799e-01,  2.8564e-01, -5.8411e-02,  ..., -1.7297e-01,\n",
       "            1.3269e-01, -8.6279e-01],\n",
       "          [-1.1494e+00,  1.1163e-01, -2.6050e-01,  ..., -5.5078e-01,\n",
       "           -2.2339e-01, -1.3779e+00],\n",
       "          [-6.9531e-01, -1.6907e-01, -3.7183e-01,  ...,  8.9417e-02,\n",
       "            3.0640e-01, -9.2969e-01]],\n",
       "\n",
       "         [[ 1.3016e-02, -8.4595e-02,  1.4658e-03,  ..., -3.0078e-01,\n",
       "            2.0752e-01,  5.2734e-01],\n",
       "          [ 1.4160e-01, -3.7231e-03,  3.7378e-01,  ..., -3.4609e+00,\n",
       "            5.3760e-01,  2.3848e+00],\n",
       "          [ 2.0007e-01,  2.9639e-01,  2.0020e-01,  ..., -2.4004e+00,\n",
       "            1.0391e+00,  4.3384e-01],\n",
       "          ...,\n",
       "          [-5.5542e-02, -1.7236e-01,  2.2131e-01,  ..., -2.0781e+00,\n",
       "            7.4707e-01,  1.1591e-01],\n",
       "          [ 4.5557e-01, -3.7158e-01, -1.1139e-01,  ..., -1.8809e+00,\n",
       "            2.5742e+00,  1.4199e+00],\n",
       "          [ 3.9648e-01, -3.2886e-01, -2.1082e-01,  ..., -2.7539e+00,\n",
       "            1.7344e+00,  1.0244e+00]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[[-6.1829e-02, -7.8201e-04, -4.3823e-02,  ..., -4.8309e-02,\n",
       "            3.2558e-03,  1.2825e-02],\n",
       "          [-2.2803e-01,  2.5833e-02,  1.8860e-01,  ...,  1.2683e-01,\n",
       "           -4.4525e-02, -1.7990e-02],\n",
       "          [-3.9160e-01,  9.2773e-02,  1.4209e-01,  ..., -1.1475e-01,\n",
       "            8.4045e-02,  1.5503e-01],\n",
       "          ...,\n",
       "          [-1.6919e-01, -3.2135e-02,  1.7859e-01,  ..., -1.5369e-01,\n",
       "           -9.3262e-02,  3.0981e-01],\n",
       "          [-7.9346e-02,  8.3618e-02,  2.8833e-01,  ..., -2.7515e-01,\n",
       "           -1.4941e-01,  2.0886e-01],\n",
       "          [-1.7859e-01,  7.1678e-03,  2.2522e-01,  ..., -2.1570e-01,\n",
       "           -7.9773e-02,  4.1187e-01]],\n",
       "\n",
       "         [[ 4.9805e-02, -9.9258e-03,  1.7426e-02,  ...,  2.2385e-02,\n",
       "           -6.3721e-02,  5.9242e-03],\n",
       "          [ 5.3516e-01,  2.8003e-01,  1.6098e-02,  ..., -2.2141e-02,\n",
       "           -1.3818e-01,  1.5576e-01],\n",
       "          [ 2.1826e-01,  8.1543e-02, -7.0724e-03,  ...,  6.6345e-02,\n",
       "           -2.0905e-02,  3.0176e-01],\n",
       "          ...,\n",
       "          [-6.5857e-02,  1.6443e-01,  1.3232e-01,  ...,  4.3915e-02,\n",
       "           -8.4290e-02,  2.8320e-01],\n",
       "          [-7.7698e-02,  1.5161e-01,  1.8054e-01,  ...,  1.4417e-01,\n",
       "           -3.3179e-01,  2.6001e-01],\n",
       "          [ 1.0718e-01,  1.3354e-01,  1.0425e-01,  ...,  1.0815e-01,\n",
       "           -1.9238e-01,  3.8672e-01]],\n",
       "\n",
       "         [[ 5.4932e-02, -5.8365e-03,  5.0468e-03,  ...,  5.3589e-02,\n",
       "           -4.5746e-02, -6.5186e-02],\n",
       "          [ 9.7412e-02,  1.3710e-02, -1.6016e-01,  ..., -1.6614e-01,\n",
       "           -1.0278e-01, -6.3086e-01],\n",
       "          [ 2.2876e-01,  4.9500e-02,  6.8245e-03,  ..., -1.7847e-01,\n",
       "           -5.7312e-02, -4.3042e-01],\n",
       "          ...,\n",
       "          [ 1.6357e-01,  6.0211e-02,  2.1472e-01,  ..., -1.1609e-01,\n",
       "            7.2449e-02, -3.8794e-01],\n",
       "          [ 4.0625e-01,  4.2206e-02,  4.3677e-01,  ..., -1.6907e-01,\n",
       "           -2.3535e-01, -7.8247e-02],\n",
       "          [ 3.7085e-01,  4.2389e-02,  3.7793e-01,  ..., -1.6541e-01,\n",
       "           -1.1047e-02, -3.3301e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.4168e-02,  6.1264e-03, -1.1871e-02,  ..., -7.6965e-02,\n",
       "           -3.1830e-02, -1.4748e-02],\n",
       "          [-2.3169e-01, -3.7378e-01, -8.0688e-02,  ..., -5.4016e-02,\n",
       "            1.1432e-01,  8.7219e-02],\n",
       "          [-7.7087e-02, -1.7883e-01,  5.3986e-02,  ..., -1.8311e-01,\n",
       "           -3.3020e-02,  2.4765e-02],\n",
       "          ...,\n",
       "          [-1.3318e-01, -1.6077e-01,  8.0322e-02,  ..., -8.9294e-02,\n",
       "            1.7566e-01,  4.5227e-02],\n",
       "          [-1.8250e-01, -1.2274e-01,  1.6724e-01,  ...,  1.1772e-02,\n",
       "            1.4319e-01,  6.4453e-02],\n",
       "          [-2.0520e-01, -1.3818e-01,  1.8494e-01,  ..., -1.0413e-01,\n",
       "            1.8396e-01, -1.0963e-02]],\n",
       "\n",
       "         [[-6.0081e-03, -4.2236e-02, -3.2867e-02,  ...,  3.1464e-02,\n",
       "           -4.7150e-03,  6.0303e-02],\n",
       "          [-1.0706e-01,  9.9548e-02, -2.9370e-01,  ...,  2.3486e-01,\n",
       "           -2.0859e-02,  4.4678e-01],\n",
       "          [-1.7798e-01, -2.5635e-01, -1.5088e-01,  ..., -3.6652e-02,\n",
       "            3.7384e-03,  1.0968e-01],\n",
       "          ...,\n",
       "          [-3.2690e-01, -2.8027e-01, -2.5024e-01,  ..., -1.3074e-01,\n",
       "            2.0520e-01, -2.8491e-01],\n",
       "          [-4.0039e-01, -6.1981e-02, -3.3276e-01,  ..., -6.6528e-02,\n",
       "            2.9468e-01, -3.7988e-01],\n",
       "          [-3.6841e-01, -1.9910e-01, -3.5547e-01,  ..., -2.9907e-01,\n",
       "            2.0752e-01, -1.3550e-01]],\n",
       "\n",
       "         [[-1.0124e-02,  1.2779e-02,  5.6000e-02,  ...,  1.0483e-02,\n",
       "           -7.4158e-03,  3.3736e-04],\n",
       "          [ 9.0698e-02,  2.5488e-01, -2.6001e-02,  ...,  1.7627e-01,\n",
       "            4.0619e-02, -1.0907e-01],\n",
       "          [-3.3173e-02,  7.9163e-02,  6.7810e-02,  ...,  7.5073e-02,\n",
       "           -5.0446e-02, -9.6008e-02],\n",
       "          ...,\n",
       "          [ 2.1094e-01,  6.4270e-02,  8.4839e-02,  ...,  2.0728e-01,\n",
       "            7.8552e-02, -7.5195e-02],\n",
       "          [ 2.6147e-01, -3.3051e-02,  8.4534e-02,  ...,  1.7700e-01,\n",
       "            1.3330e-01, -1.0834e-01],\n",
       "          [ 2.2229e-01,  8.8425e-03, -4.1595e-02,  ...,  1.8323e-01,\n",
       "            1.3342e-01, -1.0858e-01]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[ 0.1838,  0.0646, -0.1532,  ..., -0.0654, -0.0376, -0.0427],\n",
       "          [ 1.3232,  0.1315,  0.2188,  ...,  0.4299,  0.0204, -0.4790],\n",
       "          [ 0.2539, -0.1836, -0.0789,  ...,  0.1030,  0.5332,  0.0218],\n",
       "          ...,\n",
       "          [ 1.2383,  0.2247, -0.0127,  ...,  0.1079,  1.1367,  0.4600],\n",
       "          [ 0.7622,  0.0641, -0.4087,  ...,  0.3430,  0.9673,  0.2358],\n",
       "          [-0.5747, -0.1163, -0.5532,  ..., -0.0182,  1.3926,  0.5454]],\n",
       "\n",
       "         [[-0.0134,  0.0885, -0.1537,  ...,  0.1405,  0.0163,  0.3167],\n",
       "          [ 0.2754,  0.3740, -0.4966,  ..., -1.2900,  0.3259, -0.1868],\n",
       "          [ 0.0089,  0.2349, -0.0748,  ..., -0.8604, -0.3708, -0.4395],\n",
       "          ...,\n",
       "          [ 0.0918, -0.4546, -0.0708,  ..., -1.5283,  0.9897,  0.1715],\n",
       "          [-0.2917, -0.4417,  0.2415,  ..., -1.6885,  1.4355,  0.2499],\n",
       "          [-0.4365, -0.1661,  0.3743,  ..., -1.6270,  0.8574,  0.0870]],\n",
       "\n",
       "         [[-0.1118, -0.1407,  0.0863,  ...,  0.0183, -0.4702,  0.5435],\n",
       "          [ 0.3262, -0.3281, -0.0506,  ...,  0.1924, -0.9141,  0.1365],\n",
       "          [ 0.2051, -0.2236, -0.0540,  ...,  0.7041, -0.9478,  1.0635],\n",
       "          ...,\n",
       "          [ 0.6650,  0.2173,  0.1777,  ...,  0.7910,  0.3267, -0.4001],\n",
       "          [ 0.4761,  0.1018,  0.1378,  ...,  0.6040,  0.4893, -0.4556],\n",
       "          [-0.1934, -0.0813,  0.0713,  ...,  0.5605,  0.4170, -0.6045]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.1027, -0.0523, -0.0538,  ..., -0.2222, -0.0474,  0.1489],\n",
       "          [ 0.3413,  0.4263, -0.2308,  ..., -0.2881,  0.5366,  0.9204],\n",
       "          [-0.0254,  0.3765,  0.0839,  ...,  0.0392, -0.1050,  0.5283],\n",
       "          ...,\n",
       "          [-0.1362,  0.4634,  0.6069,  ..., -0.5850, -0.0225,  0.2913],\n",
       "          [ 0.3518,  0.2495,  0.3804,  ..., -0.5000,  0.2336,  0.5898],\n",
       "          [ 0.3347, -0.0121, -0.0186,  ..., -0.6558,  0.1780,  0.3828]],\n",
       "\n",
       "         [[-0.0756, -0.0805,  0.1293,  ..., -0.0440,  0.1632,  0.0200],\n",
       "          [ 0.0889, -0.5498,  0.6758,  ...,  1.1934,  1.3564,  0.9600],\n",
       "          [ 0.5820, -0.3164,  0.0549,  ...,  0.2510,  0.9116,  0.6025],\n",
       "          ...,\n",
       "          [ 0.3042,  0.3123,  0.0310,  ...,  0.3047,  0.4246,  0.8223],\n",
       "          [ 0.4412,  0.6035,  0.1713,  ...,  0.7188,  0.4551,  1.0264],\n",
       "          [ 0.0142,  0.3721, -0.0396,  ...,  0.5737,  0.6221,  0.7788]],\n",
       "\n",
       "         [[ 0.0114,  0.0854, -0.1104,  ..., -0.1354,  0.1683,  0.2690],\n",
       "          [-0.3242,  0.1333, -0.4517,  ...,  0.3591,  2.3809,  0.9150],\n",
       "          [-0.1835, -0.2152, -0.6172,  ...,  0.4336,  1.3838,  0.5605],\n",
       "          ...,\n",
       "          [-0.5947, -0.0194, -0.1318,  ...,  0.2617,  1.6025,  0.3638],\n",
       "          [-0.6167,  0.3369, -0.9395,  ...,  0.1638,  1.5527,  0.2499],\n",
       "          [-0.0307,  0.4707, -1.3096,  ...,  0.1564,  1.9375,  0.2681]]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[[-2.6901e-02, -1.7197e-02,  3.9429e-02,  ..., -6.1798e-03,\n",
       "           -3.1555e-02, -3.3264e-02],\n",
       "          [-6.2500e-02,  1.3611e-01, -1.7444e-01,  ..., -1.5649e-01,\n",
       "           -3.1494e-02,  1.8286e-01],\n",
       "          [-1.8469e-01,  1.7639e-01, -4.1187e-01,  ..., -7.1411e-02,\n",
       "            6.7322e-02, -8.9111e-02],\n",
       "          ...,\n",
       "          [-1.6895e-01,  2.7222e-01, -2.8271e-01,  ..., -2.4765e-02,\n",
       "           -5.5542e-02, -2.8125e-01],\n",
       "          [-2.3132e-01,  2.4524e-01, -2.6953e-01,  ...,  8.8379e-02,\n",
       "            4.4983e-02, -3.4692e-01],\n",
       "          [-1.9653e-01,  3.2617e-01, -3.1567e-01,  ..., -3.3234e-02,\n",
       "           -8.3862e-02, -3.4717e-01]],\n",
       "\n",
       "         [[-1.3771e-03, -4.8340e-02,  2.3163e-02,  ...,  2.7191e-02,\n",
       "           -1.5404e-02, -5.8167e-02],\n",
       "          [-7.3608e-02, -2.6196e-01, -2.9297e-02,  ..., -1.4380e-01,\n",
       "            1.1786e-01, -1.0297e-01],\n",
       "          [-8.2520e-02, -1.2415e-01, -5.0140e-02,  ...,  1.8115e-01,\n",
       "            4.3884e-02, -1.8021e-02],\n",
       "          ...,\n",
       "          [-1.2103e-01,  3.0396e-01, -4.3793e-02,  ...,  6.9824e-02,\n",
       "           -3.1274e-01,  2.4792e-01],\n",
       "          [-1.2372e-01,  3.5889e-01, -5.0690e-02,  ...,  8.6670e-03,\n",
       "           -3.9233e-01,  1.8787e-01],\n",
       "          [-1.2061e-01,  2.6587e-01, -5.6366e-02,  ...,  6.0455e-02,\n",
       "           -3.3521e-01,  2.1741e-01]],\n",
       "\n",
       "         [[-1.1169e-02,  4.3060e-02,  1.1398e-02,  ...,  6.4453e-02,\n",
       "            5.4810e-02, -2.2537e-02],\n",
       "          [ 1.7737e-01,  1.8152e-01, -3.7671e-01,  ...,  1.7424e-03,\n",
       "            2.5464e-01,  6.8262e-01],\n",
       "          [ 1.4062e-01,  8.8501e-02, -8.5938e-02,  ...,  1.9543e-01,\n",
       "            3.2422e-01,  2.9175e-01],\n",
       "          ...,\n",
       "          [ 5.9424e-01, -2.4707e-01, -1.2866e-01,  ...,  4.9866e-02,\n",
       "           -3.3234e-02,  5.0830e-01],\n",
       "          [ 5.1318e-01, -3.3179e-01, -6.6467e-02,  ...,  9.2926e-03,\n",
       "           -1.0535e-01,  5.2637e-01],\n",
       "          [ 5.6641e-01, -2.9492e-01, -1.5466e-01,  ...,  4.0924e-02,\n",
       "           -3.5767e-02,  6.6504e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.9190e-02, -2.6642e-02,  7.7324e-03,  ...,  1.7252e-03,\n",
       "            4.5197e-02,  2.3926e-02],\n",
       "          [ 3.5864e-01,  6.2451e-01, -2.5220e-01,  ...,  5.7312e-02,\n",
       "            2.2437e-01,  2.9590e-01],\n",
       "          [ 9.8328e-02,  1.8860e-01,  1.6356e-03,  ...,  1.8701e-01,\n",
       "            1.5894e-01,  2.2437e-01],\n",
       "          ...,\n",
       "          [ 3.2959e-01,  1.7334e-02, -1.0022e-01,  ...,  1.5527e-01,\n",
       "           -1.1909e-02,  5.2979e-02],\n",
       "          [ 3.4326e-01,  1.0687e-01, -1.5393e-01,  ...,  8.6853e-02,\n",
       "           -2.0325e-01, -7.6233e-02],\n",
       "          [ 2.3914e-01,  7.8857e-02, -8.0933e-02,  ...,  1.3916e-01,\n",
       "            5.9357e-02,  5.6915e-02]],\n",
       "\n",
       "         [[ 1.4191e-02, -2.2766e-02,  1.0574e-02,  ...,  7.1030e-03,\n",
       "            3.6011e-02,  2.4017e-02],\n",
       "          [ 4.3610e-02, -1.1757e-02, -2.5360e-02,  ...,  3.1323e-01,\n",
       "            1.5161e-01, -1.3647e-01],\n",
       "          [ 1.8018e-01, -1.6626e-01, -5.1758e-02,  ...,  7.9956e-03,\n",
       "            5.4321e-02, -1.4938e-02],\n",
       "          ...,\n",
       "          [ 1.0388e-01, -1.3220e-01, -2.9716e-03,  ...,  8.6731e-02,\n",
       "           -3.0594e-02, -9.9304e-02],\n",
       "          [ 6.9458e-02, -1.2524e-01, -2.1149e-02,  ...,  8.0994e-02,\n",
       "           -1.7441e-02, -1.6614e-01],\n",
       "          [ 8.5632e-02, -1.1993e-01, -2.9297e-02,  ...,  7.2998e-02,\n",
       "            2.0721e-02, -1.2671e-01]],\n",
       "\n",
       "         [[-4.6143e-02, -4.9011e-02, -6.7711e-03,  ..., -2.7347e-04,\n",
       "           -3.6102e-02, -4.7684e-07],\n",
       "          [-1.4514e-01,  5.9998e-02,  4.0833e-02,  ...,  2.4277e-02,\n",
       "           -3.0908e-01,  2.9892e-02],\n",
       "          [-1.7969e-01, -3.7964e-02, -8.2703e-02,  ...,  2.2583e-01,\n",
       "           -1.1639e-01,  1.1725e-01],\n",
       "          ...,\n",
       "          [-2.6709e-01, -1.1969e-01, -1.7175e-01,  ...,  9.1431e-02,\n",
       "           -2.7856e-01,  2.2668e-01],\n",
       "          [-3.5205e-01, -1.7419e-01, -1.6199e-01,  ...,  9.7351e-02,\n",
       "           -2.2217e-01,  2.6416e-01],\n",
       "          [-2.7930e-01, -1.8469e-01, -1.6394e-01,  ...,  9.5398e-02,\n",
       "           -2.8247e-01,  2.0361e-01]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[-1.0788e-02,  2.4948e-02,  5.8985e-04,  ..., -7.2449e-02,\n",
       "           -5.4932e-02,  1.8628e-01],\n",
       "          [-1.3818e-01, -3.0420e-01,  1.0364e-01,  ..., -5.6934e-01,\n",
       "           -1.3757e-01, -4.9683e-02],\n",
       "          [-8.8623e-01, -4.0820e-01,  3.3545e-01,  ..., -2.4878e-01,\n",
       "            1.3892e-01, -2.0178e-01],\n",
       "          ...,\n",
       "          [-4.0527e-02,  2.2119e-01,  5.0586e-01,  ...,  1.5149e-01,\n",
       "            6.9043e-01,  1.2549e-01],\n",
       "          [-9.2480e-01,  3.7427e-01,  3.6670e-01,  ...,  1.6809e-01,\n",
       "            7.2949e-01,  3.1052e-03],\n",
       "          [-1.1299e+00,  2.8955e-01,  1.1047e-01,  ...,  2.4268e-01,\n",
       "            8.2715e-01,  7.4219e-02]],\n",
       "\n",
       "         [[-1.1328e-01, -2.0416e-02,  2.7359e-02,  ..., -3.5791e-01,\n",
       "            3.0835e-01,  1.8481e-01],\n",
       "          [ 4.3457e-02, -3.5864e-01,  6.6101e-02,  ...,  8.7109e-01,\n",
       "            4.7290e-01,  1.0918e+00],\n",
       "          [ 5.8838e-01, -1.0022e-01,  1.1969e-01,  ..., -6.7480e-01,\n",
       "            4.6826e-01,  1.2285e+00],\n",
       "          ...,\n",
       "          [ 5.8740e-01,  2.7344e-01, -3.6914e-01,  ...,  6.2305e-01,\n",
       "            3.6035e-01,  1.3125e+00],\n",
       "          [ 1.0020e+00, -3.4131e-01, -6.4062e-01,  ...,  9.4287e-01,\n",
       "            2.8857e-01,  1.4502e+00],\n",
       "          [ 3.7158e-01, -6.3379e-01, -4.2505e-01,  ...,  9.1992e-01,\n",
       "            3.1421e-01,  1.3691e+00]],\n",
       "\n",
       "         [[-1.7151e-01, -1.0797e-01,  2.9956e-01,  ...,  1.0342e+00,\n",
       "           -4.5166e-02,  6.5967e-01],\n",
       "          [ 7.9785e-01, -9.1357e-01,  2.2266e-01,  ...,  6.8506e-01,\n",
       "           -1.3525e+00,  3.1230e+00],\n",
       "          [ 1.4209e+00, -5.3076e-01, -6.7334e-01,  ...,  7.7539e-01,\n",
       "           -8.5742e-01,  3.0098e+00],\n",
       "          ...,\n",
       "          [ 7.8369e-02,  4.1870e-01,  2.4414e-02,  ..., -3.0029e-02,\n",
       "           -2.9590e-01,  2.5508e+00],\n",
       "          [ 9.3066e-01,  1.0371e+00, -3.4839e-01,  ...,  1.0907e-01,\n",
       "           -3.0664e-01,  2.6875e+00],\n",
       "          [ 7.2754e-01,  1.0156e+00, -6.6895e-01,  ...,  2.9028e-01,\n",
       "           -3.7256e-01,  2.6465e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.4363e-02,  1.5857e-01,  9.9854e-02,  ...,  5.5908e-01,\n",
       "            2.0251e-01, -9.1736e-02],\n",
       "          [-2.7490e-01, -9.9731e-02,  2.2412e-01,  ...,  2.4043e+00,\n",
       "            5.7129e-01, -1.4707e+00],\n",
       "          [-9.0210e-02,  3.5004e-02, -1.6113e-01,  ...,  1.1943e+00,\n",
       "            1.6650e-01, -5.1562e-01],\n",
       "          ...,\n",
       "          [ 8.5840e-01,  1.1902e-01,  8.2581e-02,  ...,  1.7695e+00,\n",
       "            2.0996e-01, -8.6768e-01],\n",
       "          [ 1.6479e-01,  3.3936e-01, -1.7883e-02,  ...,  1.9219e+00,\n",
       "            1.1633e-01, -8.6816e-01],\n",
       "          [-8.1055e-01,  1.4246e-01,  4.1809e-02,  ...,  1.7676e+00,\n",
       "            4.5013e-02, -8.2227e-01]],\n",
       "\n",
       "         [[-2.0044e-01, -1.1157e-01,  3.8239e-02,  ..., -1.0120e-01,\n",
       "            1.9958e-01, -4.8553e-02],\n",
       "          [ 1.2378e-01, -5.0879e-01, -1.5088e-01,  ...,  1.6809e-01,\n",
       "            6.7627e-01,  5.3864e-02],\n",
       "          [ 1.1191e+00,  3.7109e-01,  1.0941e-02,  ..., -6.3782e-02,\n",
       "            5.9570e-01,  4.7876e-01],\n",
       "          ...,\n",
       "          [-9.7168e-02,  4.1797e-01, -5.1709e-01,  ..., -1.5723e-01,\n",
       "            7.1924e-01,  3.0786e-01],\n",
       "          [ 9.9561e-01,  2.8540e-01, -1.9946e-01,  ..., -3.0640e-01,\n",
       "            6.6602e-01,  4.1943e-01],\n",
       "          [ 1.2715e+00, -1.7407e-01,  2.7441e-01,  ..., -6.6528e-02,\n",
       "            4.3335e-01,  4.2114e-01]],\n",
       "\n",
       "         [[ 2.5830e-01,  3.9215e-02,  3.9597e-03,  ..., -4.1199e-02,\n",
       "            1.0809e-01, -4.8584e-01],\n",
       "          [ 4.5166e-01, -2.7075e-01,  3.2275e-01,  ..., -2.8047e+00,\n",
       "            4.8438e-01, -2.0625e+00],\n",
       "          [-2.4121e-01, -2.6172e-01, -7.1716e-03,  ..., -2.2129e+00,\n",
       "            5.1025e-01, -1.8799e+00],\n",
       "          ...,\n",
       "          [ 2.1338e-01, -1.3086e-01, -1.4319e-01,  ..., -1.4805e+00,\n",
       "            4.9585e-01, -1.9658e+00],\n",
       "          [-7.9492e-01,  7.6465e-01, -4.1626e-02,  ..., -1.5322e+00,\n",
       "            2.6050e-01, -2.3145e+00],\n",
       "          [-9.1992e-01,  1.0586e+00,  2.2266e-01,  ..., -1.5332e+00,\n",
       "            6.7041e-01, -1.9443e+00]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[[ 5.8228e-02, -8.3780e-04,  1.8555e-02,  ..., -7.7271e-02,\n",
       "           -5.0659e-02,  6.7871e-02],\n",
       "          [ 1.0492e-01, -3.8086e-01,  7.9285e-02,  ..., -2.6367e-01,\n",
       "            6.8359e-02, -1.8628e-01],\n",
       "          [-2.5098e-01, -2.2241e-01,  6.0059e-02,  ..., -9.9060e-02,\n",
       "           -1.9238e-01,  2.6294e-01],\n",
       "          ...,\n",
       "          [-2.3132e-01, -6.1188e-03, -4.8004e-02,  ...,  8.1421e-02,\n",
       "           -1.7664e-01,  2.9175e-01],\n",
       "          [-1.7566e-01,  5.5199e-03, -2.1439e-02,  ...,  2.1973e-02,\n",
       "           -1.0382e-01,  3.0298e-01],\n",
       "          [-3.2690e-01,  4.1199e-02, -4.2114e-02,  ...,  3.9581e-02,\n",
       "           -1.3403e-01,  3.5132e-01]],\n",
       "\n",
       "         [[-7.9468e-02, -5.4871e-02, -6.4575e-02,  ...,  1.5552e-01,\n",
       "            7.5264e-03,  4.3732e-02],\n",
       "          [ 2.7084e-02, -3.3130e-01, -1.1749e-01,  ...,  4.2676e-01,\n",
       "            3.4180e-01,  6.7139e-02],\n",
       "          [-5.6445e-01, -2.0007e-01, -2.2827e-01,  ...,  3.0566e-01,\n",
       "            1.0608e-01,  2.2598e-02],\n",
       "          ...,\n",
       "          [-1.8896e-01, -1.0095e-01, -2.3889e-01,  ..., -6.9885e-02,\n",
       "            4.9854e-01,  2.8961e-02],\n",
       "          [-9.0210e-02, -1.0461e-01, -2.4463e-01,  ..., -4.1771e-03,\n",
       "            5.7861e-01,  8.3679e-02],\n",
       "          [-2.0056e-01, -9.5886e-02, -1.4319e-01,  ..., -1.4697e-01,\n",
       "            4.2090e-01,  3.2074e-02]],\n",
       "\n",
       "         [[ 1.5808e-02, -4.8798e-02, -4.2999e-02,  ...,  7.6965e-02,\n",
       "           -8.9355e-02, -2.4506e-02],\n",
       "          [-2.7368e-01, -4.2944e-01, -2.1497e-01,  ..., -2.1172e-03,\n",
       "            1.1792e-01, -3.8452e-01],\n",
       "          [-1.9458e-01, -1.4099e-01,  6.8298e-02,  ...,  2.0752e-02,\n",
       "           -2.9297e-01, -2.4805e-01],\n",
       "          ...,\n",
       "          [-3.0548e-02, -2.3499e-01, -6.3599e-02,  ...,  6.1005e-02,\n",
       "           -7.3975e-02,  2.2290e-01],\n",
       "          [ 4.9553e-03, -2.5024e-01, -1.0004e-01,  ...,  6.0425e-02,\n",
       "           -9.1309e-02,  3.1128e-01],\n",
       "          [-3.7048e-02, -2.2705e-01, -1.3037e-01,  ...,  1.4062e-01,\n",
       "           -1.3831e-01,  2.3376e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 6.4270e-02, -3.0869e-02, -4.5074e-02,  ..., -6.9031e-02,\n",
       "            3.0594e-03,  2.7752e-03],\n",
       "          [ 2.6221e-01, -2.4963e-01, -6.9275e-02,  ..., -7.7698e-02,\n",
       "            2.4426e-01, -1.5540e-01],\n",
       "          [ 1.4172e-01,  2.2110e-02,  1.6052e-01,  ..., -2.7051e-01,\n",
       "            1.1011e-01, -2.7871e-04],\n",
       "          ...,\n",
       "          [ 2.9272e-01, -8.0078e-02, -7.3303e-02,  ..., -2.2058e-01,\n",
       "           -2.9590e-01, -1.7175e-01],\n",
       "          [ 1.8860e-01, -1.3115e-02, -1.1066e-01,  ..., -2.1240e-01,\n",
       "           -3.5327e-01, -2.9663e-01],\n",
       "          [ 1.6443e-01, -9.3323e-02, -2.7359e-02,  ..., -1.9434e-01,\n",
       "           -3.4521e-01, -1.8335e-01]],\n",
       "\n",
       "         [[ 1.2815e-04, -1.2183e-01, -1.3290e-02,  ..., -4.4617e-02,\n",
       "           -3.8624e-04,  3.7231e-02],\n",
       "          [ 8.9966e-02, -3.5815e-01, -5.0995e-02,  ..., -5.4639e-01,\n",
       "           -1.1914e-01,  1.5662e-01],\n",
       "          [ 2.2852e-01, -1.1700e-01,  1.0199e-01,  ..., -2.2754e-01,\n",
       "            1.1725e-01,  1.3989e-01],\n",
       "          ...,\n",
       "          [ 2.0972e-01, -1.4429e-01,  4.2676e-01,  ...,  7.3547e-02,\n",
       "           -9.7656e-02, -1.8585e-02],\n",
       "          [ 2.0410e-01, -1.2317e-01,  5.3906e-01,  ...,  1.1804e-01,\n",
       "           -9.2590e-02, -3.6564e-03],\n",
       "          [ 3.2251e-01, -1.3147e-01,  4.7388e-01,  ...,  6.2500e-02,\n",
       "           -4.7729e-02, -1.9440e-02]],\n",
       "\n",
       "         [[-6.7810e-02, -1.2659e-01, -2.7786e-02,  ...,  1.2244e-01,\n",
       "           -7.8491e-02,  2.5162e-02],\n",
       "          [-1.6638e-01, -2.0801e-01, -5.3760e-01,  ...,  5.4108e-02,\n",
       "           -1.5930e-01, -8.7402e-02],\n",
       "          [ 8.3801e-02, -1.9458e-01, -3.2373e-01,  ...,  1.2466e-02,\n",
       "           -2.1655e-01, -8.7708e-02],\n",
       "          ...,\n",
       "          [ 1.5686e-01, -5.1697e-02, -3.0176e-01,  ..., -1.9592e-01,\n",
       "           -6.6528e-02,  8.0688e-02],\n",
       "          [ 1.2756e-01, -5.4016e-02, -2.8003e-01,  ..., -1.2250e-01,\n",
       "           -6.7505e-02,  1.1115e-01],\n",
       "          [ 1.3208e-01, -9.3933e-02, -3.3496e-01,  ..., -2.1216e-01,\n",
       "           -1.0443e-01,  1.2146e-01]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[-0.3108, -0.1038, -0.0456,  ..., -0.4150, -1.0859, -0.5698],\n",
       "          [ 0.0349, -0.1272,  0.0386,  ..., -0.2128, -0.9707, -1.8232],\n",
       "          [ 0.2561,  0.4434,  0.1113,  ..., -0.3369, -0.5698, -1.7705],\n",
       "          ...,\n",
       "          [-0.1042, -0.2715,  0.9199,  ...,  0.1040, -0.0327, -1.8652],\n",
       "          [-0.1638, -0.8418,  0.4946,  ...,  0.3032, -0.1110, -2.0078],\n",
       "          [-0.3789, -0.6338, -0.2107,  ...,  0.4773, -0.2146, -2.0215]],\n",
       "\n",
       "         [[-0.0529,  0.2201, -0.1802,  ...,  0.1951, -0.2028,  0.3145],\n",
       "          [ 0.6465,  0.0952,  0.4827,  ..., -2.7676,  0.7266,  1.5615],\n",
       "          [ 0.4841, -0.2666,  0.4133,  ..., -2.2539,  1.2158,  1.6699],\n",
       "          ...,\n",
       "          [ 0.5879, -0.3110, -0.2971,  ..., -3.2539,  0.3181,  1.7793],\n",
       "          [ 1.0977,  0.1951, -0.1334,  ..., -3.5723,  0.2107,  1.7471],\n",
       "          [ 0.4795,  0.5728,  0.3550,  ..., -3.5684,  0.4062,  1.6094]],\n",
       "\n",
       "         [[ 0.0831,  0.0232, -0.2480,  ...,  0.4565,  0.1997, -0.1622],\n",
       "          [ 0.0895, -0.0378, -0.6909,  ...,  0.5352,  0.1027, -0.0722],\n",
       "          [-0.3145,  0.2927,  0.0967,  ..., -0.0689, -0.2260,  0.0283],\n",
       "          ...,\n",
       "          [-0.4797, -0.4072, -0.8398,  ...,  1.3174, -0.1971, -0.3906],\n",
       "          [-1.2412, -0.4375, -0.3950,  ...,  1.3594, -0.3223, -0.5322],\n",
       "          [-0.6865, -0.1503,  0.3525,  ...,  1.2803, -0.2026, -0.5059]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0943, -0.0842,  0.2050,  ...,  0.1356, -0.0180,  0.1604],\n",
       "          [ 0.0341,  0.2881,  0.1707,  ...,  0.0762, -0.8599,  0.3276],\n",
       "          [-0.2563,  0.5693,  0.1332,  ...,  0.4812, -1.2275,  0.1042],\n",
       "          ...,\n",
       "          [-0.1721, -0.2256,  0.0479,  ..., -0.5205, -0.3645,  0.1853],\n",
       "          [ 0.3711, -0.8208,  0.0634,  ..., -0.6221, -0.1228,  0.3215],\n",
       "          [ 0.5742, -0.9453,  0.1317,  ..., -0.6094, -0.3020,  0.0131]],\n",
       "\n",
       "         [[-0.1360, -0.0929,  0.0845,  ..., -0.2656, -0.2593, -0.1298],\n",
       "          [-0.1611, -0.0144, -0.2251,  ...,  1.9229, -0.7573, -5.1719],\n",
       "          [-0.0841,  0.0363,  0.0651,  ...,  1.4551,  0.4001, -3.8145],\n",
       "          ...,\n",
       "          [-0.3101,  0.1770, -0.0279,  ..., -0.6509, -1.1699, -1.5703],\n",
       "          [-0.0506,  0.2971, -0.2661,  ..., -0.7075, -1.4346, -1.6328],\n",
       "          [ 0.3225,  0.1666, -0.3250,  ..., -0.0966, -1.2549, -1.5928]],\n",
       "\n",
       "         [[-0.0885,  0.1627, -0.0574,  ..., -0.2498, -0.2834, -0.0399],\n",
       "          [-0.2190,  0.4468, -0.8477,  ..., -0.8433,  0.3298, -1.3789],\n",
       "          [-0.2896,  0.1545, -0.0834,  ..., -0.5098, -0.9829, -0.9351],\n",
       "          ...,\n",
       "          [ 0.3184, -0.3621, -0.7764,  ..., -0.5630, -1.1992,  0.1726],\n",
       "          [ 0.5693, -0.1804, -0.7578,  ..., -0.6641, -1.2451,  0.2134],\n",
       "          [ 0.2905,  0.1298, -0.2258,  ..., -0.4536, -1.3330,  0.2629]]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[[ 0.0869, -0.0013,  0.0818,  ...,  0.0491,  0.0790,  0.1404],\n",
       "          [ 0.3970,  0.0439,  0.5654,  ..., -0.1387,  0.0300,  0.1888],\n",
       "          [ 0.2500, -0.1232,  0.4250,  ...,  0.2729,  0.1030,  0.6479],\n",
       "          ...,\n",
       "          [ 0.7114, -0.1749,  0.0969,  ...,  0.5117,  0.6494,  0.5840],\n",
       "          [ 0.7617, -0.1111,  0.0874,  ...,  0.5903,  0.6177,  0.5459],\n",
       "          [ 0.7031, -0.1400,  0.1148,  ...,  0.5024,  0.6646,  0.6714]],\n",
       "\n",
       "         [[-0.0510, -0.0280,  0.0371,  ...,  0.0270, -0.0094, -0.0511],\n",
       "          [ 0.0099, -0.2155, -0.0106,  ..., -0.3120, -0.1238, -0.1555],\n",
       "          [ 0.1169, -0.1575, -0.0083,  ..., -0.0825, -0.1337, -0.1606],\n",
       "          ...,\n",
       "          [ 0.3525, -0.3567, -0.2224,  ...,  0.0792, -0.1209, -0.1082],\n",
       "          [ 0.3362, -0.4189, -0.2424,  ...,  0.0286, -0.1552, -0.0771],\n",
       "          [ 0.3467, -0.4563, -0.2878,  ...,  0.1111, -0.1404, -0.1544]],\n",
       "\n",
       "         [[ 0.0221,  0.1348,  0.1934,  ..., -0.2485,  0.1377,  0.0964],\n",
       "          [-0.1064,  0.5322,  0.1917,  ..., -0.1825,  0.0330, -0.0913],\n",
       "          [-0.3591,  0.6489,  0.4053,  ..., -0.7158,  0.3220, -0.1281],\n",
       "          ...,\n",
       "          [ 0.1218,  0.4155,  0.4941,  ..., -0.5352,  0.1691,  0.3054],\n",
       "          [ 0.1267,  0.2471,  0.4043,  ..., -0.4248,  0.0638,  0.3772],\n",
       "          [ 0.0870,  0.3657,  0.4221,  ..., -0.6250,  0.1666,  0.3379]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1103,  0.0275, -0.0185,  ..., -0.0280,  0.0155, -0.0472],\n",
       "          [-0.4817,  0.2181,  0.1777,  ..., -0.2004,  0.1846,  0.1131],\n",
       "          [-0.1351,  0.1034,  0.2489,  ..., -0.3496, -0.0271, -0.1349],\n",
       "          ...,\n",
       "          [-0.2385, -0.2031,  0.2725,  ..., -0.2344, -0.3198,  0.0986],\n",
       "          [-0.2166, -0.1691,  0.2482,  ..., -0.2415, -0.3577,  0.1560],\n",
       "          [-0.2296, -0.2225,  0.2216,  ..., -0.2551, -0.3135,  0.1682]],\n",
       "\n",
       "         [[-0.0008, -0.0327, -0.0257,  ..., -0.0369,  0.1080, -0.0677],\n",
       "          [ 0.2773, -0.0847,  0.0819,  ..., -0.1842, -0.0059, -0.2096],\n",
       "          [ 0.0879, -0.1270,  0.1769,  ..., -0.3479,  0.0448, -0.1895],\n",
       "          ...,\n",
       "          [ 0.1288, -0.1440, -0.1853,  ..., -0.1260,  0.0122, -0.2358],\n",
       "          [ 0.1832, -0.0923, -0.2017,  ..., -0.0791, -0.0077, -0.2374],\n",
       "          [ 0.1597, -0.1516, -0.1907,  ..., -0.0977,  0.0228, -0.2448]],\n",
       "\n",
       "         [[-0.0731,  0.0249,  0.0258,  ...,  0.0122,  0.0214,  0.0380],\n",
       "          [ 0.0851,  0.2487,  0.2358,  ...,  0.2388,  0.1283,  0.6421],\n",
       "          [ 0.0790,  0.2115,  0.1012,  ...,  0.2072, -0.1564,  0.4216],\n",
       "          ...,\n",
       "          [ 0.4065,  0.1140,  0.1719,  ...,  0.5083, -0.5327,  0.5186],\n",
       "          [ 0.3489,  0.2335,  0.1171,  ...,  0.5010, -0.5063,  0.4988],\n",
       "          [ 0.4851,  0.0956,  0.1654,  ...,  0.4866, -0.5254,  0.4609]]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<TransposeBackward0>)), (tensor([[[[-2.8516e-01, -2.2363e-01,  1.3171e-01,  ...,  3.3765e-01,\n",
       "            3.0811e-01,  6.6284e-02],\n",
       "          [-2.2144e-01, -7.3193e-01, -1.5259e-01,  ..., -1.6785e-01,\n",
       "            6.0791e-01,  5.6641e-01],\n",
       "          [-1.9043e-02,  8.3374e-02, -6.1230e-01,  ..., -4.0820e-01,\n",
       "            7.4219e-01,  6.6064e-01],\n",
       "          ...,\n",
       "          [-9.5020e-01,  5.4932e-01, -2.3267e-01,  ...,  9.1980e-02,\n",
       "            4.6045e-01, -5.6348e-01],\n",
       "          [-4.2944e-01,  2.4194e-01, -6.0059e-01,  ...,  8.7952e-02,\n",
       "            5.5469e-01, -4.9951e-01],\n",
       "          [ 6.4941e-01, -2.4524e-01, -4.9756e-01,  ...,  1.9470e-01,\n",
       "            4.3481e-01, -4.8779e-01]],\n",
       "\n",
       "         [[ 2.5708e-01,  2.6782e-01,  2.8784e-01,  ..., -2.3242e-01,\n",
       "           -9.0714e-03,  1.0382e-01],\n",
       "          [-2.4072e-01, -9.1211e-01,  1.4023e+00,  ..., -6.3135e-01,\n",
       "            9.3555e-01,  3.2373e-01],\n",
       "          [ 5.1178e-02, -1.5771e+00,  8.0762e-01,  ..., -5.5225e-01,\n",
       "            5.5786e-02,  5.2881e-01],\n",
       "          ...,\n",
       "          [-9.0332e-03, -3.9331e-01,  1.2539e+00,  ..., -5.2887e-02,\n",
       "           -9.3323e-02, -4.5874e-01],\n",
       "          [-3.6475e-01,  5.6299e-01,  8.5791e-01,  ..., -1.9714e-02,\n",
       "           -1.8262e-01, -5.1123e-01],\n",
       "          [-3.3936e-01,  1.2070e+00, -1.5894e-01,  ..., -1.5955e-01,\n",
       "           -2.0276e-01, -4.9854e-01]],\n",
       "\n",
       "         [[-1.0114e-01, -4.6265e-02,  2.1545e-01,  ...,  4.2920e-01,\n",
       "            4.3896e-01, -4.1260e-02],\n",
       "          [-2.4121e-01,  4.1577e-01,  3.1348e-01,  ...,  5.4297e-01,\n",
       "            1.4941e+00,  9.6387e-01],\n",
       "          [ 2.1729e-02,  2.0679e-01,  2.7026e-01,  ...,  1.3750e+00,\n",
       "            1.2529e+00,  6.2012e-01],\n",
       "          ...,\n",
       "          [-4.7046e-01,  2.2595e-01,  7.8223e-01,  ...,  1.1406e+00,\n",
       "            1.6406e+00,  1.2988e+00],\n",
       "          [ 7.3792e-02,  2.2644e-01,  3.2715e-01,  ...,  1.1426e+00,\n",
       "            1.8525e+00,  1.2744e+00],\n",
       "          [ 5.0000e-01,  1.0699e-01, -3.3667e-01,  ...,  1.2256e+00,\n",
       "            1.8691e+00,  1.2891e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.2144e-01, -2.0410e-01,  6.0791e-02,  ..., -2.0294e-02,\n",
       "            4.5532e-02, -2.2913e-01],\n",
       "          [ 1.5698e-01, -5.2588e-01, -1.6357e-01,  ...,  3.3032e-01,\n",
       "            1.4814e+00, -1.4297e+00],\n",
       "          [ 1.4307e-01, -2.1289e-01,  1.6028e-01,  ...,  3.5278e-01,\n",
       "            9.7461e-01, -1.0664e+00],\n",
       "          ...,\n",
       "          [ 9.3799e-01, -2.4445e-02,  3.7793e-01,  ...,  4.2236e-01,\n",
       "            1.3018e+00, -9.1357e-01],\n",
       "          [ 1.0342e+00, -1.6248e-01, -5.2246e-02,  ...,  4.6802e-01,\n",
       "            1.3154e+00, -7.7051e-01],\n",
       "          [-1.3135e-01,  6.3721e-02, -5.3125e-01,  ...,  4.4043e-01,\n",
       "            1.5244e+00, -6.9727e-01]],\n",
       "\n",
       "         [[ 2.4146e-01,  9.1187e-02,  6.4430e-03,  ...,  1.4326e+00,\n",
       "            1.3062e-01, -5.5371e-01],\n",
       "          [-5.3662e-01, -4.4189e-02, -7.5732e-01,  ...,  3.1699e+00,\n",
       "           -4.8682e-01, -8.3936e-01],\n",
       "          [-4.8511e-01,  2.1606e-02, -3.5742e-01,  ...,  3.5820e+00,\n",
       "            8.5645e-01, -1.2549e+00],\n",
       "          ...,\n",
       "          [-6.9336e-02, -6.3721e-02, -8.3936e-01,  ...,  3.9160e+00,\n",
       "            3.9673e-03,  6.1493e-02],\n",
       "          [-7.8809e-01, -3.9551e-01, -7.1191e-01,  ...,  3.8984e+00,\n",
       "           -1.4648e-01,  7.8308e-02],\n",
       "          [-7.3340e-01, -4.7046e-01, -6.5918e-03,  ...,  4.1250e+00,\n",
       "           -7.9712e-02, -8.4473e-02]],\n",
       "\n",
       "         [[ 3.9844e-01,  4.5685e-02, -2.1851e-01,  ...,  8.4180e-01,\n",
       "           -2.1045e-01,  7.2571e-02],\n",
       "          [-2.5342e-01,  3.6230e-01, -4.3799e-01,  ...,  5.2383e+00,\n",
       "            3.5181e-01,  4.1250e+00],\n",
       "          [-5.0977e-01,  5.2344e-01,  4.3945e-02,  ...,  3.5996e+00,\n",
       "            1.0137e+00,  1.7598e+00],\n",
       "          ...,\n",
       "          [-2.8687e-01, -1.4307e-01,  3.4241e-02,  ...,  4.8633e+00,\n",
       "            2.2480e+00, -6.2866e-03],\n",
       "          [-2.5708e-01, -2.6831e-01,  8.2214e-02,  ...,  5.4258e+00,\n",
       "            1.9844e+00,  2.2559e-01],\n",
       "          [-9.0393e-02, -2.5049e-01,  2.8149e-01,  ...,  4.9492e+00,\n",
       "            1.8154e+00,  1.9727e-01]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[[ 0.3037,  0.0965, -0.2283,  ...,  0.0676, -0.1548,  0.0082],\n",
       "          [ 0.5234, -0.1736, -0.2223,  ...,  0.0583, -0.1165, -0.1392],\n",
       "          [ 0.7671, -0.3125, -0.2605,  ..., -0.0544, -0.3318, -0.0929],\n",
       "          ...,\n",
       "          [ 0.5068, -0.1176, -0.3835,  ..., -0.0214,  0.0528, -0.1102],\n",
       "          [ 0.5557, -0.1174, -0.4128,  ..., -0.0421,  0.1335, -0.1093],\n",
       "          [ 0.5410, -0.0386, -0.4397,  ..., -0.0221,  0.0856, -0.1295]],\n",
       "\n",
       "         [[-0.1409, -0.1024,  0.0962,  ..., -0.0207, -0.0545,  0.0824],\n",
       "          [-0.6982,  0.0296,  0.5059,  ...,  0.1483,  0.9365,  0.3457],\n",
       "          [-0.0393,  0.0925,  0.5195,  ...,  0.1792,  0.5078,  0.2876],\n",
       "          ...,\n",
       "          [-0.6338, -0.7905,  0.4036,  ..., -0.1461,  0.5161, -0.4812],\n",
       "          [-0.6465, -0.8071,  0.2925,  ..., -0.0745,  0.3540, -0.5562],\n",
       "          [-0.5503, -0.7026,  0.3757,  ..., -0.0699,  0.5254, -0.4573]],\n",
       "\n",
       "         [[ 0.0732, -0.0432, -0.0538,  ..., -0.0202, -0.1489,  0.0954],\n",
       "          [ 0.0956,  0.0109, -0.1254,  ..., -0.0191, -0.2676,  0.2578],\n",
       "          [ 0.0043,  0.2532,  0.0166,  ...,  0.3560,  0.0626,  0.4644],\n",
       "          ...,\n",
       "          [-0.0363,  0.1262,  0.1061,  ...,  0.1407, -0.1783,  0.3208],\n",
       "          [-0.0235,  0.1139,  0.1414,  ...,  0.1571, -0.1888,  0.3406],\n",
       "          [-0.0517,  0.1508,  0.0944,  ...,  0.1495, -0.1578,  0.3521]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0662,  0.0153, -0.0356,  ...,  0.0352, -0.1093,  0.0585],\n",
       "          [-0.0107, -0.1980, -0.2338,  ...,  0.1802, -0.1674,  0.3293],\n",
       "          [ 0.2019, -0.0657,  0.0136,  ...,  0.1333, -0.2313,  0.3794],\n",
       "          ...,\n",
       "          [-0.0558, -0.0527,  0.1849,  ...,  0.1299, -0.0587,  0.1204],\n",
       "          [-0.0979, -0.0246,  0.2085,  ...,  0.0659, -0.0242,  0.1453],\n",
       "          [-0.0677, -0.0237,  0.2039,  ...,  0.0236, -0.0523,  0.0838]],\n",
       "\n",
       "         [[ 0.0728, -0.0592, -0.0026,  ...,  0.0043, -0.1263, -0.0527],\n",
       "          [ 0.0962,  0.0969,  0.0427,  ...,  0.0021,  0.1864,  0.0850],\n",
       "          [ 0.0511, -0.1149, -0.1265,  ..., -0.0467, -0.0777, -0.2468],\n",
       "          ...,\n",
       "          [ 0.1925,  0.3379,  0.0224,  ..., -0.1414,  0.3215, -0.0923],\n",
       "          [ 0.0982,  0.3140,  0.0057,  ..., -0.0926,  0.2469, -0.0820],\n",
       "          [ 0.1982,  0.2434, -0.0267,  ..., -0.1724,  0.2654, -0.0577]],\n",
       "\n",
       "         [[-0.0344,  0.1656,  0.1305,  ..., -0.1476, -0.0133, -0.0951],\n",
       "          [ 0.1078,  0.1121, -0.0578,  ...,  0.1970,  0.2046, -0.4148],\n",
       "          [ 0.3584,  0.3340,  0.0481,  ...,  0.0979,  0.0408, -0.6211],\n",
       "          ...,\n",
       "          [ 0.0624, -0.0529,  0.2375,  ..., -0.1633,  0.0707, -0.3979],\n",
       "          [ 0.0792, -0.0392,  0.2974,  ..., -0.2104,  0.0146, -0.3611],\n",
       "          [ 0.0406, -0.1355,  0.2147,  ..., -0.1444,  0.0605, -0.3816]]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<TransposeBackward0>)), (tensor([[[[ 2.4231e-01, -1.0352e-01, -1.1829e-01,  ...,  4.6216e-01,\n",
       "           -2.2339e-01,  5.5664e-01],\n",
       "          [-2.6514e-01,  1.8774e-01,  3.5400e-03,  ..., -8.7204e-03,\n",
       "           -2.4707e+00, -2.7588e-02],\n",
       "          [-2.0105e-01, -5.3375e-02,  1.8250e-02,  ...,  6.3623e-01,\n",
       "           -1.3770e+00,  7.7002e-01],\n",
       "          ...,\n",
       "          [-4.9731e-01, -4.5728e-01,  3.9990e-01,  ..., -1.0303e-01,\n",
       "           -1.7305e+00,  1.4001e-01],\n",
       "          [-6.8555e-01,  7.9163e-02,  1.8335e-01,  ..., -1.1884e-01,\n",
       "           -1.7852e+00, -2.8458e-03],\n",
       "          [-1.6345e-01,  4.7412e-01, -8.5815e-02,  ..., -3.2690e-01,\n",
       "           -1.6250e+00,  2.3682e-01]],\n",
       "\n",
       "         [[-1.1340e-01,  2.0740e-01, -1.7932e-01,  ...,  6.9641e-02,\n",
       "            1.7297e-01,  7.5836e-03],\n",
       "          [-3.9307e-01,  3.2617e-01, -7.1729e-01,  ..., -7.9541e-01,\n",
       "            1.7812e+00, -7.5928e-01],\n",
       "          [ 3.2324e-01,  4.1846e-01,  2.1790e-02,  ..., -1.3320e+00,\n",
       "            1.5723e+00, -8.9160e-01],\n",
       "          ...,\n",
       "          [ 1.4856e-01, -1.1389e-01, -5.3125e-01,  ..., -7.5977e-01,\n",
       "            1.8770e+00, -1.5469e+00],\n",
       "          [ 3.1921e-02, -5.5859e-01, -1.4001e-01,  ..., -9.5410e-01,\n",
       "            1.9180e+00, -1.5518e+00],\n",
       "          [-3.6926e-02, -3.4326e-01,  1.7163e-01,  ..., -1.0283e+00,\n",
       "            1.9473e+00, -1.6025e+00]],\n",
       "\n",
       "         [[-2.2510e-01, -2.5342e-01,  3.5187e-02,  ...,  5.1025e-01,\n",
       "           -9.3079e-02,  2.2363e-01],\n",
       "          [-2.7710e-01, -8.1006e-01,  5.6836e-01,  ...,  1.4150e+00,\n",
       "           -9.8535e-01, -8.8623e-02],\n",
       "          [-1.6174e-02, -1.1383e-01,  2.6074e-01,  ...,  7.2998e-01,\n",
       "           -1.1055e+00, -2.3828e-01],\n",
       "          ...,\n",
       "          [ 3.9502e-01,  9.0381e-01,  6.1133e-01,  ...,  1.1504e+00,\n",
       "           -8.1543e-01, -3.2861e-01],\n",
       "          [ 5.2344e-01,  7.2852e-01, -1.9653e-02,  ...,  1.1758e+00,\n",
       "           -6.7871e-01, -3.4790e-01],\n",
       "          [-9.7656e-03, -1.3379e-01, -4.5215e-01,  ...,  9.5752e-01,\n",
       "           -9.0186e-01, -5.0781e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.4036e-01, -2.0154e-01, -6.1493e-02,  ...,  1.4905e-01,\n",
       "           -3.7201e-02,  1.7358e-01],\n",
       "          [ 3.9258e-01, -4.9316e-01, -3.4717e-01,  ..., -3.4027e-02,\n",
       "            3.7183e-01,  3.0005e-01],\n",
       "          [-4.5752e-01,  4.8779e-01,  2.0483e-01,  ..., -3.3423e-01,\n",
       "           -2.0459e-01, -5.4736e-01],\n",
       "          ...,\n",
       "          [-3.1592e-01,  2.6147e-01, -7.2363e-01,  ..., -4.9438e-01,\n",
       "            7.1777e-02,  1.3135e-01],\n",
       "          [-3.5278e-01,  6.0254e-01,  1.5662e-01,  ..., -4.5435e-01,\n",
       "            3.1519e-01,  2.3877e-01],\n",
       "          [ 1.1829e-01,  5.0391e-01,  8.6523e-01,  ..., -7.1533e-01,\n",
       "            2.6685e-01,  2.0370e-02]],\n",
       "\n",
       "         [[-5.9723e-02,  2.7246e-01,  2.1606e-01,  ...,  1.1615e-01,\n",
       "            3.6597e-01,  9.7839e-02],\n",
       "          [ 8.4570e-01, -7.4829e-02, -1.0803e-01,  ...,  5.7080e-01,\n",
       "            2.7881e-01,  1.6094e+00],\n",
       "          [ 4.8169e-01, -2.6025e-01, -4.8950e-01,  ...,  6.5247e-02,\n",
       "            8.1494e-01,  5.4639e-01],\n",
       "          ...,\n",
       "          [-3.4668e-01, -1.6724e-01, -4.5410e-01,  ..., -5.4230e-02,\n",
       "           -2.6660e-01,  1.1484e+00],\n",
       "          [-1.9897e-02, -2.4829e-01, -4.4189e-01,  ..., -4.3640e-02,\n",
       "           -2.2681e-01,  9.5898e-01],\n",
       "          [ 5.5469e-01, -1.0303e-01, -5.9814e-03,  ..., -2.4426e-01,\n",
       "           -3.3521e-01,  1.0342e+00]],\n",
       "\n",
       "         [[ 2.3938e-01,  1.9775e-02,  4.7424e-02,  ..., -6.4697e-01,\n",
       "           -4.4556e-01, -3.0664e-01],\n",
       "          [ 4.4482e-01,  9.7656e-04, -2.2961e-01,  ..., -4.2031e+00,\n",
       "           -1.4343e-02, -1.4170e+00],\n",
       "          [ 3.7598e-02,  1.2543e-02,  8.5327e-02,  ..., -3.6562e+00,\n",
       "           -8.6182e-01, -8.7842e-01],\n",
       "          ...,\n",
       "          [ 5.7031e-01, -2.5049e-01,  2.1591e-02,  ..., -4.5195e+00,\n",
       "           -1.4121e+00, -2.8359e+00],\n",
       "          [-2.2766e-01, -2.7979e-01, -1.7319e-02,  ..., -4.9023e+00,\n",
       "           -1.0938e+00, -2.7207e+00],\n",
       "          [-6.6895e-01, -1.0083e-01, -2.5543e-02,  ..., -4.6562e+00,\n",
       "           -1.0547e+00, -2.2930e+00]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[[ 2.7298e-02,  9.2529e-02,  7.5378e-02,  ...,  7.7515e-02,\n",
       "           -2.0557e-01,  1.9226e-02],\n",
       "          [-3.5376e-01,  3.0322e-01, -8.8989e-02,  ..., -1.1467e-02,\n",
       "           -3.5864e-01, -6.0986e-01],\n",
       "          [-2.0190e-01,  4.4629e-01,  8.9417e-03,  ..., -3.5675e-02,\n",
       "           -3.8110e-01, -1.2103e-01],\n",
       "          ...,\n",
       "          [ 5.0732e-01,  4.9390e-01,  1.8384e-01,  ..., -9.9976e-02,\n",
       "           -1.8262e-01,  7.4524e-02],\n",
       "          [ 4.9927e-01,  4.1040e-01,  1.6199e-01,  ..., -8.6914e-02,\n",
       "           -1.3501e-01,  1.5732e-02],\n",
       "          [ 4.9365e-01,  4.6582e-01,  1.0858e-01,  ..., -1.0406e-01,\n",
       "           -1.6675e-01,  5.2246e-02]],\n",
       "\n",
       "         [[-6.7993e-02,  5.2032e-02, -3.6346e-02,  ..., -1.3806e-01,\n",
       "           -6.9153e-02, -1.3260e-02],\n",
       "          [-2.2900e-01, -1.0205e-01, -7.6294e-02,  ...,  5.9766e-01,\n",
       "           -2.7734e-01,  2.5098e-01],\n",
       "          [-1.9629e-01, -1.5430e-01, -8.3679e-02,  ...,  3.0688e-01,\n",
       "           -2.2827e-01,  3.6865e-01],\n",
       "          ...,\n",
       "          [-1.1682e-01, -2.6270e-01, -4.3359e-01,  ...,  3.9941e-01,\n",
       "           -1.2292e-01,  3.3234e-02],\n",
       "          [-1.1163e-01, -2.4170e-01, -4.2383e-01,  ...,  4.0527e-01,\n",
       "           -1.4771e-01, -2.1815e-04],\n",
       "          [-7.0618e-02, -2.2461e-01, -4.3774e-01,  ...,  3.9844e-01,\n",
       "           -1.0693e-01, -2.3010e-02]],\n",
       "\n",
       "         [[-5.1422e-02, -5.5603e-02,  1.2585e-01,  ..., -1.2622e-01,\n",
       "           -1.2598e-01, -3.8544e-02],\n",
       "          [-2.4756e-01, -2.9932e-01,  4.7803e-01,  ..., -2.5360e-02,\n",
       "           -2.2925e-01, -1.2115e-01],\n",
       "          [ 1.2598e-01, -9.5276e-02,  1.3245e-01,  ...,  6.1401e-02,\n",
       "           -2.2607e-01, -8.8806e-02],\n",
       "          ...,\n",
       "          [-1.2292e-01, -2.1301e-01,  3.4692e-01,  ..., -2.6465e-01,\n",
       "           -2.8442e-01, -5.1819e-02],\n",
       "          [-1.5063e-01, -1.9861e-01,  2.8906e-01,  ..., -3.5791e-01,\n",
       "           -2.6782e-01, -1.0431e-01],\n",
       "          [-1.2286e-01, -1.1859e-01,  3.5596e-01,  ..., -2.7979e-01,\n",
       "           -3.1250e-01, -2.3560e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.6255e-02, -1.5405e-01, -1.0483e-02,  ...,  3.2349e-03,\n",
       "            7.9163e-02,  2.7969e-02],\n",
       "          [-1.4233e-01, -1.9519e-01, -1.5881e-01,  ..., -1.0834e-01,\n",
       "            3.3295e-02, -1.9861e-01],\n",
       "          [-1.9165e-01, -3.8818e-01, -1.4343e-02,  ..., -2.5464e-01,\n",
       "           -1.9495e-01,  9.9670e-02],\n",
       "          ...,\n",
       "          [-2.4002e-02, -3.0298e-01,  5.0049e-02,  ..., -1.3843e-01,\n",
       "            1.6678e-02,  1.0114e-01],\n",
       "          [ 3.2196e-02, -2.7295e-01,  6.2561e-02,  ..., -1.1023e-01,\n",
       "            7.0984e-02,  9.0637e-02],\n",
       "          [-3.4241e-02, -2.9077e-01,  5.3497e-02,  ..., -1.7615e-01,\n",
       "            6.1493e-02,  1.1316e-01]],\n",
       "\n",
       "         [[-6.3477e-02,  1.7273e-02,  6.5308e-02,  ...,  2.3621e-02,\n",
       "           -3.6865e-02,  7.0679e-02],\n",
       "          [-2.3880e-02,  2.4146e-01,  2.0044e-01,  ..., -4.1675e-01,\n",
       "            1.0490e-02,  9.1125e-02],\n",
       "          [ 9.5886e-02,  9.5337e-02,  2.2607e-01,  ..., -1.4087e-01,\n",
       "           -7.5867e-02,  2.2009e-01],\n",
       "          ...,\n",
       "          [ 2.9114e-02, -2.9221e-02,  4.1211e-01,  ..., -3.6426e-01,\n",
       "            1.6687e-01, -9.9121e-02],\n",
       "          [-3.2592e-04, -1.4633e-02,  4.2212e-01,  ..., -4.0381e-01,\n",
       "            1.5808e-01, -1.1810e-01],\n",
       "          [ 3.9734e-02,  4.8553e-02,  4.5093e-01,  ..., -3.8867e-01,\n",
       "            2.3438e-01, -1.4124e-01]],\n",
       "\n",
       "         [[ 5.7709e-02, -1.2866e-01, -8.5754e-02,  ...,  5.6671e-02,\n",
       "           -1.3037e-01, -2.1851e-02],\n",
       "          [ 2.2864e-01, -7.3425e-02, -5.7422e-01,  ..., -4.5044e-02,\n",
       "            1.0063e-02,  1.2415e-01],\n",
       "          [ 2.5708e-01,  1.4336e-02, -2.9663e-01,  ...,  1.8372e-01,\n",
       "           -1.0834e-01,  1.0925e-01],\n",
       "          ...,\n",
       "          [-7.5035e-03,  2.1631e-01, -3.1250e-01,  ...,  1.4114e-02,\n",
       "           -3.4302e-01, -1.9153e-01],\n",
       "          [-1.1584e-01,  1.2054e-01, -3.3496e-01,  ...,  1.0803e-01,\n",
       "           -3.3276e-01, -6.8909e-02],\n",
       "          [-8.6731e-02,  1.8665e-01, -3.0688e-01,  ...,  6.3293e-02,\n",
       "           -3.2568e-01, -1.7737e-01]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[-3.6438e-02, -1.1627e-01, -2.5977e-01,  ...,  3.3936e-01,\n",
       "           -4.9829e-01, -1.8047e+00],\n",
       "          [ 1.8524e-02, -1.1621e-01,  2.8589e-01,  ...,  8.0908e-01,\n",
       "           -1.7275e+00, -6.6016e+00],\n",
       "          [-2.7893e-02,  3.7329e-01,  1.4624e-01,  ...,  9.9512e-01,\n",
       "           -2.0586e+00, -5.8516e+00],\n",
       "          ...,\n",
       "          [ 7.4414e-01,  3.5400e-03, -1.4673e-01,  ...,  1.3574e+00,\n",
       "           -2.9629e+00, -6.7695e+00],\n",
       "          [-9.8389e-02, -2.4316e-01,  1.2274e-01,  ...,  1.5693e+00,\n",
       "           -2.8789e+00, -6.9062e+00],\n",
       "          [-8.6133e-01, -4.3408e-01,  2.2766e-01,  ...,  1.5088e+00,\n",
       "           -2.9355e+00, -6.7383e+00]],\n",
       "\n",
       "         [[-5.1086e-02,  1.8701e-01, -2.5464e-01,  ...,  1.1597e-01,\n",
       "           -2.6221e-01, -5.2979e-01],\n",
       "          [ 6.4844e-01,  4.3896e-01, -4.5801e-01,  ...,  2.2910e+00,\n",
       "           -3.4375e-01, -4.9390e-01],\n",
       "          [ 4.1235e-01, -1.2177e-02,  5.6689e-01,  ...,  1.5771e+00,\n",
       "           -7.2217e-01, -1.7061e+00],\n",
       "          ...,\n",
       "          [ 5.7666e-01, -6.6699e-01, -7.8613e-01,  ...,  1.6250e+00,\n",
       "           -9.3750e-01, -2.0195e+00],\n",
       "          [ 6.9092e-02, -9.0234e-01, -4.4824e-01,  ...,  1.8320e+00,\n",
       "           -9.5508e-01, -1.8652e+00],\n",
       "          [-4.2700e-01, -3.1445e-01,  4.5410e-02,  ...,  1.7695e+00,\n",
       "           -1.1123e+00, -1.9785e+00]],\n",
       "\n",
       "         [[-9.1919e-02,  6.9458e-02,  6.4026e-02,  ...,  8.4412e-02,\n",
       "           -1.7798e-01, -6.0150e-02],\n",
       "          [-3.5059e-01,  7.1777e-01, -3.0884e-01,  ...,  7.5635e-01,\n",
       "           -2.3691e+00, -8.4131e-01],\n",
       "          [ 6.1646e-02,  4.3066e-01, -5.4053e-01,  ...,  6.7334e-01,\n",
       "           -1.6592e+00, -1.2168e+00],\n",
       "          ...,\n",
       "          [ 8.5815e-02, -1.1450e-01, -6.2256e-03,  ...,  1.2627e+00,\n",
       "           -8.9539e-02, -9.9805e-01],\n",
       "          [-3.0811e-01, -7.9688e-01, -7.4951e-02,  ...,  1.5986e+00,\n",
       "           -1.2323e-01, -1.2441e+00],\n",
       "          [-4.5898e-01, -6.9287e-01, -4.5728e-01,  ...,  1.2129e+00,\n",
       "           -2.0410e-01, -1.0527e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-5.0476e-02, -2.3779e-01,  1.1884e-01,  ...,  2.3438e-01,\n",
       "           -7.7295e-01,  7.3584e-01],\n",
       "          [ 3.2373e-01,  1.2390e-01,  2.1179e-02,  ...,  8.0518e-01,\n",
       "           -2.2910e+00,  3.8496e+00],\n",
       "          [ 4.0649e-02,  5.4346e-01,  1.4050e-01,  ...,  3.4619e-01,\n",
       "           -1.2471e+00,  1.7588e+00],\n",
       "          ...,\n",
       "          [ 4.4434e-02,  3.1860e-01,  4.0576e-01,  ...,  4.8755e-01,\n",
       "           -1.7822e+00,  2.5488e+00],\n",
       "          [ 1.3000e-01, -6.4697e-03,  5.7324e-01,  ...,  5.0684e-01,\n",
       "           -1.9141e+00,  3.0059e+00],\n",
       "          [ 9.8877e-02, -4.1724e-01,  3.6768e-01,  ...,  2.8467e-01,\n",
       "           -1.7031e+00,  2.3027e+00]],\n",
       "\n",
       "         [[ 1.8982e-01,  6.6345e-02,  1.8677e-01,  ...,  6.0107e-01,\n",
       "            7.2119e-01,  4.6240e-01],\n",
       "          [-4.2334e-01,  4.5068e-01,  2.7515e-01,  ...,  3.2251e-01,\n",
       "            1.2383e+00,  1.0518e+00],\n",
       "          [-4.9707e-01, -3.5645e-01,  3.5425e-01,  ..., -8.1238e-02,\n",
       "            8.2324e-01,  5.5029e-01],\n",
       "          ...,\n",
       "          [-2.0776e-01, -5.1904e-01, -2.3987e-01,  ..., -5.1758e-02,\n",
       "            4.3823e-01,  2.4268e-01],\n",
       "          [-8.7793e-01, -7.5562e-02,  1.4038e-01,  ..., -1.6919e-01,\n",
       "            4.9097e-01,  2.4585e-01],\n",
       "          [-7.2754e-01,  5.9229e-01,  4.7656e-01,  ..., -3.2739e-01,\n",
       "            2.8247e-01,  1.5747e-01]],\n",
       "\n",
       "         [[-3.0664e-01,  2.9053e-01,  3.9600e-01,  ...,  6.1615e-02,\n",
       "            2.5806e-01,  2.3145e-01],\n",
       "          [-1.3611e-01,  5.1709e-01,  9.9951e-01,  ...,  9.8877e-01,\n",
       "            4.6240e-01,  4.1650e-01],\n",
       "          [ 2.9199e-01,  4.6692e-02,  1.6919e-01,  ...,  1.2725e+00,\n",
       "           -1.7078e-01, -6.1572e-01],\n",
       "          ...,\n",
       "          [-1.1270e+00, -1.8250e-01,  8.1494e-01,  ...,  1.3418e+00,\n",
       "            1.0752e+00, -2.2351e-01],\n",
       "          [-2.2925e-01,  4.9225e-02,  2.8320e-01,  ...,  1.4512e+00,\n",
       "            1.1650e+00, -1.2976e-01],\n",
       "          [ 1.2168e+00,  1.6821e-01, -4.7803e-01,  ...,  1.3906e+00,\n",
       "            1.0459e+00, -3.9282e-01]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[[ 1.0992e-01,  4.1565e-02, -5.9082e-02,  ..., -1.0284e-01,\n",
       "            1.0913e-01,  2.1558e-01],\n",
       "          [ 2.3792e-01,  1.3757e-01, -1.0986e-01,  ...,  6.0089e-02,\n",
       "            6.7322e-02,  6.1182e-01],\n",
       "          [-1.0529e-01,  3.9948e-02,  1.1711e-02,  ...,  1.3281e-01,\n",
       "           -4.5502e-02,  5.1367e-01],\n",
       "          ...,\n",
       "          [ 1.8689e-01, -2.1957e-02, -1.7322e-01,  ...,  3.1665e-01,\n",
       "            9.3994e-02,  4.0381e-01],\n",
       "          [ 1.6785e-01, -3.7659e-02, -2.8589e-01,  ...,  2.9932e-01,\n",
       "            5.8716e-02,  3.1860e-01],\n",
       "          [ 1.8384e-01, -1.2225e-01, -1.8677e-01,  ...,  2.6782e-01,\n",
       "            6.2683e-02,  3.5498e-01]],\n",
       "\n",
       "         [[-1.1652e-01, -8.7402e-02,  7.1960e-02,  ...,  3.5143e-04,\n",
       "           -1.0284e-02, -9.9304e-02],\n",
       "          [-8.7598e-01, -2.2803e-01, -1.2549e-01,  ...,  2.6062e-02,\n",
       "            6.2805e-02, -1.0370e-01],\n",
       "          [-3.2373e-01, -5.5389e-02, -1.5369e-01,  ..., -1.0864e-02,\n",
       "            2.9663e-02,  1.9226e-02],\n",
       "          ...,\n",
       "          [-6.3721e-01,  2.3914e-01, -3.6377e-01,  ..., -1.8433e-02,\n",
       "           -1.5430e-01, -3.3417e-02],\n",
       "          [-7.2852e-01,  1.9470e-01, -3.6792e-01,  ...,  8.8379e-02,\n",
       "           -1.2903e-01,  8.1329e-03],\n",
       "          [-6.7871e-01,  2.7295e-01, -4.4653e-01,  ...,  1.0061e-03,\n",
       "           -1.3672e-01,  1.7151e-02]],\n",
       "\n",
       "         [[ 1.1978e-02, -8.4778e-02,  7.8308e-02,  ...,  2.6733e-02,\n",
       "            5.1975e-04, -1.3977e-01],\n",
       "          [ 2.2681e-01, -5.5695e-02, -1.6525e-02,  ..., -2.2049e-02,\n",
       "           -2.8198e-01,  2.2327e-01],\n",
       "          [ 3.2690e-01, -3.5547e-01,  6.0516e-02,  ...,  1.7249e-01,\n",
       "           -2.3120e-01,  5.3711e-02],\n",
       "          ...,\n",
       "          [ 1.0754e-01, -4.1162e-01, -2.0020e-01,  ..., -5.5939e-02,\n",
       "           -6.6956e-02, -1.7761e-01],\n",
       "          [ 5.9570e-02, -3.9160e-01, -1.5161e-01,  ..., -4.6234e-02,\n",
       "           -9.3384e-02, -1.8628e-01],\n",
       "          [ 1.0114e-01, -3.7842e-01, -1.9019e-01,  ..., -4.8492e-02,\n",
       "           -6.7322e-02, -1.6284e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.5601e-01, -3.0243e-02, -1.9226e-03,  ...,  2.5009e-02,\n",
       "           -2.2168e-01,  1.0736e-01],\n",
       "          [ 5.1367e-01,  1.4246e-01,  3.7061e-01,  ...,  6.0394e-02,\n",
       "           -3.8452e-01, -3.3813e-02],\n",
       "          [-8.4961e-02, -1.3574e-01,  3.3911e-01,  ...,  1.4319e-01,\n",
       "           -6.0889e-01, -1.1798e-01],\n",
       "          ...,\n",
       "          [-4.0466e-02,  2.4255e-01,  4.4263e-01,  ...,  3.5889e-01,\n",
       "           -4.7388e-01, -2.5098e-01],\n",
       "          [ 2.1957e-02,  2.1045e-01,  3.6890e-01,  ...,  2.9419e-01,\n",
       "           -4.3774e-01, -2.2729e-01],\n",
       "          [ 7.7934e-03,  2.6318e-01,  4.2017e-01,  ...,  2.9810e-01,\n",
       "           -5.2734e-01, -2.4963e-01]],\n",
       "\n",
       "         [[-2.8564e-02,  9.3567e-02,  9.8343e-03,  ...,  9.2957e-02,\n",
       "           -2.5070e-02, -9.5642e-02],\n",
       "          [ 8.1406e-03,  9.4421e-02, -2.3840e-01,  ..., -6.2561e-02,\n",
       "            3.4009e-01, -1.5027e-01],\n",
       "          [-1.1865e-01, -5.9784e-02, -1.0284e-01,  ..., -7.6172e-02,\n",
       "            6.4270e-02, -1.1316e-01],\n",
       "          ...,\n",
       "          [-1.7700e-02,  5.0720e-02,  1.1121e-01,  ...,  6.1951e-02,\n",
       "            2.0947e-01, -2.7295e-01],\n",
       "          [-4.1656e-02,  6.6040e-02,  1.2201e-01,  ...,  6.3049e-02,\n",
       "            2.5269e-01, -2.7612e-01],\n",
       "          [-5.7697e-04, -1.2329e-02,  1.5906e-01,  ...,  7.7271e-02,\n",
       "            1.8201e-01, -2.9663e-01]],\n",
       "\n",
       "         [[ 2.0874e-02,  1.2683e-01, -3.5217e-02,  ...,  1.1572e-01,\n",
       "           -3.0167e-02,  7.3929e-03],\n",
       "          [ 6.1230e-01,  5.3223e-02, -6.7627e-01,  ...,  2.3596e-01,\n",
       "            1.7834e-01, -3.7915e-01],\n",
       "          [-1.9922e-01,  3.2520e-01, -1.7810e-01,  ...,  1.6162e-01,\n",
       "           -3.8086e-01, -2.4683e-01],\n",
       "          ...,\n",
       "          [ 1.7212e-02,  1.4343e-01, -2.6074e-01,  ...,  1.1975e-01,\n",
       "           -2.9492e-01, -4.1455e-01],\n",
       "          [-3.0457e-02,  1.2842e-01, -2.7686e-01,  ...,  9.9243e-02,\n",
       "           -3.1592e-01, -3.9453e-01],\n",
       "          [ 1.0445e-02,  1.2720e-01, -2.6929e-01,  ...,  1.3782e-01,\n",
       "           -3.0811e-01, -4.1846e-01]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[-3.4576e-02,  2.1802e-01,  8.0261e-02,  ..., -2.3743e-01,\n",
       "           -5.9863e-01,  2.3254e-01],\n",
       "          [-4.0137e-01, -1.8518e-01,  3.5840e-01,  ..., -2.6543e+00,\n",
       "           -1.8086e+00, -1.1279e+00],\n",
       "          [-3.8672e-01, -6.9580e-02,  4.6265e-01,  ..., -2.3848e+00,\n",
       "           -1.7002e+00, -1.0342e+00],\n",
       "          ...,\n",
       "          [ 1.5833e-01, -3.4790e-01,  1.2427e-01,  ..., -2.8789e+00,\n",
       "           -1.4922e+00, -6.7041e-01],\n",
       "          [-6.4087e-03,  1.9775e-01,  1.2250e-01,  ..., -2.9824e+00,\n",
       "           -1.6240e+00, -5.5273e-01],\n",
       "          [-3.5889e-01,  6.3281e-01,  1.9519e-01,  ..., -2.8613e+00,\n",
       "           -1.5684e+00, -6.4551e-01]],\n",
       "\n",
       "         [[ 9.5459e-02, -1.9775e-01, -2.0544e-01,  ...,  1.7014e-02,\n",
       "            2.0605e-01, -1.4673e-01],\n",
       "          [-1.9980e+00,  2.4438e-01, -7.9346e-01,  ...,  6.1377e-01,\n",
       "            1.2207e+00, -7.3425e-02],\n",
       "          [-2.5566e+00,  5.1270e-01, -8.8770e-01,  ...,  1.0156e+00,\n",
       "            1.8965e+00, -1.7371e-01],\n",
       "          ...,\n",
       "          [-2.0371e+00, -2.2510e-01, -9.1797e-01,  ...,  2.7710e-01,\n",
       "            1.3906e+00, -3.5132e-01],\n",
       "          [-3.3770e+00, -1.7432e-01, -1.4268e+00,  ...,  2.3022e-01,\n",
       "            1.3154e+00, -3.0518e-01],\n",
       "          [-1.2998e+00,  6.4148e-02, -9.5801e-01,  ...,  4.2651e-01,\n",
       "            1.6504e+00, -2.5171e-01]],\n",
       "\n",
       "         [[-4.2163e-01,  8.4778e-02, -1.1688e-01,  ..., -2.6392e-01,\n",
       "            2.8198e-01,  2.3849e-02],\n",
       "          [-5.5713e-01, -7.3914e-02,  2.7771e-02,  ..., -2.7734e-01,\n",
       "            6.2061e-01,  1.5049e+00],\n",
       "          [ 9.3359e-01, -2.9614e-01, -7.5684e-02,  ...,  1.1249e-01,\n",
       "            8.9014e-01,  1.3984e+00],\n",
       "          ...,\n",
       "          [ 2.0508e-01, -9.7949e-01, -3.5205e-01,  ..., -1.4160e+00,\n",
       "           -1.8506e-01,  9.1211e-01],\n",
       "          [ 1.4609e+00, -1.6699e-01, -4.8828e-01,  ..., -1.4570e+00,\n",
       "           -3.4644e-01,  8.9160e-01],\n",
       "          [ 1.1084e+00,  6.7432e-01, -2.2534e-01,  ..., -1.1973e+00,\n",
       "           -1.7224e-01,  1.0439e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 9.1553e-02,  8.0185e-03,  1.2634e-01,  ..., -5.6396e-01,\n",
       "           -4.4629e-01, -4.6289e-01],\n",
       "          [ 9.4336e-01, -4.6094e-01,  3.4448e-01,  ..., -2.4414e+00,\n",
       "           -4.1484e+00, -6.8750e-01],\n",
       "          [-3.4985e-01, -7.0312e-02,  5.1172e-01,  ..., -1.6621e+00,\n",
       "           -4.1641e+00, -9.0967e-01],\n",
       "          ...,\n",
       "          [ 4.8242e-01,  8.8281e-01,  1.9617e-01,  ...,  1.5027e-01,\n",
       "           -5.2891e+00, -9.7168e-01],\n",
       "          [ 2.2803e-01,  5.6982e-01,  2.5977e-01,  ..., -3.1641e-01,\n",
       "           -5.6172e+00, -9.8389e-01],\n",
       "          [-2.7563e-01, -2.0679e-01,  3.5010e-01,  ..., -2.3108e-01,\n",
       "           -5.6719e+00, -1.0156e+00]],\n",
       "\n",
       "         [[-3.8433e-04, -1.6068e-02, -2.8931e-01,  ...,  9.6436e-01,\n",
       "            2.5854e-01,  5.3857e-01],\n",
       "          [-2.1692e-01,  8.7097e-02, -4.8462e-02,  ...,  2.9785e+00,\n",
       "           -9.7363e-01,  1.7686e+00],\n",
       "          [ 2.4561e-01,  6.3599e-02, -3.8037e-01,  ...,  2.2930e+00,\n",
       "           -7.7051e-01,  8.4619e-01],\n",
       "          ...,\n",
       "          [ 8.2422e-01,  5.7812e-01, -3.2153e-01,  ...,  1.3994e+00,\n",
       "           -1.5586e+00,  1.3223e+00],\n",
       "          [ 5.1660e-01,  6.2842e-01, -1.3269e-01,  ...,  1.5312e+00,\n",
       "           -1.8896e+00,  1.5352e+00],\n",
       "          [-4.6777e-01, -7.3120e-02,  3.7781e-02,  ...,  1.2324e+00,\n",
       "           -1.6074e+00,  1.2012e+00]],\n",
       "\n",
       "         [[-1.6235e-02, -2.6611e-01, -2.5806e-01,  ..., -1.8823e-01,\n",
       "            2.9816e-02, -3.1616e-01],\n",
       "          [ 1.9507e-01, -2.7441e-01, -8.4082e-01,  ...,  8.2959e-01,\n",
       "            4.2139e-01, -4.4458e-01],\n",
       "          [-1.6309e-01,  4.8193e-01, -1.4563e-01,  ..., -5.7178e-01,\n",
       "            6.4880e-02, -1.1420e-01],\n",
       "          ...,\n",
       "          [-5.6396e-01,  3.2520e-01, -2.3877e-01,  ..., -5.3223e-01,\n",
       "            6.1816e-01, -1.0187e-01],\n",
       "          [-1.3550e-01, -1.5869e-02,  1.0730e-01,  ..., -5.6494e-01,\n",
       "            6.2109e-01, -2.9150e-01],\n",
       "          [ 5.1270e-01, -3.2007e-01,  1.5100e-01,  ..., -6.6309e-01,\n",
       "            6.5381e-01, -7.6477e-02]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[[-0.0825,  0.0725,  0.1807,  ...,  0.1818, -0.0665,  0.1710],\n",
       "          [ 0.1859,  0.3354,  0.0317,  ...,  0.2532, -0.0495,  0.3311],\n",
       "          [-0.0291,  0.1725,  0.1200,  ...,  0.2190,  0.1160,  0.1536],\n",
       "          ...,\n",
       "          [-0.0387,  0.2173,  0.3708,  ...,  0.3428,  0.1700, -0.0829],\n",
       "          [-0.0374,  0.2174,  0.3765,  ...,  0.4250,  0.1494, -0.0085],\n",
       "          [-0.0323,  0.2427,  0.3584,  ...,  0.3491,  0.1722, -0.1511]],\n",
       "\n",
       "         [[-0.1346, -0.1764, -0.0566,  ...,  0.0025,  0.1737, -0.0543],\n",
       "          [-0.1970, -0.0211, -0.0161,  ...,  0.0463,  0.5513,  0.0751],\n",
       "          [-0.1154, -0.1144, -0.3879,  ...,  0.0182,  0.3916, -0.0033],\n",
       "          ...,\n",
       "          [ 0.0966,  0.0465, -0.0222,  ...,  0.3792,  0.4619,  0.2168],\n",
       "          [ 0.2019,  0.1232, -0.0654,  ...,  0.3889,  0.3994,  0.1628],\n",
       "          [ 0.1124,  0.1038, -0.0287,  ...,  0.4385,  0.4258,  0.2384]],\n",
       "\n",
       "         [[-0.0074, -0.0842, -0.1827,  ..., -0.0959,  0.0093, -0.0331],\n",
       "          [ 0.3704,  0.0095,  0.3889,  ..., -0.0747, -0.5630, -0.2229],\n",
       "          [ 0.6182, -0.0432,  0.3018,  ...,  0.0161, -0.0457,  0.1757],\n",
       "          ...,\n",
       "          [-0.2417, -0.2969,  0.1964,  ..., -0.1681, -0.2433,  0.1467],\n",
       "          [-0.1809, -0.3596,  0.1196,  ..., -0.1558, -0.2373,  0.1462],\n",
       "          [-0.2681, -0.3958,  0.2394,  ..., -0.0852, -0.2469,  0.0745]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0133, -0.2032,  0.0495,  ..., -0.0594,  0.0267, -0.0093],\n",
       "          [ 0.0611, -0.4797,  0.2764,  ..., -0.3499, -0.0504, -0.4680],\n",
       "          [ 0.4404, -0.5825,  0.0051,  ..., -0.2332,  0.1179, -0.5225],\n",
       "          ...,\n",
       "          [-0.0320, -0.1682,  0.0471,  ..., -0.1095,  0.2122, -0.1305],\n",
       "          [-0.0997, -0.1835,  0.0573,  ..., -0.1306,  0.2015, -0.0926],\n",
       "          [-0.0489, -0.1221,  0.0714,  ..., -0.1181,  0.2189, -0.1725]],\n",
       "\n",
       "         [[ 0.1447,  0.1407, -0.2100,  ..., -0.0834, -0.0079,  0.0851],\n",
       "          [ 0.2517,  0.2476, -0.3496,  ..., -0.2421,  0.2299,  0.1293],\n",
       "          [ 0.1042,  0.1572, -0.3101,  ..., -0.2935, -0.0234,  0.2241],\n",
       "          ...,\n",
       "          [ 0.3770,  0.0742, -0.2189,  ..., -0.1276, -0.2234,  0.2566],\n",
       "          [ 0.3772,  0.0622, -0.2598,  ..., -0.1387, -0.2327,  0.2334],\n",
       "          [ 0.4282,  0.0667, -0.1860,  ..., -0.1274, -0.2139,  0.2089]],\n",
       "\n",
       "         [[-0.0169,  0.2673,  0.2239,  ...,  0.0016,  0.0144, -0.1438],\n",
       "          [-0.3418,  0.3132, -0.0198,  ...,  0.0886,  0.0923, -0.2659],\n",
       "          [-0.1327,  0.1163, -0.0050,  ...,  0.1147, -0.1245, -0.6177],\n",
       "          ...,\n",
       "          [-0.1149,  0.0249,  0.0517,  ...,  0.2181, -0.0424, -0.2671],\n",
       "          [-0.1146, -0.0139,  0.1486,  ...,  0.2372,  0.0143, -0.2815],\n",
       "          [-0.1211,  0.0059,  0.0589,  ...,  0.2944, -0.1158, -0.2288]]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<TransposeBackward0>)), (tensor([[[[ 3.0737e-01,  1.0968e-01,  2.4365e-01,  ..., -3.6719e-01,\n",
       "            6.5674e-02, -1.4001e-01],\n",
       "          [ 7.5977e-01, -2.8711e-01,  1.5552e-01,  ..., -3.1079e-01,\n",
       "            4.1992e-01,  1.4941e-01],\n",
       "          [ 2.0325e-01, -3.1396e-01, -2.1704e-01,  ...,  2.4475e-01,\n",
       "           -3.0322e-01,  5.1709e-01],\n",
       "          ...,\n",
       "          [-5.3833e-02,  4.1870e-02, -1.3867e-01,  ..., -8.3789e-01,\n",
       "            5.6689e-01, -6.5186e-02],\n",
       "          [ 3.0273e-02, -8.5388e-02, -3.0176e-01,  ..., -1.0098e+00,\n",
       "            4.6387e-01, -1.3916e-01],\n",
       "          [ 3.2739e-01, -2.2168e-01, -3.4131e-01,  ..., -9.4727e-01,\n",
       "            2.9321e-01, -4.5227e-02]],\n",
       "\n",
       "         [[ 4.7339e-01, -4.5557e-01,  1.2830e-01,  ..., -4.6234e-02,\n",
       "            6.0889e-01,  6.7482e-03],\n",
       "          [ 5.0049e-01, -2.4146e-01, -2.6831e-01,  ..., -1.0059e+00,\n",
       "            1.6296e-01, -5.5713e-01],\n",
       "          [ 1.3892e-01,  1.3525e-01,  8.5498e-01,  ..., -1.0156e+00,\n",
       "           -5.3223e-01,  5.5908e-02],\n",
       "          ...,\n",
       "          [ 1.2383e+00,  5.5969e-02, -2.4756e-01,  ...,  1.6296e-01,\n",
       "           -3.3911e-01, -1.1582e+00],\n",
       "          [ 1.2559e+00,  1.1438e-01,  1.4893e-01,  ...,  9.3506e-02,\n",
       "           -3.0615e-01, -1.2012e+00],\n",
       "          [-3.7598e-02,  2.9968e-02,  4.4458e-01,  ..., -5.4131e-03,\n",
       "           -2.9077e-01, -1.4092e+00]],\n",
       "\n",
       "         [[ 1.3354e-01,  2.1851e-01, -1.3904e-01,  ...,  1.5635e+00,\n",
       "           -3.7036e-01,  3.0000e+00],\n",
       "          [ 6.9580e-01, -4.9927e-02, -2.5439e-01,  ...,  4.3242e+00,\n",
       "            6.3184e-01,  6.6016e+00],\n",
       "          [ 1.2189e-01,  1.6211e-01, -1.7322e-01,  ...,  3.1660e+00,\n",
       "           -7.2705e-01,  5.2227e+00],\n",
       "          ...,\n",
       "          [ 3.9526e-01, -5.8398e-01, -2.8101e-01,  ...,  4.5273e+00,\n",
       "            3.0396e-01,  6.6172e+00],\n",
       "          [-2.9126e-01,  1.7859e-01,  3.4619e-01,  ...,  4.5273e+00,\n",
       "            1.5121e-02,  6.8398e+00],\n",
       "          [-6.5869e-01,  7.8564e-01,  8.2715e-01,  ...,  4.2070e+00,\n",
       "           -4.0381e-01,  6.8008e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.0535e-01,  2.3230e-01, -1.6663e-01,  ..., -1.3027e+00,\n",
       "           -1.1357e+00, -7.9395e-01],\n",
       "          [ 7.6221e-01,  2.5244e-01, -5.3223e-01,  ..., -2.4102e+00,\n",
       "           -2.0039e+00, -3.9185e-01],\n",
       "          [ 1.2344e+00,  3.2990e-02, -4.5215e-01,  ..., -1.5684e+00,\n",
       "           -1.9346e+00, -1.5273e+00],\n",
       "          ...,\n",
       "          [ 7.5439e-01,  2.0667e-01, -2.3901e-01,  ..., -1.4023e+00,\n",
       "           -1.3613e+00, -6.4014e-01],\n",
       "          [ 2.7832e-01,  6.9153e-02,  1.2744e-01,  ..., -1.4141e+00,\n",
       "           -1.2871e+00, -6.3184e-01],\n",
       "          [-2.9492e-01, -5.2124e-02,  4.1357e-01,  ..., -1.5273e+00,\n",
       "           -1.3818e+00, -7.8857e-01]],\n",
       "\n",
       "         [[-4.1699e-01, -1.4001e-01, -1.0010e-01,  ...,  4.7217e-01,\n",
       "           -1.0586e+00,  1.0040e-01],\n",
       "          [-9.7461e-01,  3.7476e-01,  1.8921e-01,  ..., -7.8174e-01,\n",
       "           -5.4414e+00, -1.3789e+00],\n",
       "          [-1.9727e-01,  3.3032e-01,  3.0835e-01,  ..., -1.3643e+00,\n",
       "           -5.1758e+00,  8.8379e-01],\n",
       "          ...,\n",
       "          [-9.3506e-01, -1.1951e-01,  1.2323e-01,  ..., -1.3701e+00,\n",
       "           -5.3008e+00,  1.3057e+00],\n",
       "          [ 8.8232e-01,  1.0773e-01,  1.1139e-01,  ..., -1.4648e+00,\n",
       "           -5.6094e+00,  1.1582e+00],\n",
       "          [ 1.6191e+00,  8.8501e-02,  8.7524e-02,  ..., -1.2305e+00,\n",
       "           -5.4023e+00,  1.1982e+00]],\n",
       "\n",
       "         [[ 2.3621e-01,  3.0811e-01, -1.5088e-01,  ..., -1.1797e+00,\n",
       "            3.9429e-01,  6.2109e-01],\n",
       "          [ 7.4658e-01,  2.3462e-01, -4.0967e-01,  ..., -2.1406e+00,\n",
       "           -3.5815e-01,  1.0859e+00],\n",
       "          [ 1.5283e-01,  7.5073e-02, -2.8125e-01,  ..., -2.1953e+00,\n",
       "           -6.1279e-01,  1.0684e+00],\n",
       "          ...,\n",
       "          [ 1.3291e+00, -6.5674e-01, -5.5957e-01,  ..., -1.3633e+00,\n",
       "           -3.7671e-01,  1.1482e-02],\n",
       "          [ 1.1309e+00,  5.3223e-02, -5.6689e-01,  ..., -1.1660e+00,\n",
       "           -2.5122e-01,  1.5356e-01],\n",
       "          [-5.4980e-01,  6.5820e-01, -3.3594e-01,  ..., -1.3145e+00,\n",
       "           -6.0938e-01,  2.4561e-01]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[[-1.0614e-01,  8.4473e-02, -5.3131e-02,  ..., -2.8183e-02,\n",
       "           -1.4502e-01, -9.7290e-02],\n",
       "          [ 1.9531e-01,  2.2607e-01,  4.1895e-01,  ..., -3.2739e-01,\n",
       "           -5.0888e-03, -2.7002e-01],\n",
       "          [ 1.3100e-02,  2.2229e-01,  1.5991e-01,  ..., -6.1951e-02,\n",
       "            2.3041e-02, -2.0325e-01],\n",
       "          ...,\n",
       "          [ 6.3171e-02,  1.6260e-01,  2.3035e-01,  ..., -5.9631e-02,\n",
       "            2.3230e-01,  3.4904e-04],\n",
       "          [ 6.6772e-02,  1.9385e-01,  2.8369e-01,  ..., -1.7444e-01,\n",
       "            2.2974e-01, -4.5929e-02],\n",
       "          [ 1.6815e-02,  1.9800e-01,  2.2168e-01,  ..., -2.0496e-01,\n",
       "            2.2266e-01, -5.1498e-03]],\n",
       "\n",
       "         [[ 1.8982e-02, -2.0166e-01,  7.8430e-02,  ..., -2.0103e-03,\n",
       "           -7.0801e-02, -1.3806e-01],\n",
       "          [ 2.5562e-01, -1.6992e-01,  1.7676e-01,  ...,  8.3862e-02,\n",
       "           -1.1267e-01, -3.9526e-01],\n",
       "          [ 1.0010e-01, -9.9426e-02, -2.9510e-02,  ...,  3.2129e-01,\n",
       "           -5.8319e-02, -1.3049e-01],\n",
       "          ...,\n",
       "          [ 2.4304e-01, -3.8794e-01, -1.5320e-01,  ..., -9.8633e-02,\n",
       "            7.6904e-02, -4.6387e-01],\n",
       "          [ 2.1143e-01, -4.3286e-01, -1.8152e-01,  ..., -1.3892e-01,\n",
       "            7.6599e-02, -4.4287e-01],\n",
       "          [ 2.8418e-01, -3.9209e-01, -2.1948e-01,  ..., -1.4185e-01,\n",
       "            1.1078e-01, -4.8218e-01]],\n",
       "\n",
       "         [[ 7.4158e-02,  6.5247e-02,  4.3060e-02,  ...,  1.3708e-01,\n",
       "            1.2396e-01,  4.3732e-02],\n",
       "          [-8.5449e-01,  5.6006e-01, -6.9287e-01,  ..., -1.9543e-01,\n",
       "            6.1218e-02,  6.1035e-01],\n",
       "          [ 3.9185e-01,  1.6565e-01, -2.4500e-01,  ...,  6.0974e-02,\n",
       "            2.0972e-01, -1.1261e-01],\n",
       "          ...,\n",
       "          [ 4.0314e-02,  1.8518e-01,  2.8882e-01,  ...,  1.9617e-01,\n",
       "           -1.8689e-01,  4.7559e-01],\n",
       "          [-8.0444e-02,  1.9458e-01,  3.2007e-01,  ...,  3.1372e-01,\n",
       "           -2.4219e-01,  3.7109e-01],\n",
       "          [ 4.6387e-02,  2.6535e-02,  3.5376e-01,  ...,  2.9810e-01,\n",
       "           -1.8005e-01,  3.1128e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 6.8787e-02, -5.2277e-02, -2.6294e-01,  ...,  5.2643e-02,\n",
       "           -2.0386e-01,  7.5745e-02],\n",
       "          [-3.0273e-01, -2.3608e-01,  5.5542e-02,  ..., -3.0762e-01,\n",
       "           -3.3594e-01,  3.2202e-01],\n",
       "          [ 1.9739e-01, -9.0881e-02, -5.1270e-01,  ..., -3.7622e-01,\n",
       "           -3.0762e-01,  1.4648e-01],\n",
       "          ...,\n",
       "          [-1.0620e-01, -2.1558e-01, -3.7769e-01,  ..., -1.3904e-01,\n",
       "           -1.4673e-01,  2.7808e-01],\n",
       "          [-1.4270e-01, -1.5649e-01, -3.2007e-01,  ...,  1.9608e-02,\n",
       "           -1.6138e-01,  1.3977e-01],\n",
       "          [-1.9482e-01, -1.7163e-01, -2.8613e-01,  ..., -7.5317e-02,\n",
       "           -1.8188e-01,  1.8823e-01]],\n",
       "\n",
       "         [[ 1.4185e-01, -4.9400e-03, -6.8787e-02,  ...,  3.9703e-02,\n",
       "           -4.9438e-02, -1.0431e-01],\n",
       "          [-2.7979e-01, -2.5317e-01,  3.1348e-01,  ...,  2.8046e-02,\n",
       "            2.6001e-01, -1.5295e-01],\n",
       "          [ 3.7695e-01,  3.2135e-02, -6.8665e-02,  ..., -5.1208e-02,\n",
       "           -2.9004e-01, -1.9608e-02],\n",
       "          ...,\n",
       "          [-1.3684e-01, -2.6184e-02,  1.2720e-01,  ..., -6.9702e-02,\n",
       "            1.1194e-01, -1.2195e-01],\n",
       "          [-1.3843e-01, -5.4504e-02,  1.5308e-01,  ..., -1.2390e-02,\n",
       "            9.4788e-02, -1.2891e-01],\n",
       "          [-1.1304e-01, -3.5706e-02,  8.9478e-02,  ..., -6.1279e-02,\n",
       "            3.7567e-02, -1.4795e-01]],\n",
       "\n",
       "         [[-8.8196e-02,  6.6414e-03, -6.8115e-02,  ..., -4.7028e-02,\n",
       "            2.5253e-02, -2.0905e-02],\n",
       "          [ 1.8457e-01,  1.2915e-01,  2.8149e-01,  ..., -2.6245e-01,\n",
       "            4.0039e-01,  1.7395e-02],\n",
       "          [-5.1172e-01, -1.1757e-02, -1.5515e-01,  ..., -3.5522e-01,\n",
       "            2.8516e-01, -1.9922e-01],\n",
       "          ...,\n",
       "          [-5.7471e-01,  1.3321e-02, -9.0210e-02,  ..., -1.9714e-01,\n",
       "           -9.1553e-02,  1.3477e-01],\n",
       "          [-4.9585e-01, -2.2736e-03, -1.2622e-01,  ..., -1.9727e-01,\n",
       "           -6.0211e-02,  2.1069e-01],\n",
       "          [-5.7227e-01, -9.2087e-03, -1.3855e-01,  ..., -1.5015e-01,\n",
       "           -1.7834e-01,  1.3879e-01]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[-9.0866e-03,  4.8279e-02, -2.2253e-01,  ..., -9.1797e-02,\n",
       "           -6.0303e-01, -4.6478e-02],\n",
       "          [ 8.0933e-02,  9.4971e-02,  1.8384e-01,  ..., -2.5488e-01,\n",
       "           -7.0508e-01,  1.4062e+00],\n",
       "          [ 1.0706e-01,  8.7305e-01, -4.9536e-01,  ...,  2.9022e-02,\n",
       "           -8.1934e-01,  1.8213e-01],\n",
       "          ...,\n",
       "          [-4.1382e-01,  1.3953e-01, -6.4746e-01,  ...,  3.6353e-01,\n",
       "           -5.6396e-01, -2.0874e-01],\n",
       "          [-9.1309e-02,  2.4146e-01, -5.7275e-01,  ...,  3.5181e-01,\n",
       "           -5.6641e-01, -1.1652e-01],\n",
       "          [ 4.5020e-01,  1.2390e-02, -3.4985e-01,  ...,  3.4668e-01,\n",
       "           -5.3711e-01, -2.0142e-01]],\n",
       "\n",
       "         [[ 1.3855e-01, -1.6797e-01,  1.0077e-01,  ...,  1.7041e-01,\n",
       "           -3.7793e-01,  1.7175e-01],\n",
       "          [ 9.2871e-01,  2.2412e-01,  4.5654e-01,  ...,  1.5656e-02,\n",
       "           -1.0039e+00,  2.2751e-02],\n",
       "          [ 1.2012e+00,  3.5400e-01,  1.2341e-01,  ...,  3.2178e-01,\n",
       "            2.6807e-01,  6.2317e-02],\n",
       "          ...,\n",
       "          [ 3.9966e-01,  8.9600e-02,  4.3652e-01,  ..., -3.7292e-02,\n",
       "            4.2969e-01, -3.5718e-01],\n",
       "          [ 3.3887e-01,  1.1328e-01, -1.5906e-01,  ..., -4.2755e-02,\n",
       "            4.6655e-01, -4.1187e-01],\n",
       "          [ 2.0935e-01, -1.0352e-01, -5.3223e-01,  ...,  4.0405e-02,\n",
       "            5.4541e-01, -4.8828e-01]],\n",
       "\n",
       "         [[ 2.8931e-01, -2.3059e-01,  4.4403e-02,  ...,  6.4648e-01,\n",
       "           -1.5967e+00,  1.2549e+00],\n",
       "          [ 2.4146e-01, -3.1665e-01,  1.1316e-01,  ...,  1.3369e+00,\n",
       "           -3.3242e+00,  1.5283e+00],\n",
       "          [-1.7419e-01, -2.8125e-01, -1.0971e-02,  ...,  4.6460e-01,\n",
       "           -4.0469e+00,  3.0117e+00],\n",
       "          ...,\n",
       "          [ 2.1313e-01,  6.9434e-01, -3.7964e-02,  ...,  6.1475e-01,\n",
       "           -5.2578e+00,  5.1523e+00],\n",
       "          [-5.0098e-01,  4.5850e-01, -9.2896e-02,  ...,  6.5430e-01,\n",
       "           -4.6406e+00,  4.8984e+00],\n",
       "          [-6.8164e-01, -7.7148e-02, -1.6650e-01,  ...,  4.0479e-01,\n",
       "           -4.8281e+00,  4.4727e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.0516e-01, -8.5693e-02,  8.4351e-02,  ...,  1.4307e-01,\n",
       "           -8.2959e-01, -3.6646e-01],\n",
       "          [-3.1860e-01, -2.6636e-01,  3.3130e-01,  ...,  9.5410e-01,\n",
       "           -2.7715e+00, -1.0312e+00],\n",
       "          [-1.0039e+00,  6.6162e-02,  5.2686e-01,  ...,  3.3105e-01,\n",
       "           -2.0938e+00, -1.0231e-02],\n",
       "          ...,\n",
       "          [-4.9463e-01, -3.5327e-01,  3.2812e-01,  ...,  2.2693e-01,\n",
       "           -3.3516e+00, -1.1191e+00],\n",
       "          [-3.2812e-01,  4.4702e-01,  4.8511e-01,  ...,  2.3413e-01,\n",
       "           -3.6133e+00, -1.5234e+00],\n",
       "          [ 9.3994e-02,  6.4648e-01,  4.5996e-01,  ...,  3.2324e-01,\n",
       "           -3.5195e+00, -1.2637e+00]],\n",
       "\n",
       "         [[ 3.1128e-01, -3.7866e-01,  2.2620e-01,  ..., -1.2080e+00,\n",
       "            1.9873e-01,  1.1904e+00],\n",
       "          [ 6.7871e-01, -5.8212e-03,  2.6904e-01,  ..., -1.1191e+00,\n",
       "           -1.2539e+00,  3.9121e+00],\n",
       "          [ 2.6489e-01,  1.9324e-01,  7.0190e-02,  ..., -1.5762e+00,\n",
       "           -8.6914e-02,  3.7559e+00],\n",
       "          ...,\n",
       "          [ 7.2998e-01,  2.0508e-01,  2.1106e-01,  ..., -1.2812e+00,\n",
       "            9.3604e-01,  4.1602e+00],\n",
       "          [-3.3057e-01, -2.4719e-03, -4.2084e-02,  ..., -1.1436e+00,\n",
       "            7.8369e-01,  4.5820e+00],\n",
       "          [-9.9951e-01, -1.7542e-01, -2.0410e-01,  ..., -1.2207e+00,\n",
       "            8.6230e-01,  4.4492e+00]],\n",
       "\n",
       "         [[-1.6394e-01,  9.6802e-02,  1.0089e-01,  ...,  5.4883e-01,\n",
       "           -3.4717e-01,  7.9736e-01],\n",
       "          [-1.0083e-01,  3.4644e-01,  8.2275e-02,  ...,  1.2268e-01,\n",
       "           -6.9580e-01,  3.8145e+00],\n",
       "          [ 1.1871e-01,  4.9121e-01,  8.5400e-01,  ...,  8.5303e-01,\n",
       "           -5.2881e-01,  2.6133e+00],\n",
       "          ...,\n",
       "          [-1.0107e-01, -1.1548e-01, -3.7109e-01,  ...,  3.7036e-01,\n",
       "            2.5342e-01,  3.1406e+00],\n",
       "          [ 8.5352e-01, -1.9055e-01,  1.4929e-01,  ...,  9.9182e-02,\n",
       "            2.7246e-01,  3.3809e+00],\n",
       "          [ 7.2266e-01, -1.2231e-01,  4.5117e-01,  ...,  3.2251e-01,\n",
       "           -1.0376e-01,  3.1953e+00]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[[ 0.0769,  0.3254,  0.0354,  ...,  0.1332,  0.0529, -0.2991],\n",
       "          [ 0.1359,  0.3782, -0.0015,  ...,  0.6387,  0.0657, -0.4814],\n",
       "          [ 0.2964, -0.2013,  0.1854,  ...,  0.6548,  0.0290, -0.5059],\n",
       "          ...,\n",
       "          [ 0.1292,  0.2732,  0.0818,  ...,  0.1841,  0.4331, -0.4624],\n",
       "          [ 0.1501,  0.2937,  0.0433,  ...,  0.1696,  0.4451, -0.5068],\n",
       "          [ 0.0930,  0.2524,  0.0972,  ...,  0.2092,  0.4614, -0.5220]],\n",
       "\n",
       "         [[-0.0906, -0.0041,  0.2416,  ...,  0.1365, -0.2795, -0.0779],\n",
       "          [ 0.2644,  0.0793,  0.3127,  ...,  0.3218, -0.1162, -0.1324],\n",
       "          [-0.0992, -0.2024,  0.3083,  ...,  0.0424, -0.2186,  0.1437],\n",
       "          ...,\n",
       "          [-0.1068, -0.0834,  0.1705,  ...,  0.0255, -0.1555,  0.0760],\n",
       "          [-0.1126, -0.1396,  0.1649,  ...,  0.0567, -0.1259,  0.0862],\n",
       "          [-0.0429, -0.0876,  0.2148,  ...,  0.0262, -0.1349,  0.0345]],\n",
       "\n",
       "         [[-0.0367,  0.3220,  0.2294,  ..., -0.1305,  0.2729, -0.1227],\n",
       "          [-0.1044,  0.8477,  0.5620,  ..., -0.1355,  0.3618,  0.6079],\n",
       "          [ 0.4099,  1.2178,  0.2705,  ..., -0.5200, -0.5830,  1.3789],\n",
       "          ...,\n",
       "          [-0.1991,  0.2896,  0.2458,  ..., -0.5181,  0.9019,  0.2208],\n",
       "          [-0.1379,  0.2367,  0.0674,  ..., -0.2988,  0.8618,  0.1158],\n",
       "          [ 0.0535,  0.4832,  0.2323,  ..., -0.6187,  0.5444,  0.3152]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0485, -0.0710,  0.3137,  ...,  0.1439,  0.2268,  0.2869],\n",
       "          [-0.6655,  0.1293,  0.2408,  ...,  0.0126,  0.2715,  0.0781],\n",
       "          [-0.5234, -0.4167, -0.2861,  ...,  0.1492, -0.0823,  0.1365],\n",
       "          ...,\n",
       "          [-0.4766,  0.1508,  0.0994,  ..., -0.0357, -0.2532,  0.5835],\n",
       "          [-0.4353,  0.1521,  0.1309,  ..., -0.0483, -0.3245,  0.6660],\n",
       "          [-0.5410,  0.1978,  0.0539,  ..., -0.0503, -0.3013,  0.5391]],\n",
       "\n",
       "         [[ 0.1254,  0.1075, -0.1515,  ..., -0.2639,  0.1655,  0.1016],\n",
       "          [ 0.5098,  0.0473, -0.1049,  ..., -0.1893,  0.0650, -0.1926],\n",
       "          [-0.0579, -0.0470, -0.2874,  ..., -0.3657,  0.3025, -0.2159],\n",
       "          ...,\n",
       "          [-0.2747,  0.1270, -0.3044,  ..., -0.3831,  0.3716, -0.0528],\n",
       "          [-0.2727,  0.1846, -0.2267,  ..., -0.3457,  0.3621, -0.0464],\n",
       "          [-0.2505,  0.1112, -0.2915,  ..., -0.2922,  0.3550, -0.0878]],\n",
       "\n",
       "         [[-0.0768,  0.0264,  0.0457,  ..., -0.0558, -0.0961,  0.1919],\n",
       "          [ 0.1715,  0.0339, -0.0473,  ...,  0.1626,  0.1016,  0.2725],\n",
       "          [ 0.2404,  0.2881,  0.0122,  ...,  0.4131,  0.0071,  0.4631],\n",
       "          ...,\n",
       "          [ 0.1520,  0.2094, -0.1868,  ..., -0.1087, -0.1259,  0.3232],\n",
       "          [ 0.1278,  0.1648, -0.1422,  ..., -0.1140, -0.0902,  0.2773],\n",
       "          [ 0.1737,  0.2893, -0.1832,  ..., -0.0402, -0.1503,  0.3335]]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<TransposeBackward0>)), (tensor([[[[-1.1084e-01, -4.4373e-02,  2.2388e-01,  ...,  1.2366e-01,\n",
       "            5.2295e-01, -5.8789e-01],\n",
       "          [ 3.0298e-01,  4.5380e-02,  8.9062e-01,  ..., -4.9023e-01,\n",
       "            7.7930e-01, -8.2080e-01],\n",
       "          [ 8.8574e-01,  9.2102e-02, -1.3928e-01,  ..., -1.2637e+00,\n",
       "            1.0430e+00, -1.6230e+00],\n",
       "          ...,\n",
       "          [ 6.8896e-01,  4.9194e-02,  8.9844e-02,  ..., -6.9385e-01,\n",
       "            6.0596e-01, -1.5615e+00],\n",
       "          [ 6.0156e-01, -2.5063e-03,  4.3152e-02,  ..., -8.8330e-01,\n",
       "            7.0557e-01, -1.8291e+00],\n",
       "          [-1.6724e-01,  1.7688e-01,  1.7468e-01,  ..., -9.0137e-01,\n",
       "            7.6221e-01, -1.4062e+00]],\n",
       "\n",
       "         [[ 3.2812e-01,  1.2537e-01,  2.5928e-01,  ...,  2.5977e-01,\n",
       "            2.0020e-01,  3.5889e-01],\n",
       "          [ 9.8828e-01,  6.6504e-01,  7.8491e-02,  ...,  7.4609e-01,\n",
       "            9.2383e-01,  9.7949e-01],\n",
       "          [ 3.5352e-01,  8.8086e-01,  1.4819e-01,  ...,  1.2219e-01,\n",
       "            8.9307e-01,  1.4717e+00],\n",
       "          ...,\n",
       "          [ 7.5195e-01, -1.0583e-01,  6.8799e-01,  ...,  8.4082e-01,\n",
       "            8.2471e-01,  1.7109e+00],\n",
       "          [ 2.2852e-01, -2.5464e-01,  2.0081e-01,  ...,  1.0264e+00,\n",
       "            7.7393e-01,  1.7773e+00],\n",
       "          [-2.7759e-01, -3.4595e-01, -3.1104e-01,  ...,  7.7734e-01,\n",
       "            5.6152e-01,  1.7041e+00]],\n",
       "\n",
       "         [[ 3.6987e-01,  6.9031e-02, -9.0149e-02,  ...,  8.7598e-01,\n",
       "            8.5156e-01, -1.5759e-01],\n",
       "          [-2.1765e-01,  1.6565e-01, -5.9814e-01,  ...,  6.4844e-01,\n",
       "            1.9141e+00,  2.3594e+00],\n",
       "          [-3.0786e-01,  6.1133e-01,  1.4844e-01,  ...,  5.7715e-01,\n",
       "            9.4482e-01,  1.4414e+00],\n",
       "          ...,\n",
       "          [-4.8853e-01, -2.0154e-01, -5.0488e-01,  ...,  2.7173e-01,\n",
       "            4.2871e-01,  9.3359e-01],\n",
       "          [-7.4170e-01, -2.1912e-01, -4.6387e-01,  ..., -1.8250e-01,\n",
       "            6.7090e-01,  9.5898e-01],\n",
       "          [-2.6343e-01, -2.3376e-01, -1.1920e-01,  ...,  2.2412e-01,\n",
       "            1.4209e-01,  1.0273e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.2578e-01, -5.1172e-01,  1.9812e-01,  ...,  1.7163e-01,\n",
       "           -2.0447e-02,  1.1367e+00],\n",
       "          [ 7.8711e-01,  7.1533e-02,  7.5879e-01,  ..., -1.2549e-01,\n",
       "            1.0000e+00,  2.3457e+00],\n",
       "          [-1.6113e-02,  4.9011e-02,  1.5039e+00,  ...,  8.6670e-01,\n",
       "           -2.5952e-01,  1.9580e+00],\n",
       "          ...,\n",
       "          [ 8.2910e-01,  3.2153e-01,  6.3818e-01,  ...,  9.5215e-01,\n",
       "            4.2896e-01,  3.1914e+00],\n",
       "          [-3.6035e-01, -5.2344e-01,  5.6299e-01,  ...,  8.5205e-01,\n",
       "            6.4160e-01,  3.3125e+00],\n",
       "          [-1.0654e+00, -9.4922e-01,  2.4890e-01,  ...,  1.2686e+00,\n",
       "            2.2058e-01,  3.2246e+00]],\n",
       "\n",
       "         [[-3.3740e-01, -1.3184e-01,  4.5349e-02,  ..., -7.0312e-01,\n",
       "            6.3770e-01,  2.0593e-01],\n",
       "          [-1.8542e-01, -1.6870e-01, -1.2964e-01,  ..., -3.5980e-02,\n",
       "            1.9512e+00,  1.1738e+00],\n",
       "          [-5.7373e-01,  3.0469e-01, -6.6113e-01,  ..., -3.4937e-01,\n",
       "            1.9072e+00,  1.5078e+00],\n",
       "          ...,\n",
       "          [-9.1064e-02,  2.2522e-01,  1.8726e-01,  ..., -8.0029e-01,\n",
       "            2.6230e+00, -7.0679e-02],\n",
       "          [ 3.3984e-01,  1.0193e-01,  2.3706e-01,  ..., -8.4668e-01,\n",
       "            2.8223e+00,  9.3506e-02],\n",
       "          [ 3.3472e-01,  1.8982e-01,  6.7566e-02,  ..., -1.1328e+00,\n",
       "            2.9395e+00,  1.0986e-01]],\n",
       "\n",
       "         [[ 1.9263e-01,  2.8760e-01,  5.6183e-02,  ...,  3.2861e-01,\n",
       "           -1.2031e+00, -1.2129e+00],\n",
       "          [-8.1738e-01,  7.1289e-01,  8.1543e-01,  ...,  7.2998e-02,\n",
       "           -1.0723e+00, -1.3887e+00],\n",
       "          [-5.8936e-01,  1.4526e-01,  1.3513e-01,  ...,  1.7688e-01,\n",
       "           -1.0928e+00, -2.5645e+00],\n",
       "          ...,\n",
       "          [-1.3086e+00, -4.9365e-01,  3.3008e-01,  ..., -4.8486e-01,\n",
       "           -8.3130e-02, -1.6895e+00],\n",
       "          [-1.4961e+00, -3.0933e-01,  3.5010e-01,  ..., -4.3286e-01,\n",
       "            3.4454e-02, -1.7783e+00],\n",
       "          [-5.7861e-02,  1.2769e-01,  1.5125e-01,  ..., -6.8945e-01,\n",
       "            2.0850e-01, -1.8076e+00]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[[ 0.1221, -0.2854, -0.5938,  ...,  0.3169, -0.0403,  0.2341],\n",
       "          [ 0.0320, -0.4856, -0.2878,  ...,  0.1262, -0.5728, -0.0961],\n",
       "          [ 0.3057, -0.6968, -0.5781,  ...,  0.4229, -0.4600,  0.0270],\n",
       "          ...,\n",
       "          [-0.1131, -0.5215, -0.5308,  ...,  0.3628, -0.3245,  0.0477],\n",
       "          [-0.1271, -0.6113, -0.4956,  ...,  0.3555, -0.4902,  0.0941],\n",
       "          [-0.1011, -0.5391, -0.5229,  ...,  0.3804, -0.4272, -0.0087]],\n",
       "\n",
       "         [[-0.2399,  0.0432,  0.0580,  ...,  0.1473,  0.0098, -0.2418],\n",
       "          [-0.3213, -0.2507,  0.0431,  ...,  0.3252, -0.1628, -0.1543],\n",
       "          [ 0.0070, -0.0039, -0.0589,  ...,  0.4670,  0.2340, -0.4009],\n",
       "          ...,\n",
       "          [-0.1333, -0.0424,  0.3777,  ...,  0.1667,  0.0198, -0.5029],\n",
       "          [-0.2267, -0.0601,  0.4370,  ...,  0.2024,  0.0714, -0.4902],\n",
       "          [-0.0955,  0.0423,  0.3979,  ...,  0.2310,  0.0900, -0.4846]],\n",
       "\n",
       "         [[-0.0153, -0.2207, -0.1947,  ...,  0.2520,  0.0260, -0.0646],\n",
       "          [-0.0850,  0.0897, -0.2942,  ...,  0.4175, -0.2585, -0.2644],\n",
       "          [-0.2629, -0.4082, -0.5229,  ...,  0.2017, -0.0347, -0.0755],\n",
       "          ...,\n",
       "          [ 0.0159, -0.2325, -0.0038,  ...,  0.3386, -0.2047,  0.0438],\n",
       "          [-0.0411, -0.2625, -0.0106,  ...,  0.3352, -0.1956,  0.0126],\n",
       "          [ 0.0023, -0.2732,  0.0381,  ...,  0.2485, -0.1719,  0.0458]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.2102, -0.0105,  0.0365,  ..., -0.0565, -0.0563,  0.1263],\n",
       "          [ 0.2023, -0.1310, -0.5239,  ..., -0.2629,  0.2401,  0.1614],\n",
       "          [-0.1749, -0.1376,  0.0471,  ..., -0.1820,  0.2783,  0.4590],\n",
       "          ...,\n",
       "          [-0.1810, -0.2302,  0.1072,  ..., -0.1309,  0.2161,  0.3623],\n",
       "          [-0.1564, -0.2842,  0.0791,  ..., -0.2048,  0.3005,  0.2371],\n",
       "          [-0.2238, -0.2446,  0.1315,  ..., -0.0756,  0.2078,  0.3398]],\n",
       "\n",
       "         [[-0.1246, -0.0571, -0.2402,  ..., -0.0750, -0.1444,  0.2461],\n",
       "          [-0.0334, -0.1582, -0.6982,  ..., -0.2661, -0.0230,  0.2664],\n",
       "          [ 0.1162,  0.0595, -0.6455,  ..., -0.0072, -0.1882,  0.4478],\n",
       "          ...,\n",
       "          [ 0.3567, -0.0679, -0.2037,  ...,  0.0790, -0.2296,  0.2878],\n",
       "          [ 0.3411, -0.0604, -0.1643,  ...,  0.0099, -0.2465,  0.1393],\n",
       "          [ 0.3948, -0.1026, -0.1652,  ...,  0.0875, -0.2208,  0.2261]],\n",
       "\n",
       "         [[ 0.1262,  0.2554,  0.0847,  ...,  0.1691,  0.0271, -0.0783],\n",
       "          [ 0.2198,  0.0048,  0.1039,  ..., -0.2417, -0.2712,  0.0079],\n",
       "          [ 0.4053,  0.0018,  0.6118,  ..., -0.2137,  0.0397, -0.0958],\n",
       "          ...,\n",
       "          [-0.0339,  0.0435, -0.1699,  ..., -0.1904, -0.3706, -0.0980],\n",
       "          [-0.0528,  0.0018, -0.2004,  ..., -0.0803, -0.3708, -0.0587],\n",
       "          [-0.0227,  0.0409, -0.0978,  ..., -0.2269, -0.3630, -0.0278]]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<TransposeBackward0>)), (tensor([[[[ 9.3994e-01, -5.8447e-01, -4.5258e-02,  ...,  3.2251e-01,\n",
       "           -1.0371e+00,  2.7393e-01],\n",
       "          [ 1.0469e+00,  3.7622e-01, -4.9951e-01,  ...,  9.9316e-01,\n",
       "           -1.4766e+00,  7.1191e-01],\n",
       "          [ 9.5215e-02, -1.1420e-01,  1.0925e-01,  ...,  7.9443e-01,\n",
       "           -1.3018e+00,  6.2109e-01],\n",
       "          ...,\n",
       "          [ 9.1064e-01,  9.1260e-01, -5.8154e-01,  ...,  1.1279e+00,\n",
       "           -1.5645e+00,  6.5918e-01],\n",
       "          [-5.1221e-01,  4.9048e-01, -6.5723e-01,  ...,  1.2256e+00,\n",
       "           -1.4561e+00,  6.6895e-01],\n",
       "          [-1.3506e+00, -2.0996e-02, -5.2344e-01,  ...,  1.2598e+00,\n",
       "           -1.4375e+00,  6.3135e-01]],\n",
       "\n",
       "         [[-4.0967e-01, -7.6355e-02, -3.2227e-01,  ...,  2.9668e+00,\n",
       "           -4.9731e-01, -1.9941e+00],\n",
       "          [ 3.7842e-01,  1.4233e-01, -9.2480e-01,  ...,  4.8867e+00,\n",
       "            7.7942e-02, -3.1270e+00],\n",
       "          [ 8.7256e-01,  5.5371e-01, -2.7319e-01,  ...,  4.6680e+00,\n",
       "           -9.6741e-02, -3.0898e+00],\n",
       "          ...,\n",
       "          [ 1.1074e+00, -1.3892e-01, -1.1328e+00,  ...,  5.4609e+00,\n",
       "           -7.5195e-01, -2.8984e+00],\n",
       "          [ 1.1064e+00, -6.2842e-01, -5.9082e-01,  ...,  5.5742e+00,\n",
       "           -6.5332e-01, -2.9551e+00],\n",
       "          [-1.4844e-01, -5.0830e-01,  1.7505e-01,  ...,  5.5703e+00,\n",
       "           -7.7490e-01, -3.1777e+00]],\n",
       "\n",
       "         [[-1.2183e-01, -1.5771e-01,  2.1936e-01,  ..., -9.6826e-01,\n",
       "            1.3477e-01, -3.6499e-01],\n",
       "          [ 4.9927e-02, -1.2930e+00, -3.3740e-01,  ..., -2.7969e+00,\n",
       "           -4.1846e-01, -3.4009e-01],\n",
       "          [-5.0781e-01, -2.5952e-01, -4.6692e-02,  ..., -1.9492e+00,\n",
       "           -7.6123e-01,  2.2852e-01],\n",
       "          ...,\n",
       "          [ 7.1289e-02,  8.7500e-01, -7.3486e-01,  ..., -1.3232e+00,\n",
       "           -1.3037e+00,  1.1650e+00],\n",
       "          [-7.3120e-02,  7.9639e-01, -1.1182e+00,  ..., -1.4521e+00,\n",
       "           -1.3926e+00,  1.1787e+00],\n",
       "          [-2.0935e-02, -1.5503e-01, -8.9160e-01,  ..., -1.3818e+00,\n",
       "           -1.3467e+00,  1.4082e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.4863e-01, -3.4766e-01,  3.9597e-03,  ...,  3.0020e+00,\n",
       "           -2.3379e+00,  2.6250e+00],\n",
       "          [ 1.2041e+00, -5.6543e-01, -2.6172e-01,  ...,  5.6602e+00,\n",
       "           -5.2148e+00,  3.0684e+00],\n",
       "          [ 1.3721e+00,  2.5195e-01, -1.7480e-01,  ...,  5.8008e+00,\n",
       "           -6.1914e+00,  3.9844e+00],\n",
       "          ...,\n",
       "          [ 2.2998e-01,  6.8018e-01,  1.4893e-02,  ...,  4.4531e+00,\n",
       "           -4.9922e+00,  2.7129e+00],\n",
       "          [ 1.1191e+00,  2.9346e-01,  2.9761e-01,  ...,  4.6680e+00,\n",
       "           -5.1523e+00,  2.9004e+00],\n",
       "          [ 1.0176e+00, -3.8989e-01,  3.3447e-01,  ...,  4.9570e+00,\n",
       "           -5.4141e+00,  2.7090e+00]],\n",
       "\n",
       "         [[-5.5615e-01, -3.4985e-01, -2.1973e-01,  ...,  3.1616e-01,\n",
       "           -5.0098e-01,  1.4570e+00],\n",
       "          [-2.1790e-01, -1.4404e-01, -7.7979e-01,  ..., -6.7383e-02,\n",
       "           -8.1934e-01,  2.2500e+00],\n",
       "          [ 4.7705e-01,  3.9551e-01, -3.6108e-01,  ..., -6.7871e-01,\n",
       "           -4.0454e-01,  2.8965e+00],\n",
       "          ...,\n",
       "          [ 4.1650e-01,  2.2668e-01, -3.5986e-01,  ..., -3.9635e-03,\n",
       "           -8.9294e-02,  2.1699e+00],\n",
       "          [ 6.6650e-01,  2.4384e-02, -3.3911e-01,  ...,  1.6370e-01,\n",
       "           -8.8928e-02,  2.1465e+00],\n",
       "          [ 2.4951e-01, -2.4487e-01,  7.2937e-02,  ..., -1.4062e-01,\n",
       "           -1.8509e-02,  2.4941e+00]],\n",
       "\n",
       "         [[-1.0004e-01, -3.1543e-01, -2.1765e-01,  ...,  7.3425e-02,\n",
       "            6.6016e-01, -9.3689e-02],\n",
       "          [ 2.8052e-01, -6.8604e-01,  3.0029e-01,  ...,  5.3741e-02,\n",
       "            2.5781e-01, -5.6787e-01],\n",
       "          [ 5.6201e-01, -6.8066e-01,  1.1982e+00,  ...,  2.9858e-01,\n",
       "            1.2461e+00, -9.2822e-01],\n",
       "          ...,\n",
       "          [ 6.2012e-02,  5.1855e-01,  6.2402e-01,  ...,  3.3252e-01,\n",
       "            1.2139e+00, -1.7908e-01],\n",
       "          [ 2.3621e-02,  5.3809e-01,  9.6436e-01,  ...,  3.2983e-01,\n",
       "            1.1172e+00, -3.3887e-01],\n",
       "          [-1.3135e-01,  4.0747e-01,  1.0977e+00,  ...,  2.5732e-01,\n",
       "            1.2891e+00, -3.9673e-01]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[[-0.2847, -0.1223,  0.4927,  ...,  0.1405,  0.3088, -0.0885],\n",
       "          [-0.2056, -0.3003,  0.3354,  ...,  0.2363,  0.5752,  0.0737],\n",
       "          [-0.2715, -0.4968,  0.4678,  ...,  0.1121,  0.1109,  0.1570],\n",
       "          ...,\n",
       "          [-0.2206,  0.0828,  0.7642,  ...,  0.0972,  0.6299,  0.0594],\n",
       "          [-0.2139,  0.1099,  0.6772,  ..., -0.0609,  0.6782,  0.0872],\n",
       "          [-0.1268,  0.1170,  0.7637,  ..., -0.0166,  0.5698,  0.0290]],\n",
       "\n",
       "         [[ 0.0827, -0.1992,  0.1600,  ...,  0.1051, -0.0512,  0.2510],\n",
       "          [-0.3994, -0.1940,  0.4705,  ...,  0.2325, -0.2056,  0.3945],\n",
       "          [ 0.3398, -0.4685,  0.2869,  ...,  0.8467, -0.3118,  0.7305],\n",
       "          ...,\n",
       "          [-0.0021, -0.1313,  0.5801,  ...,  0.3931,  0.1914,  0.1065],\n",
       "          [-0.0934, -0.1180,  0.5537,  ...,  0.2935,  0.2959,  0.0463],\n",
       "          [ 0.0200, -0.1276,  0.5259,  ...,  0.5811,  0.2031,  0.1207]],\n",
       "\n",
       "         [[ 0.1426, -0.0297, -0.0414,  ..., -0.1011,  0.1176,  0.0756],\n",
       "          [ 0.1761, -0.2346, -0.4705,  ...,  0.0019,  0.1694,  0.3918],\n",
       "          [-0.0836, -0.1293,  0.0701,  ..., -0.1914,  0.0627,  0.3120],\n",
       "          ...,\n",
       "          [ 0.0981, -0.2344,  0.0210,  ...,  0.2407, -0.0791,  0.3384],\n",
       "          [ 0.0859, -0.1487, -0.0059,  ...,  0.2947, -0.0895,  0.3271],\n",
       "          [ 0.1392, -0.2471,  0.0217,  ...,  0.3054, -0.0374,  0.2927]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0728, -0.0029, -0.0009,  ..., -0.0066, -0.0296,  0.0562],\n",
       "          [ 0.0153,  0.1483, -0.1438,  ..., -0.0114, -0.4458, -0.2878],\n",
       "          [ 0.2094,  0.1281, -0.1599,  ..., -0.0543, -0.2050, -0.1141],\n",
       "          ...,\n",
       "          [ 0.3384,  0.0371, -0.0941,  ...,  0.0243, -0.2539, -0.0606],\n",
       "          [ 0.3411,  0.0450, -0.0753,  ...,  0.0706, -0.2578, -0.1448],\n",
       "          [ 0.3340,  0.0385, -0.1669,  ...,  0.0131, -0.2583, -0.0932]],\n",
       "\n",
       "         [[ 0.3799, -0.0830,  0.0282,  ...,  0.1332,  0.1909, -0.2417],\n",
       "          [-0.0825,  0.1234, -0.1493,  ...,  0.4919,  0.8315, -0.0551],\n",
       "          [ 0.6191,  0.2715,  0.2964,  ...,  0.0717,  0.1681, -0.0905],\n",
       "          ...,\n",
       "          [ 0.2410, -0.0053,  0.0478,  ...,  0.0864,  0.4236, -0.1056],\n",
       "          [ 0.3027,  0.0110,  0.0948,  ...,  0.1506,  0.3940, -0.1622],\n",
       "          [ 0.4111,  0.0407, -0.0227,  ...,  0.0845,  0.4758, -0.2107]],\n",
       "\n",
       "         [[-0.2113, -0.2053, -0.2708,  ...,  0.2654,  0.3701,  0.2490],\n",
       "          [-0.1256, -0.1794, -0.1959,  ...,  0.5283,  0.2389, -0.6646],\n",
       "          [-0.0852, -0.1520, -0.2208,  ...,  0.7095,  0.8564,  0.2233],\n",
       "          ...,\n",
       "          [-0.1582, -0.4504,  0.3206,  ...,  0.1445,  0.2086,  0.3643],\n",
       "          [-0.1048, -0.5708,  0.3384,  ...,  0.1533,  0.1890,  0.3401],\n",
       "          [-0.1229, -0.3740,  0.2510,  ...,  0.2283,  0.2842,  0.4844]]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<TransposeBackward0>)), (tensor([[[[-2.3572e-01,  2.7206e-02, -1.7651e-01,  ..., -8.1885e-01,\n",
       "           -3.9819e-01,  3.6011e-01],\n",
       "          [ 3.2861e-01,  8.1177e-02,  3.9209e-01,  ..., -9.8926e-01,\n",
       "           -4.5776e-01,  9.2529e-01],\n",
       "          [ 7.5635e-01,  9.4922e-01,  5.6836e-01,  ..., -1.7383e+00,\n",
       "           -6.7188e-01,  1.2246e+00],\n",
       "          ...,\n",
       "          [-3.1494e-02, -3.0688e-01,  5.0684e-01,  ..., -3.9111e-01,\n",
       "           -6.3086e-01,  6.4648e-01],\n",
       "          [ 1.9971e-01, -7.2900e-01,  5.9961e-01,  ..., -1.1304e-01,\n",
       "           -6.1133e-01,  7.3535e-01],\n",
       "          [ 3.6133e-01, -7.2168e-01,  6.1768e-01,  ..., -8.3203e-01,\n",
       "           -6.3916e-01,  8.8623e-01]],\n",
       "\n",
       "         [[-1.4563e-01, -3.5767e-01, -3.2812e-01,  ..., -1.3940e-01,\n",
       "            4.0039e-01, -4.5093e-01],\n",
       "          [-2.4084e-01, -3.0713e-01, -4.8291e-01,  ...,  1.0657e-01,\n",
       "           -2.6636e-01, -3.6987e-01],\n",
       "          [-8.2715e-01, -1.1445e+00, -6.4087e-02,  ..., -5.0928e-01,\n",
       "            2.6245e-01, -8.6035e-01],\n",
       "          ...,\n",
       "          [-3.3325e-01,  3.1152e-01, -4.4775e-01,  ...,  7.3584e-01,\n",
       "            5.5762e-01, -4.8975e-01],\n",
       "          [-1.6235e-01,  6.2793e-01, -1.1072e-01,  ...,  1.0088e+00,\n",
       "            5.3320e-01, -4.7290e-01],\n",
       "          [-1.3611e-01,  3.0811e-01,  5.4102e-01,  ...,  8.7646e-01,\n",
       "            7.5195e-01, -5.6250e-01]],\n",
       "\n",
       "         [[ 2.2864e-01,  1.9763e-01,  1.4893e-01,  ..., -7.0752e-01,\n",
       "            8.5107e-01,  4.3872e-01],\n",
       "          [-9.8486e-01,  7.5879e-01, -5.0977e-01,  ..., -1.4766e+00,\n",
       "            8.3398e-01, -1.1475e-02],\n",
       "          [-1.6211e+00,  2.0874e-01, -8.7549e-01,  ..., -1.0312e+00,\n",
       "            1.3105e+00,  6.2061e-01],\n",
       "          ...,\n",
       "          [-4.8291e-01, -8.5938e-01, -3.2275e-01,  ..., -7.4268e-01,\n",
       "            1.3232e+00,  3.3618e-01],\n",
       "          [-7.0605e-01, -5.0586e-01, -8.5156e-01,  ..., -9.5166e-01,\n",
       "            1.5605e+00,  3.7109e-01],\n",
       "          [-6.7285e-01,  2.7271e-01, -9.3213e-01,  ..., -1.1074e+00,\n",
       "            1.4766e+00,  2.5366e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-9.4482e-02, -3.5718e-01, -7.0459e-01,  ...,  1.3447e+00,\n",
       "            1.1758e+00, -1.4734e-01],\n",
       "          [ 1.9385e-01, -4.8413e-01, -7.5977e-01,  ...,  1.3447e+00,\n",
       "            1.6455e+00,  3.5791e-01],\n",
       "          [-4.4800e-01,  1.3660e-01,  7.8308e-02,  ...,  2.3203e+00,\n",
       "            2.6836e+00, -7.7539e-01],\n",
       "          ...,\n",
       "          [-4.1016e-02,  3.9600e-01, -8.3887e-01,  ...,  1.6436e+00,\n",
       "            2.5098e+00, -5.5908e-01],\n",
       "          [-6.5234e-01,  1.6638e-01, -2.0508e-01,  ...,  1.5947e+00,\n",
       "            2.5332e+00, -3.7744e-01],\n",
       "          [-4.8096e-01, -1.5735e-01,  3.3936e-01,  ...,  1.5732e+00,\n",
       "            2.7930e+00, -7.0215e-01]],\n",
       "\n",
       "         [[-5.3192e-02,  2.0813e-01, -1.7334e-01,  ..., -7.2852e-01,\n",
       "           -5.8057e-01,  6.5078e+00],\n",
       "          [-3.1934e-01,  1.9788e-01, -3.4814e-01,  ..., -1.5195e+00,\n",
       "           -2.0279e-02,  1.0289e+01],\n",
       "          [-4.2578e-01,  2.3718e-01, -2.8052e-01,  ..., -1.2031e+00,\n",
       "           -8.9355e-01,  1.1984e+01],\n",
       "          ...,\n",
       "          [-4.5142e-01, -7.4023e-01,  9.6008e-02,  ..., -1.5713e+00,\n",
       "            1.9348e-01,  1.0477e+01],\n",
       "          [-2.0996e-02, -6.2793e-01,  8.5831e-04,  ..., -1.7041e+00,\n",
       "            2.6343e-01,  1.0758e+01],\n",
       "          [ 2.3047e-01, -1.5186e-01,  6.9458e-02,  ..., -1.5752e+00,\n",
       "            1.1673e-02,  1.1148e+01]],\n",
       "\n",
       "         [[-2.9053e-01,  1.2683e-01,  4.4434e-02,  ...,  1.1240e+00,\n",
       "            6.3171e-02,  8.4180e-01],\n",
       "          [-9.8340e-01,  1.0425e-01,  3.6816e-01,  ...,  1.1729e+00,\n",
       "            1.1387e+00,  2.4492e+00],\n",
       "          [-6.6943e-01, -1.0602e-01,  1.0388e-01,  ...,  3.3066e+00,\n",
       "            1.4629e+00,  1.0391e+00],\n",
       "          ...,\n",
       "          [-8.9307e-01,  2.5952e-01,  1.5723e-01,  ...,  2.2773e+00,\n",
       "            2.3352e-01,  1.3320e+00],\n",
       "          [ 1.6174e-01,  2.3300e-02,  1.6516e-01,  ...,  2.2695e+00,\n",
       "            8.4351e-02,  1.3799e+00],\n",
       "          [ 9.1943e-01, -3.9233e-01,  1.5259e-01,  ...,  2.7324e+00,\n",
       "            3.1152e-01,  1.4258e+00]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[[ 0.1415,  0.3264,  0.0961,  ..., -0.1755,  0.0674,  0.2401],\n",
       "          [ 0.1093,  0.2900,  0.2312,  ..., -0.6406,  0.5234,  0.0759],\n",
       "          [ 0.1456,  0.0860,  0.2455,  ..., -0.7881, -0.0868,  0.3247],\n",
       "          ...,\n",
       "          [-0.0973,  0.2175,  0.0602,  ..., -0.2837, -0.1099,  0.1550],\n",
       "          [ 0.0043,  0.1055,  0.1461,  ..., -0.2903, -0.0873,  0.1710],\n",
       "          [-0.1844,  0.2617,  0.0448,  ..., -0.3457, -0.1312,  0.2477]],\n",
       "\n",
       "         [[ 0.1294, -0.1440,  0.5488,  ...,  0.4155,  0.5933,  0.0774],\n",
       "          [-0.2517, -0.1522,  0.8149,  ...,  0.4524,  0.9634, -0.3723],\n",
       "          [-0.3098, -0.3083,  1.0371,  ...,  0.0485,  0.5479,  0.0395],\n",
       "          ...,\n",
       "          [ 0.1002,  0.0133,  0.5137,  ...,  0.4399,  0.6035, -0.1418],\n",
       "          [ 0.0905,  0.0737,  0.6069,  ...,  0.5337,  0.6753, -0.0944],\n",
       "          [ 0.0834,  0.0801,  0.5874,  ...,  0.3984,  0.5220, -0.1157]],\n",
       "\n",
       "         [[ 0.2037,  0.4426,  0.2998,  ...,  0.2834,  0.0046,  0.1450],\n",
       "          [ 0.0018,  0.8369,  0.3633,  ..., -0.0045,  0.2583, -0.5391],\n",
       "          [ 0.4626,  0.7744,  0.3062,  ...,  0.0691,  0.3914,  0.3467],\n",
       "          ...,\n",
       "          [-0.1760,  0.1400,  0.1598,  ...,  0.0580,  0.0918,  0.3950],\n",
       "          [-0.1179,  0.2372,  0.1520,  ...,  0.1312,  0.1538,  0.4087],\n",
       "          [-0.0906,  0.1917,  0.2529,  ..., -0.0098,  0.0779,  0.4243]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.3000,  0.3816,  0.2937,  ..., -0.2244,  0.3298, -0.1405],\n",
       "          [ 0.5815,  0.4324,  0.4556,  ...,  0.1892,  0.2920, -0.2649],\n",
       "          [ 0.8110,  0.4583,  0.3718,  ...,  0.4360,  0.2625,  0.0330],\n",
       "          ...,\n",
       "          [ 0.7246,  0.3306,  0.1793,  ...,  0.2715,  0.1587,  0.0193],\n",
       "          [ 0.7300,  0.3340,  0.2236,  ...,  0.2610,  0.1621,  0.0897],\n",
       "          [ 0.6846,  0.3250,  0.2111,  ...,  0.1892,  0.1465,  0.0773]],\n",
       "\n",
       "         [[-0.0895,  0.0452, -0.1846,  ...,  0.1301,  0.3511,  0.1229],\n",
       "          [-0.4343,  0.0829, -0.3755,  ...,  0.0878, -0.1639, -0.1980],\n",
       "          [-0.1305,  0.3608, -0.7866,  ...,  0.1545,  0.3511, -0.0879],\n",
       "          ...,\n",
       "          [-0.2554,  0.1180, -0.2390,  ..., -0.0090,  0.1129, -0.2155],\n",
       "          [-0.2299,  0.1085, -0.2527,  ...,  0.0803,  0.1720, -0.2559],\n",
       "          [-0.2427,  0.0262, -0.2322,  ...,  0.0219,  0.1754, -0.2053]],\n",
       "\n",
       "         [[ 0.2495,  0.0779, -0.2688,  ..., -0.0938,  0.1625, -0.1530],\n",
       "          [ 0.2954, -0.2191, -0.7744,  ..., -0.0127,  0.1827,  0.0726],\n",
       "          [ 0.1349,  0.1604, -0.4795,  ..., -0.0270,  0.2288, -0.0309],\n",
       "          ...,\n",
       "          [ 0.1658,  0.1327, -0.4316,  ..., -0.0195,  0.0895, -0.4216],\n",
       "          [ 0.2445,  0.1522, -0.4348,  ..., -0.0804, -0.0203, -0.2988],\n",
       "          [ 0.2120,  0.0934, -0.4094,  ...,  0.0221,  0.0733, -0.3044]]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<TransposeBackward0>)), (tensor([[[[ 0.4575,  0.3018,  0.0844,  ...,  0.1091, -0.4934,  0.6987],\n",
       "          [-0.1460,  1.2109,  0.6255,  ...,  0.8101, -0.8062,  1.3389],\n",
       "          [-1.0566,  0.5688, -0.1249,  ..., -0.1873, -0.2062,  2.3008],\n",
       "          ...,\n",
       "          [-0.1914, -0.8394,  0.4048,  ...,  0.0310, -0.1453,  1.6592],\n",
       "          [-0.7881, -0.7568,  0.2725,  ...,  0.5566, -0.3845,  1.5566],\n",
       "          [-0.5791, -0.0676,  0.1475,  ...,  0.3013, -0.1864,  1.4307]],\n",
       "\n",
       "         [[-0.9932, -0.1431,  0.1910,  ..., -0.9067,  2.4434, -0.2455],\n",
       "          [-0.5630, -0.2145,  0.8096,  ..., -1.0996,  3.4316, -1.3135],\n",
       "          [ 0.7168, -0.0607,  0.1848,  ..., -1.0928,  2.2188, -0.0852],\n",
       "          ...,\n",
       "          [ 0.2500, -0.3840,  0.7168,  ...,  0.3730,  3.3438, -0.3867],\n",
       "          [ 1.7676, -0.9863,  0.8970,  ...,  0.7603,  3.4121, -0.4683],\n",
       "          [ 1.3477, -0.7192,  0.7046,  ...,  0.5200,  3.2578, -0.4487]],\n",
       "\n",
       "         [[ 0.1990, -0.5615, -0.5337,  ...,  0.1009,  1.3555, -0.4275],\n",
       "          [-0.2277, -1.5879, -0.4258,  ..., -0.3809,  1.7002, -1.0068],\n",
       "          [-0.7236, -1.1201, -0.3533,  ..., -2.0605,  2.7617, -0.1400],\n",
       "          ...,\n",
       "          [-1.0986,  1.4160, -0.2678,  ..., -1.0908,  1.6924, -0.7407],\n",
       "          [-1.4424,  1.4316, -0.0776,  ..., -0.8926,  1.5273, -0.5054],\n",
       "          [-0.2927,  0.4502,  0.1653,  ..., -1.3750,  1.9932, -0.7764]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.3689,  0.4744,  0.0903,  ...,  0.9785, -1.8838, -1.8867],\n",
       "          [ 0.5571,  0.8042,  1.0029,  ...,  0.6484, -3.2109, -2.8809],\n",
       "          [ 0.1011, -0.4941,  0.6987,  ...,  2.1855, -3.5859, -2.4629],\n",
       "          ...,\n",
       "          [ 0.5605, -0.6504,  0.8311,  ...,  1.0479, -2.0547, -2.4961],\n",
       "          [-0.7822, -0.1069,  0.9702,  ...,  1.0459, -2.3359, -2.1758],\n",
       "          [-1.2764,  0.4541,  0.6240,  ...,  1.2422, -2.4961, -2.2383]],\n",
       "\n",
       "         [[-0.7329, -0.6870, -0.5498,  ..., -0.5127, -0.3386,  4.1328],\n",
       "          [ 0.1479, -0.5366, -0.0808,  ..., -0.8770, -0.6685,  6.7617],\n",
       "          [ 1.4189, -0.2362,  0.3977,  ..., -0.1559,  0.1881,  5.8398],\n",
       "          ...,\n",
       "          [ 0.4634,  0.5825, -0.2620,  ..., -1.2441,  0.5034,  5.1836],\n",
       "          [ 2.1777,  0.3159,  0.3955,  ..., -1.3828,  0.5356,  5.4961],\n",
       "          [ 1.5830, -0.2200,  0.9258,  ..., -0.7476,  0.3516,  5.3398]],\n",
       "\n",
       "         [[-0.3330,  0.1866,  0.0615,  ...,  0.0322,  0.2330,  1.0635],\n",
       "          [-0.0293, -0.3379,  0.4873,  ..., -0.6211,  1.4219,  1.5430],\n",
       "          [ 0.7041, -0.6113, -0.1842,  ..., -0.6055,  1.2969,  0.5884],\n",
       "          ...,\n",
       "          [ 0.4136,  0.4380,  0.1910,  ...,  0.3613,  0.8545, -0.3931],\n",
       "          [ 0.9395,  0.8213,  0.1465,  ...,  0.3762,  1.0059, -0.2537],\n",
       "          [ 0.3726,  0.6411, -0.0712,  ...,  0.5073,  1.2393, -0.2032]]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[[-0.2131, -0.0222,  0.5830,  ..., -0.4397, -0.2693,  0.0615],\n",
       "          [-0.2893, -0.6553,  0.7744,  ...,  0.2460, -0.0101, -0.0310],\n",
       "          [-0.1451,  0.3215,  0.1505,  ...,  0.0645, -0.0619, -0.1990],\n",
       "          ...,\n",
       "          [-0.3450,  0.0050,  0.5186,  ..., -0.1558,  0.0544,  0.0118],\n",
       "          [-0.4473,  0.0148,  0.4646,  ...,  0.0551,  0.0616, -0.0629],\n",
       "          [-0.2496, -0.0392,  0.4451,  ..., -0.0847,  0.0059, -0.0393]],\n",
       "\n",
       "         [[ 0.3113,  0.2009, -0.1427,  ...,  0.3208, -0.5776,  0.0345],\n",
       "          [ 0.9058,  0.3652, -0.0271,  ..., -0.1422, -0.0801,  0.4326],\n",
       "          [ 0.0068,  0.3870, -0.8354,  ..., -1.0723, -0.7339, -0.0979],\n",
       "          ...,\n",
       "          [ 0.1411, -0.2467,  0.0017,  ..., -0.0508, -0.0477,  0.0400],\n",
       "          [ 0.1986,  0.0222,  0.0698,  ..., -0.1807,  0.1598,  0.0236],\n",
       "          [ 0.1133,  0.0723, -0.2935,  ..., -0.2393,  0.1156, -0.0457]],\n",
       "\n",
       "         [[ 0.2030, -0.0222,  0.1748,  ...,  0.0455,  0.0551, -0.1389],\n",
       "          [-0.5391, -0.2047,  0.2246,  ..., -0.2352,  0.1346, -0.1768],\n",
       "          [-0.1615, -0.1941,  0.2717,  ...,  0.1332,  0.1471, -0.3643],\n",
       "          ...,\n",
       "          [-0.0468, -0.1698,  0.1838,  ...,  0.1357, -0.1285, -0.0442],\n",
       "          [-0.0959, -0.1393,  0.1392,  ...,  0.0718, -0.2534, -0.0693],\n",
       "          [-0.0558, -0.0922,  0.1433,  ...,  0.0718, -0.1282, -0.1379]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.3154,  0.1349, -0.1107,  ...,  0.1177,  0.1697,  0.2091],\n",
       "          [ 0.5327,  0.4192, -0.4124,  ...,  0.2341,  0.4683, -0.2086],\n",
       "          [ 0.2944,  0.1689, -0.1656,  ...,  0.2057,  0.3823, -0.6279],\n",
       "          ...,\n",
       "          [ 0.2299, -0.2517, -0.3628,  ...,  0.0919,  0.2961, -0.1901],\n",
       "          [-0.0653, -0.1151, -0.4585,  ..., -0.1025,  0.2563, -0.0339],\n",
       "          [ 0.1656, -0.1859, -0.3411,  ...,  0.1799,  0.3838, -0.1860]],\n",
       "\n",
       "         [[-0.2334, -0.3994, -0.0897,  ..., -0.0271, -0.0571,  0.1949],\n",
       "          [-0.1102, -0.5034,  0.0709,  ..., -0.2903, -0.2568, -0.3076],\n",
       "          [ 0.1523, -0.4851, -0.1166,  ..., -0.2474, -0.6533,  0.1285],\n",
       "          ...,\n",
       "          [-0.3638, -0.0658, -0.0287,  ...,  0.1423,  0.1239,  0.3933],\n",
       "          [-0.4905, -0.1147, -0.0552,  ...,  0.1646,  0.2303,  0.3181],\n",
       "          [-0.3789, -0.2310,  0.0055,  ...,  0.0580,  0.1589,  0.3303]],\n",
       "\n",
       "         [[ 0.2654, -0.1927,  0.2156,  ..., -0.1824, -0.1210,  0.1549],\n",
       "          [-0.2849, -0.1716,  0.3411,  ..., -0.3677, -0.0067, -0.0132],\n",
       "          [-0.2148, -0.0977,  0.6685,  ..., -0.4963, -0.3293,  0.2023],\n",
       "          ...,\n",
       "          [-0.6362,  0.2478,  0.2991,  ..., -0.5303, -0.0180,  0.5547],\n",
       "          [-0.4802,  0.2759,  0.3845,  ..., -0.5068,  0.0937,  0.5728],\n",
       "          [-0.5635,  0.2235,  0.4260,  ..., -0.5176,  0.0338,  0.5566]]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<TransposeBackward0>)), (tensor([[[[ 0.0253, -0.3386,  0.2576,  ..., -1.0312, -0.7837,  1.3242],\n",
       "          [-0.2979,  0.1034,  0.2412,  ..., -3.4648, -0.9189, -0.1947],\n",
       "          [-0.1722,  0.4629, -0.4736,  ..., -2.4844, -1.2529,  1.6650],\n",
       "          ...,\n",
       "          [ 0.1044,  0.1760,  0.1030,  ..., -2.1035, -0.0198,  0.8188],\n",
       "          [-0.0114,  0.0068, -0.1627,  ..., -1.9619, -0.2788,  0.7329],\n",
       "          [ 0.0298, -0.2241, -0.1627,  ..., -2.2754, -0.2159,  0.9116]],\n",
       "\n",
       "         [[ 0.0133, -0.3809, -0.5474,  ..., -0.6470,  0.6626,  0.0305],\n",
       "          [ 0.7559, -0.3667,  0.7607,  ..., -0.7388,  0.3076,  1.4893],\n",
       "          [ 0.1086, -0.0519,  0.4375,  ..., -1.1787,  0.1810,  1.3711],\n",
       "          ...,\n",
       "          [ 0.0063,  0.3770, -0.0533,  ..., -0.8872, -0.3704,  0.6235],\n",
       "          [-0.7969,  0.1154, -0.0191,  ..., -1.0371, -0.2981,  0.6035],\n",
       "          [-0.9297,  0.0683,  0.0736,  ..., -1.0977, -0.4185,  0.9624]],\n",
       "\n",
       "         [[-0.0743, -0.2766, -0.8237,  ...,  1.4824, -0.9897, -0.5850],\n",
       "          [ 0.1436, -0.5000,  0.2993,  ...,  1.7852, -0.8564, -1.4424],\n",
       "          [-0.1689, -0.4932,  1.2627,  ...,  3.0527, -1.3252, -0.2905],\n",
       "          ...,\n",
       "          [ 0.1831, -0.0219,  0.4460,  ...,  2.1094, -1.1289, -1.5732],\n",
       "          [ 1.1367, -0.0687,  1.1553,  ...,  2.0781, -1.1729, -1.6582],\n",
       "          [ 0.9009,  0.0326,  1.4355,  ...,  2.3535, -1.2969, -1.6797]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.5801,  0.1501, -0.3850,  ...,  0.6582,  0.5898,  0.2810],\n",
       "          [ 1.0625,  1.4561, -0.9028,  ...,  0.7798,  1.0020,  0.2354],\n",
       "          [ 0.6367,  0.8750, -0.6812,  ...,  1.7393,  1.3359,  0.0892],\n",
       "          ...,\n",
       "          [ 0.9990,  0.0526, -0.6411,  ...,  1.3242,  0.7212,  0.0945],\n",
       "          [ 0.2996,  0.0879, -1.1152,  ...,  1.3994,  0.6323,  0.5474],\n",
       "          [-0.9141, -0.1536, -0.7910,  ...,  1.6572,  0.6724, -0.0194]],\n",
       "\n",
       "         [[ 0.1055,  0.1310, -0.3767,  ...,  0.3567, -0.0724, -0.7959],\n",
       "          [ 0.0066,  0.0205, -0.4827,  ..., -1.0283,  0.3369, -0.3884],\n",
       "          [ 0.2299,  0.5684, -0.0403,  ..., -1.8682,  1.0527, -1.7197],\n",
       "          ...,\n",
       "          [-0.0369,  0.5146, -0.0076,  ..., -0.7690,  0.4622, -2.6445],\n",
       "          [-1.0225, -0.4600,  0.1492,  ..., -0.6362,  0.4739, -2.4082],\n",
       "          [-0.4517, -0.8604,  0.1428,  ..., -1.1523,  0.4270, -2.3672]],\n",
       "\n",
       "         [[-0.4805,  0.0043, -0.0902,  ..., -0.6377,  1.1289, -1.2881],\n",
       "          [ 0.2190,  0.3628, -0.2405,  ..., -0.4673,  2.0859, -1.1221],\n",
       "          [ 0.3096,  0.5718, -0.2637,  ...,  0.2524,  1.2939, -1.4932],\n",
       "          ...,\n",
       "          [ 0.6245, -0.0408, -0.0292,  ...,  1.4297,  1.2422, -1.1338],\n",
       "          [ 0.9014, -0.3303, -0.2073,  ...,  1.0537,  1.4102, -0.8062],\n",
       "          [ 0.2339, -0.2759, -0.1727,  ...,  1.3018,  1.2207, -0.9497]]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[[ 0.0124, -0.8340, -0.0058,  ...,  0.0781,  0.2588, -0.1247],\n",
       "          [-0.8682, -1.5420, -0.0168,  ..., -0.0723,  0.0862, -0.4475],\n",
       "          [-0.2352, -1.2178, -0.1068,  ..., -0.0325,  0.1505, -0.2456],\n",
       "          ...,\n",
       "          [-0.1702, -1.2188, -0.1299,  ..., -0.2358,  0.3281, -0.6680],\n",
       "          [-0.1478, -1.1270, -0.4167,  ..., -0.0861,  0.2280, -0.6655],\n",
       "          [-0.2803, -1.1992, -0.1567,  ..., -0.3813,  0.3757, -0.5718]],\n",
       "\n",
       "         [[-0.0830,  0.0387, -0.2419,  ..., -0.1819, -0.1310,  0.3367],\n",
       "          [-0.2422,  0.0579,  0.0159,  ..., -0.0759,  0.0656,  0.8057],\n",
       "          [-0.0040,  0.1006,  0.1161,  ..., -0.2373, -0.3677,  0.7290],\n",
       "          ...,\n",
       "          [ 0.0347, -0.0206, -0.2883,  ...,  0.2346, -0.5073,  0.5762],\n",
       "          [ 0.0536,  0.0064, -0.1946,  ...,  0.1575, -0.4006,  0.7251],\n",
       "          [ 0.1144, -0.1157, -0.1440,  ...,  0.1028, -0.6191,  0.5923]],\n",
       "\n",
       "         [[ 0.3447,  0.2495,  0.0396,  ..., -0.0658, -0.3501,  0.1718],\n",
       "          [ 0.0656,  0.1862, -0.1106,  ..., -0.2268, -0.5366,  0.1359],\n",
       "          [ 0.5605,  0.6626, -0.0237,  ..., -0.0975, -0.1689,  0.3022],\n",
       "          ...,\n",
       "          [ 0.2137,  0.4795, -0.2098,  ..., -0.4543, -0.2637,  0.4172],\n",
       "          [ 0.2083,  0.3120, -0.4426,  ..., -0.3555, -0.2477,  0.4683],\n",
       "          [ 0.3784,  0.4448, -0.2162,  ..., -0.4526, -0.3088,  0.3220]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0175,  0.1696, -0.2433,  ...,  0.0834,  0.0536,  0.4124],\n",
       "          [-0.0887,  0.1545, -0.4485,  ...,  0.0847,  0.2959,  0.6523],\n",
       "          [-0.1245,  0.4673,  0.0513,  ..., -0.1284,  0.2722,  1.0615],\n",
       "          ...,\n",
       "          [-0.0527,  0.0381,  0.1260,  ..., -0.4177,  0.2681,  0.4590],\n",
       "          [-0.0894, -0.0205,  0.0876,  ..., -0.4333,  0.2673,  0.4519],\n",
       "          [-0.1525,  0.0920,  0.1736,  ..., -0.5151,  0.3181,  0.6562]],\n",
       "\n",
       "         [[-0.2230, -0.4583,  0.1658,  ...,  0.0998,  0.0467, -0.0130],\n",
       "          [-0.4241, -0.4233,  0.4548,  ...,  0.0916,  0.3123, -0.0626],\n",
       "          [-0.1031, -0.3230,  0.2917,  ...,  0.3110,  0.0169,  0.2087],\n",
       "          ...,\n",
       "          [-0.1222, -0.2988,  0.2817,  ...,  0.1676,  0.1952, -0.1512],\n",
       "          [-0.1317, -0.2954,  0.3257,  ...,  0.1304,  0.2434, -0.0699],\n",
       "          [-0.0729, -0.3293,  0.3777,  ...,  0.1401,  0.2170, -0.1443]],\n",
       "\n",
       "         [[ 0.0872, -0.0637,  0.3276,  ...,  0.2452,  0.3452,  0.3787],\n",
       "          [-0.1710,  0.2500,  0.1692,  ...,  0.1438,  0.0997,  0.1964],\n",
       "          [ 0.2087,  0.2462,  0.0262,  ...,  0.1097, -0.0939,  0.4465],\n",
       "          ...,\n",
       "          [-0.3438, -0.1351, -0.0333,  ...,  0.2284,  0.2822,  0.1920],\n",
       "          [-0.1638, -0.0763, -0.1084,  ...,  0.2888,  0.2686,  0.0595],\n",
       "          [-0.2112, -0.2344,  0.0146,  ...,  0.1987,  0.2036,  0.1447]]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<TransposeBackward0>)), (tensor([[[[ 5.7526e-02,  2.8458e-02, -9.4055e-02,  ..., -1.0781e+00,\n",
       "            6.0254e-01,  1.2402e-01],\n",
       "          [-3.1006e-01,  5.4150e-01,  2.2583e-02,  ..., -8.4961e-01,\n",
       "            1.1230e+00,  5.1123e-01],\n",
       "          [-1.4038e-01,  1.0439e+00,  4.9561e-01,  ..., -7.6465e-01,\n",
       "            3.3661e-02, -8.6609e-02],\n",
       "          ...,\n",
       "          [ 1.2250e-01, -1.9983e-01, -2.4561e-01,  ..., -1.0388e-01,\n",
       "            3.4570e-01, -7.4280e-02],\n",
       "          [ 5.7666e-01, -1.4038e-01, -3.0228e-02,  ...,  3.3984e-01,\n",
       "            4.7974e-01, -2.9999e-02],\n",
       "          [ 1.9360e-01, -2.6306e-02,  4.1016e-02,  ..., -7.4463e-02,\n",
       "            2.2388e-01, -1.6235e-01]],\n",
       "\n",
       "         [[-1.9165e-01, -3.9819e-01,  6.7627e-01,  ..., -2.3438e+00,\n",
       "            1.5352e+00, -2.0000e+00],\n",
       "          [-8.9600e-02,  2.5781e-01,  4.8828e-02,  ..., -3.4355e+00,\n",
       "            4.0234e-01, -1.8779e+00],\n",
       "          [ 3.1934e-01,  2.6416e-01, -3.3984e-01,  ..., -3.6836e+00,\n",
       "            1.4756e+00, -3.2168e+00],\n",
       "          ...,\n",
       "          [ 8.4473e-02, -1.2177e-01,  1.2659e-01,  ..., -3.0156e+00,\n",
       "            9.6826e-01, -1.5293e+00],\n",
       "          [ 7.0020e-01, -4.5752e-01, -9.9243e-02,  ..., -3.4492e+00,\n",
       "            8.7500e-01, -1.8242e+00],\n",
       "          [ 5.6055e-01, -4.3164e-01, -4.6094e-01,  ..., -2.9473e+00,\n",
       "            9.5459e-01, -2.0098e+00]],\n",
       "\n",
       "         [[ 8.6975e-02, -1.9214e-01,  1.7861e+00,  ...,  2.8223e-01,\n",
       "            5.2344e-01,  4.1016e-01],\n",
       "          [ 8.0615e-01,  6.1523e-02,  1.0869e+00,  ..., -1.3145e-02,\n",
       "            2.0361e-01,  2.2375e-01],\n",
       "          [ 3.7744e-01,  7.2021e-01,  4.8926e-01,  ..., -8.4180e-01,\n",
       "            3.7598e-01,  4.2114e-01],\n",
       "          ...,\n",
       "          [-7.4512e-01, -8.0908e-01,  1.3691e+00,  ..., -9.2920e-01,\n",
       "            7.2363e-01,  1.7749e-01],\n",
       "          [-1.2979e+00, -1.4844e+00,  8.7598e-01,  ..., -7.7490e-01,\n",
       "            5.3564e-01,  4.4067e-01],\n",
       "          [-4.7607e-01, -1.2070e+00, -1.9531e-02,  ..., -7.5732e-01,\n",
       "            7.2803e-01,  4.9683e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.0137e+00, -7.5635e-01,  4.5557e-01,  ..., -5.8154e-01,\n",
       "            1.0918e+00,  1.0381e+00],\n",
       "          [ 7.9980e-01,  7.2754e-02,  3.3350e-01,  ..., -2.7637e-01,\n",
       "            9.8535e-01,  8.8721e-01],\n",
       "          [ 3.5669e-01,  8.9160e-01,  5.0244e-01,  ...,  1.4600e-01,\n",
       "            9.4385e-01,  7.6221e-01],\n",
       "          ...,\n",
       "          [ 1.2285e+00, -2.8613e-01,  7.2070e-01,  ..., -7.9395e-01,\n",
       "            1.3809e+00,  1.2734e+00],\n",
       "          [ 2.8687e-01, -7.8320e-01,  2.3950e-01,  ..., -8.0176e-01,\n",
       "            1.3174e+00,  1.6279e+00],\n",
       "          [-1.1123e+00, -5.8936e-01, -1.7090e-03,  ..., -6.1914e-01,\n",
       "            1.6357e+00,  1.5566e+00]],\n",
       "\n",
       "         [[ 6.2109e-01,  6.3477e-01,  7.2754e-01,  ..., -2.6758e+00,\n",
       "            6.6797e+00,  7.5244e-01],\n",
       "          [ 1.3496e+00,  8.3398e-01,  9.3164e-01,  ..., -2.1133e+00,\n",
       "            7.9141e+00,  9.3555e-01],\n",
       "          [ 6.0449e-01,  1.3757e-01,  9.2188e-01,  ..., -3.2188e+00,\n",
       "            8.2891e+00,  1.5430e+00],\n",
       "          ...,\n",
       "          [ 1.6895e+00, -3.7695e-01,  9.4629e-01,  ..., -2.3164e+00,\n",
       "            7.0039e+00,  1.7422e+00],\n",
       "          [ 1.3945e+00, -3.8110e-01,  5.9668e-01,  ..., -2.7324e+00,\n",
       "            7.4414e+00,  1.1553e+00],\n",
       "          [-3.2544e-01, -1.4294e-01, -4.9072e-02,  ..., -2.5703e+00,\n",
       "            7.5781e+00,  1.7197e+00]],\n",
       "\n",
       "         [[-2.0129e-01,  2.7417e-01,  1.2006e-01,  ..., -2.3809e+00,\n",
       "           -2.8564e-01, -6.0742e-01],\n",
       "          [ 1.2909e-02, -7.4609e-01, -1.9531e-02,  ..., -2.6758e+00,\n",
       "           -1.9150e+00, -1.2490e+00],\n",
       "          [ 3.4229e-01, -1.0010e+00, -1.4648e-02,  ..., -3.8203e+00,\n",
       "           -7.3828e-01, -2.1855e+00],\n",
       "          ...,\n",
       "          [ 5.0586e-01,  2.4756e-01,  2.8467e-01,  ..., -1.8848e+00,\n",
       "           -7.3193e-01, -1.9121e+00],\n",
       "          [ 2.2632e-01,  4.9170e-01, -4.1443e-02,  ..., -2.1445e+00,\n",
       "           -7.2607e-01, -1.9297e+00],\n",
       "          [-2.7344e-01,  3.2153e-01, -4.0967e-01,  ..., -2.3594e+00,\n",
       "           -9.5361e-01, -2.1797e+00]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[[-1.4636e-01,  5.9521e-01,  6.1066e-02,  ..., -7.4829e-02,\n",
       "           -1.8152e-01,  2.7319e-01],\n",
       "          [-2.8748e-02,  8.4570e-01,  8.8916e-01,  ..., -9.1614e-02,\n",
       "            2.1436e-01, -2.0325e-01],\n",
       "          [-3.0075e-02,  4.0601e-01,  2.9465e-02,  ...,  2.0950e-02,\n",
       "           -1.5576e-01,  8.7708e-02],\n",
       "          ...,\n",
       "          [-5.8984e-01,  3.8770e-01, -9.9365e-02,  ..., -7.0459e-01,\n",
       "           -3.5864e-01,  2.2119e-01],\n",
       "          [-5.2148e-01,  4.3726e-01, -2.1393e-02,  ..., -6.5771e-01,\n",
       "           -2.7856e-01,  1.7102e-01],\n",
       "          [-5.0049e-01,  3.8647e-01, -1.5906e-01,  ..., -5.7324e-01,\n",
       "           -3.3716e-01,  1.2390e-01]],\n",
       "\n",
       "         [[-2.6392e-01,  6.6185e-03,  2.2018e-02,  ...,  2.6489e-01,\n",
       "            3.7524e-01, -2.3834e-02],\n",
       "          [ 1.1865e-01, -3.7524e-01, -1.0376e-02,  ..., -1.2744e-01,\n",
       "            4.2480e-01,  3.3008e-01],\n",
       "          [-2.6733e-01,  5.8502e-02, -2.2644e-01,  ..., -1.2213e-01,\n",
       "            5.3418e-01, -2.0615e-02],\n",
       "          ...,\n",
       "          [-2.0056e-01, -1.5576e-01, -3.2227e-01,  ..., -4.7760e-02,\n",
       "            6.7383e-01, -1.4209e-01],\n",
       "          [-2.3828e-01, -5.3955e-01, -3.0640e-01,  ..., -1.3818e-01,\n",
       "            5.4150e-01, -6.4575e-02],\n",
       "          [-1.0962e-01, -1.5161e-01, -3.0151e-01,  ..., -2.0166e-01,\n",
       "            4.8267e-01,  2.1698e-02]],\n",
       "\n",
       "         [[-3.4473e-01, -5.9521e-01,  2.0050e-02,  ...,  2.2791e-01,\n",
       "            5.1709e-01,  8.8818e-01],\n",
       "          [-1.0974e-01, -9.7949e-01,  3.4497e-01,  ...,  7.3779e-01,\n",
       "            7.2119e-01,  6.8555e-01],\n",
       "          [-4.5197e-02, -3.1677e-02, -8.6212e-03,  ...,  2.4963e-02,\n",
       "            5.6445e-01,  7.2217e-01],\n",
       "          ...,\n",
       "          [-1.9958e-01, -6.0596e-01, -1.4172e-01,  ...,  6.1084e-01,\n",
       "            2.3206e-01,  6.0498e-01],\n",
       "          [ 3.9101e-03, -6.8408e-01, -1.0046e-01,  ...,  6.0498e-01,\n",
       "            2.8125e-01,  7.2363e-01],\n",
       "          [-2.7496e-02, -6.4795e-01, -5.2521e-02,  ...,  6.3672e-01,\n",
       "            3.1006e-01,  6.7627e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 7.2461e-01,  6.1963e-01, -1.4575e-01,  ..., -3.7549e-01,\n",
       "            2.5269e-01, -1.4563e-01],\n",
       "          [ 8.4180e-01,  2.3669e-01, -1.5137e-01,  ...,  1.6800e-02,\n",
       "            1.9409e-01, -3.6182e-01],\n",
       "          [ 9.5654e-01,  2.6440e-01, -2.4902e-01,  ..., -1.8213e-01,\n",
       "            1.1328e+00, -1.1673e-02],\n",
       "          ...,\n",
       "          [ 9.6826e-01,  3.8257e-01, -6.3135e-01,  ..., -1.2384e-01,\n",
       "            4.3555e-01, -2.6489e-01],\n",
       "          [ 1.0576e+00,  1.7419e-01, -6.9092e-01,  ..., -5.4749e-02,\n",
       "            5.0635e-01, -1.1542e-01],\n",
       "          [ 8.0859e-01,  2.4219e-01, -6.9727e-01,  ...,  8.8882e-03,\n",
       "            7.1826e-01, -2.8711e-01]],\n",
       "\n",
       "         [[-3.8208e-01,  4.3750e-01,  5.1514e-01,  ...,  7.7332e-02,\n",
       "           -9.0637e-02,  4.1718e-02],\n",
       "          [ 3.2764e-01,  2.8296e-01, -7.4097e-02,  ...,  4.6069e-01,\n",
       "           -2.5220e-01, -8.9844e-02],\n",
       "          [-3.9258e-01, -2.1973e-01,  3.0200e-01,  ...,  1.2708e-01,\n",
       "            4.7974e-01,  1.9821e-02],\n",
       "          ...,\n",
       "          [-7.0117e-01, -2.3575e-02,  1.0133e-05,  ..., -2.5903e-01,\n",
       "            1.5259e-01,  5.6201e-01],\n",
       "          [-4.8022e-01, -2.5122e-01, -2.0581e-01,  ..., -4.8340e-01,\n",
       "           -5.7716e-03,  3.7036e-01],\n",
       "          [-5.7520e-01, -9.8572e-02,  1.0150e-01,  ..., -2.3352e-01,\n",
       "            4.1840e-02,  3.7402e-01]],\n",
       "\n",
       "         [[-8.3069e-02, -2.2913e-01, -2.3169e-01,  ...,  9.4666e-02,\n",
       "            8.0750e-02, -5.5127e-01],\n",
       "          [ 2.4323e-02,  5.0385e-02,  1.4900e-02,  ...,  4.5624e-03,\n",
       "            1.4233e-01, -7.8320e-01],\n",
       "          [ 2.4939e-01, -2.1033e-01, -2.4988e-01,  ...,  1.2878e-01,\n",
       "           -9.0576e-02, -5.7568e-01],\n",
       "          ...,\n",
       "          [-2.2314e-01, -3.9795e-02, -2.8174e-01,  ...,  2.8076e-01,\n",
       "           -9.7900e-02, -4.4189e-01],\n",
       "          [-2.1313e-01, -2.3422e-02, -1.8567e-01,  ...,  1.9739e-01,\n",
       "            1.2718e-02, -4.2456e-01],\n",
       "          [-1.1737e-01, -1.0413e-01, -1.8799e-01,  ...,  1.5515e-01,\n",
       "           -8.3191e-02, -4.5654e-01]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[ 0.1417, -0.2455, -0.6772,  ...,  1.4658, -1.2627, -0.9219],\n",
       "          [-0.5371, -0.7827, -0.2455,  ...,  0.9746, -1.5967, -0.4302],\n",
       "          [-0.6606, -1.0459,  0.2766,  ...,  0.7490, -1.5654, -0.7778],\n",
       "          ...,\n",
       "          [-0.8740,  0.8047, -0.1758,  ...,  0.9985, -1.3916, -0.9780],\n",
       "          [-0.3376,  0.8594,  0.0558,  ...,  1.0674, -1.6719, -0.7637],\n",
       "          [ 0.5728,  0.4194,  0.3604,  ...,  0.8276, -1.4209, -0.9688]],\n",
       "\n",
       "         [[-0.9360,  0.7227,  0.3401,  ..., -0.6226, -1.0605, -0.6743],\n",
       "          [-0.2229, -0.1660, -0.1664,  ..., -1.7246, -0.7632,  0.1843],\n",
       "          [ 0.2893, -0.8389, -0.1222,  ..., -0.6157, -0.1156, -0.9727],\n",
       "          ...,\n",
       "          [-0.1204, -0.1018,  0.1674,  ...,  0.1164, -0.1443, -0.2690],\n",
       "          [-0.2734,  0.4233,  0.0193,  ..., -0.2585, -0.3831, -0.4309],\n",
       "          [-0.3130,  0.6685, -0.2136,  ...,  0.1427,  0.1622, -0.4697]],\n",
       "\n",
       "         [[-0.0080,  0.0443, -0.7900,  ..., -0.2678, -0.0281,  0.9214],\n",
       "          [-0.8545,  1.1855, -1.9141,  ..., -1.0996,  0.2079,  0.6245],\n",
       "          [-0.7432,  0.2810, -1.4795,  ..., -0.4326,  0.1072,  0.1226],\n",
       "          ...,\n",
       "          [-2.0078,  0.1157, -1.6543,  ..., -0.6406, -0.1836,  0.7627],\n",
       "          [-0.5127, -0.1844, -1.9707,  ..., -0.6226, -0.4397,  0.6118],\n",
       "          [ 1.4180, -0.0667, -1.3926,  ..., -0.3447, -0.0355,  0.6216]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.4260, -0.5435,  0.5864,  ...,  0.7554,  0.4929, -0.9106],\n",
       "          [ 0.3398, -0.8457,  0.8574,  ...,  0.9521,  0.8096, -1.0010],\n",
       "          [ 0.0437,  0.4558,  0.2217,  ...,  1.5215,  0.3613, -0.9834],\n",
       "          ...,\n",
       "          [ 0.2202, -0.1541,  0.4253,  ...,  1.0029,  0.1296, -1.1670],\n",
       "          [ 0.3284, -0.0682,  0.4761,  ...,  1.1904, -0.1108, -1.3213],\n",
       "          [ 0.3032, -0.0160,  0.1674,  ...,  1.1934,  0.1768, -1.0850]],\n",
       "\n",
       "         [[-0.0745, -0.0650, -0.3123,  ..., -0.2964, -0.0426,  0.3984],\n",
       "          [ 0.0709, -0.3745,  0.0967,  ..., -0.8882,  0.8472,  0.3301],\n",
       "          [ 0.1005,  0.1826,  0.3987,  ..., -0.7119,  0.8945, -0.3350],\n",
       "          ...,\n",
       "          [ 0.3628, -0.0048, -0.6616,  ..., -0.1299, -0.2874,  0.6611],\n",
       "          [ 0.1010,  0.0213, -0.6987,  ..., -0.1576, -0.1095,  0.7207],\n",
       "          [-0.1567, -0.2507, -0.2842,  ..., -0.0437, -0.1359,  0.6533]],\n",
       "\n",
       "         [[-0.2061, -0.0299,  0.5229,  ...,  0.5830, -1.5654, -0.5146],\n",
       "          [ 0.0951,  0.2340,  0.6362,  ...,  0.8286, -0.9985,  0.6729],\n",
       "          [ 1.3262,  0.5439,  0.4675,  ...,  0.1857, -2.2656,  0.3679],\n",
       "          ...,\n",
       "          [ 1.0869, -0.1204,  0.6221,  ...,  0.8579, -1.9189, -0.4712],\n",
       "          [ 1.6875, -0.6260,  0.5376,  ...,  0.8101, -2.1230, -0.3203],\n",
       "          [ 0.6484, -0.5879,  0.2073,  ...,  0.6768, -2.3613, -0.2549]]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[[ 0.3679,  0.3833,  0.6553,  ..., -0.2739,  0.2812, -0.0270],\n",
       "          [ 0.7466, -0.1616,  0.4385,  ..., -0.0047, -0.5732, -0.1927],\n",
       "          [ 0.3711,  0.3359,  0.3713,  ..., -0.4563, -0.2842, -0.3137],\n",
       "          ...,\n",
       "          [ 0.3237,  0.1733,  0.4800,  ..., -0.7485, -0.3486, -0.3203],\n",
       "          [ 0.1681,  0.1841,  0.4023,  ..., -0.6929, -0.5620, -0.2595],\n",
       "          [ 0.3716,  0.2864,  0.4001,  ..., -0.7466, -0.4294, -0.3738]],\n",
       "\n",
       "         [[-0.2208,  0.4714, -0.0265,  ..., -0.5815,  0.2041, -0.3496],\n",
       "          [-0.1243,  0.5376,  0.1466,  ..., -0.2517,  0.4836, -0.1884],\n",
       "          [-0.2615, -0.1011,  0.6680,  ..., -0.5601, -0.1591, -0.6489],\n",
       "          ...,\n",
       "          [ 0.1106,  0.0206,  0.2405,  ..., -0.2783,  0.0720, -0.5444],\n",
       "          [ 0.1744, -0.0015,  0.2529,  ..., -0.3274,  0.0667, -0.5029],\n",
       "          [ 0.1312, -0.1589,  0.3428,  ..., -0.2561,  0.0701, -0.6411]],\n",
       "\n",
       "         [[ 0.3323, -0.2201, -0.3042,  ...,  0.3445, -0.3564,  0.3079],\n",
       "          [ 0.5161, -0.2922,  0.2064,  ...,  0.2603, -0.4490,  0.7124],\n",
       "          [ 0.2739, -0.3481, -0.3076,  ...,  0.2705, -0.4019,  0.3386],\n",
       "          ...,\n",
       "          [ 0.5811, -0.5210,  0.1396,  ..., -0.0281, -0.2810,  0.3748],\n",
       "          [ 0.5347, -0.4319,  0.0986,  ...,  0.0156, -0.3364,  0.4880],\n",
       "          [ 0.4927, -0.5425,  0.0682,  ..., -0.0630, -0.2791,  0.4011]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0344,  0.1276,  0.1101,  ...,  0.3696, -0.3711, -0.0983],\n",
       "          [ 0.3047,  0.2034,  0.0542,  ..., -0.0885, -0.1879, -0.0357],\n",
       "          [-0.3398,  0.5757, -0.1527,  ...,  0.2976, -0.1927, -0.2932],\n",
       "          ...,\n",
       "          [-0.2571,  0.8013, -0.0066,  ..., -0.0746, -0.8169, -0.1132],\n",
       "          [-0.1241,  0.7891,  0.0555,  ..., -0.0143, -0.5801, -0.2710],\n",
       "          [-0.1242,  0.8062, -0.1383,  ..., -0.1931, -0.7769, -0.2380]],\n",
       "\n",
       "         [[ 0.6646, -0.1699, -0.1042,  ...,  0.2913,  0.0038, -0.0905],\n",
       "          [ 0.5693,  0.2034,  0.2449,  ...,  0.7329, -0.4453, -0.6646],\n",
       "          [ 0.4265,  0.0105,  0.0994,  ...,  0.4202, -0.7046, -0.2993],\n",
       "          ...,\n",
       "          [ 0.2050, -0.5659, -0.5234,  ...,  0.0763, -0.0025, -0.0407],\n",
       "          [ 0.2363, -0.3376, -0.5435,  ...,  0.0552, -0.0613,  0.0282],\n",
       "          [ 0.0380, -0.3784, -0.5815,  ...,  0.1521, -0.1968,  0.0903]],\n",
       "\n",
       "         [[-0.8340,  0.3945, -0.0262,  ..., -0.4014,  0.1132, -0.1313],\n",
       "          [-0.7500,  0.2842, -0.1471,  ..., -0.2231,  0.0445,  0.1298],\n",
       "          [-0.6123,  0.1222, -0.0195,  ..., -0.1484,  0.0824,  0.2505],\n",
       "          ...,\n",
       "          [-0.4846, -0.0416,  0.1234,  ..., -0.1592, -0.0422,  0.5781],\n",
       "          [-0.4719,  0.1051,  0.1792,  ..., -0.0731,  0.0712,  0.5273],\n",
       "          [-0.3721,  0.0341,  0.1354,  ..., -0.1199,  0.1160,  0.6260]]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<TransposeBackward0>)), (tensor([[[[ 7.6904e-02,  7.5244e-01,  7.3486e-01,  ...,  2.9863e+00,\n",
       "           -2.1851e-01,  4.9531e+00],\n",
       "          [ 9.0723e-01,  7.4219e-02,  3.7354e-01,  ...,  2.1621e+00,\n",
       "           -1.2148e+00,  7.2734e+00],\n",
       "          [ 8.7451e-01, -6.0645e-01, -1.3123e-03,  ...,  2.7129e+00,\n",
       "           -1.5955e-01,  7.2930e+00],\n",
       "          ...,\n",
       "          [ 2.2217e-01,  7.4463e-03,  3.8232e-01,  ...,  1.9375e+00,\n",
       "            3.3936e-01,  6.5469e+00],\n",
       "          [ 1.7871e-01,  3.3008e-01, -1.4783e-01,  ...,  2.1094e+00,\n",
       "            2.7637e-01,  6.5703e+00],\n",
       "          [-1.3965e-01,  3.8867e-01, -3.7598e-01,  ...,  2.1797e+00,\n",
       "            5.4443e-01,  7.0078e+00]],\n",
       "\n",
       "         [[ 1.4563e-01,  2.8833e-01,  3.5553e-02,  ..., -6.9763e-02,\n",
       "           -5.3945e+00,  1.7676e+00],\n",
       "          [-2.7051e-01, -1.8970e-01,  3.8818e-02,  ...,  4.7729e-01,\n",
       "           -7.7812e+00,  6.1572e-01],\n",
       "          [-3.5986e-01, -4.5923e-01,  1.0687e-01,  ..., -3.9453e-01,\n",
       "           -7.4727e+00,  2.3887e+00],\n",
       "          ...,\n",
       "          [-4.8608e-01,  7.7576e-02,  2.5586e-01,  ...,  5.2948e-02,\n",
       "           -6.4062e+00,  2.4102e+00],\n",
       "          [-6.1182e-01,  2.3706e-01, -1.1926e-01,  ...,  4.9512e-01,\n",
       "           -6.7070e+00,  2.2168e+00],\n",
       "          [-1.1658e-01,  2.6172e-01, -1.2854e-01,  ...,  5.1074e-01,\n",
       "           -6.6289e+00,  2.3086e+00]],\n",
       "\n",
       "         [[ 7.6807e-01,  1.9446e-01, -4.2627e-01,  ...,  2.5610e-01,\n",
       "            1.7832e+00, -1.0117e+00],\n",
       "          [ 5.2100e-01,  4.7119e-02, -2.9834e-01,  ...,  9.6631e-01,\n",
       "            2.1094e+00, -1.8457e+00],\n",
       "          [-8.4277e-01, -3.2275e-01,  2.2632e-01,  ..., -1.0229e-01,\n",
       "            1.7490e+00, -1.2686e+00],\n",
       "          ...,\n",
       "          [-3.7793e-01,  1.2158e-01, -3.3838e-01,  ..., -1.7737e-01,\n",
       "            1.5791e+00, -1.5469e+00],\n",
       "          [-1.0732e+00,  7.6611e-01,  2.8345e-01,  ...,  2.8760e-01,\n",
       "            1.8447e+00, -1.9932e+00],\n",
       "          [-5.1562e-01,  5.0586e-01,  5.7471e-01,  ..., -1.3916e-01,\n",
       "            1.6592e+00, -1.4072e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.8848e-01,  3.7061e-01, -7.8674e-02,  ...,  2.7617e+00,\n",
       "           -2.8008e+00, -8.0185e-03],\n",
       "          [ 2.6416e-01,  4.4507e-01, -1.1230e-01,  ...,  4.4297e+00,\n",
       "           -2.7500e+00,  1.0657e-01],\n",
       "          [ 1.5283e-01, -2.0569e-01,  8.3557e-02,  ...,  4.7695e+00,\n",
       "           -4.4219e+00,  7.0020e-01],\n",
       "          ...,\n",
       "          [ 1.8420e-01, -5.9875e-02, -1.7688e-01,  ...,  3.6133e+00,\n",
       "           -2.1055e+00, -2.7734e-01],\n",
       "          [ 1.0864e-01,  9.0454e-02,  8.0566e-03,  ...,  3.9746e+00,\n",
       "           -2.0293e+00, -3.0420e-01],\n",
       "          [-1.1707e-01,  1.8250e-01,  2.1533e-01,  ...,  3.8672e+00,\n",
       "           -2.3691e+00,  9.7778e-02]],\n",
       "\n",
       "         [[ 3.0859e-01, -2.8345e-01, -8.7509e-03,  ..., -2.0781e+00,\n",
       "            1.2139e+00, -2.2773e+00],\n",
       "          [ 5.5811e-01,  3.5791e-01, -3.0859e-01,  ..., -2.4727e+00,\n",
       "            2.1699e+00, -3.6270e+00],\n",
       "          [ 2.9834e-01,  6.0156e-01, -4.5923e-01,  ..., -3.1172e+00,\n",
       "            1.3447e+00, -4.6523e+00],\n",
       "          ...,\n",
       "          [ 6.4844e-01, -1.5649e-01, -1.6028e-01,  ..., -2.3320e+00,\n",
       "            2.8477e+00, -2.0059e+00],\n",
       "          [ 3.2227e-02, -6.3623e-01, -9.4910e-02,  ..., -2.5332e+00,\n",
       "            2.8516e+00, -2.1660e+00],\n",
       "          [-7.3242e-01, -5.1953e-01,  4.7150e-02,  ..., -2.7168e+00,\n",
       "            2.8535e+00, -2.5156e+00]],\n",
       "\n",
       "         [[-5.0079e-02, -4.9951e-01, -1.4221e-01,  ...,  8.8428e-01,\n",
       "            5.6396e-01, -3.7578e+00],\n",
       "          [ 1.1401e-01, -5.0098e-01, -2.3346e-02,  ...,  1.1475e+00,\n",
       "            6.2744e-01, -4.7969e+00],\n",
       "          [-5.2148e-01, -4.8682e-01, -7.1106e-02,  ...,  9.7021e-01,\n",
       "            1.1221e+00, -4.7852e+00],\n",
       "          ...,\n",
       "          [-1.2520e+00,  7.8516e-01, -4.0527e-02,  ...,  9.5166e-01,\n",
       "           -1.8408e-01, -5.5156e+00],\n",
       "          [-9.9121e-01,  3.2031e-01, -3.2031e-01,  ...,  1.0752e+00,\n",
       "           -3.6597e-01, -5.7305e+00],\n",
       "          [ 4.0649e-01, -2.0203e-01, -5.7227e-01,  ...,  1.1709e+00,\n",
       "           -1.2048e-01, -5.6328e+00]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[[-3.4595e-01,  1.7725e-01, -5.7465e-02,  ..., -6.3916e-01,\n",
       "           -2.7271e-01,  4.5068e-01],\n",
       "          [-6.1035e-01,  5.1953e-01,  3.3838e-01,  ..., -4.8755e-01,\n",
       "           -2.0837e-01,  4.1064e-01],\n",
       "          [-5.7812e-01,  1.3184e-01,  3.4082e-01,  ..., -5.3857e-01,\n",
       "           -1.5979e-01,  4.3359e-01],\n",
       "          ...,\n",
       "          [-3.0981e-01, -4.7949e-01,  7.6514e-01,  ..., -8.1445e-01,\n",
       "           -1.7810e-01, -9.6035e-04],\n",
       "          [-5.3662e-01, -4.2993e-01,  4.4336e-01,  ..., -6.4746e-01,\n",
       "            1.5356e-01, -1.7731e-02],\n",
       "          [-5.6152e-01, -2.0605e-01,  5.5615e-01,  ..., -4.7681e-01,\n",
       "            3.1052e-02,  5.9143e-02]],\n",
       "\n",
       "         [[ 6.4453e-01, -5.2783e-01,  4.0894e-01,  ...,  5.7812e-01,\n",
       "            6.9385e-01,  1.8286e-01],\n",
       "          [ 5.4749e-02, -1.5198e-01,  5.7080e-01,  ...,  4.7394e-02,\n",
       "            6.9189e-01,  2.9785e-01],\n",
       "          [ 1.0010e+00, -5.4047e-02,  4.4849e-01,  ...,  4.2458e-03,\n",
       "            5.6836e-01,  2.3962e-01],\n",
       "          ...,\n",
       "          [ 7.3633e-01, -4.5288e-01,  1.1310e-01,  ..., -3.3887e-01,\n",
       "            3.0518e-01,  5.0195e-01],\n",
       "          [ 6.6895e-01, -1.3416e-01,  1.5356e-01,  ..., -3.1567e-01,\n",
       "            2.9272e-01,  3.9233e-01],\n",
       "          [ 8.7939e-01, -4.9341e-01,  1.2878e-01,  ..., -2.9907e-01,\n",
       "            2.3779e-01,  5.5029e-01]],\n",
       "\n",
       "         [[ 6.0156e-01,  3.8062e-01, -7.9639e-01,  ..., -6.5918e-02,\n",
       "           -2.1008e-01, -4.2651e-01],\n",
       "          [ 4.8608e-01,  4.3262e-01,  2.2842e-02,  ..., -2.3999e-01,\n",
       "           -2.5586e-01, -5.4736e-01],\n",
       "          [ 6.8994e-01,  3.9575e-01, -5.2100e-01,  ..., -7.0068e-02,\n",
       "           -4.7192e-01, -4.4214e-01],\n",
       "          ...,\n",
       "          [ 1.7078e-01,  4.1443e-02, -4.2822e-01,  ...,  1.2927e-01,\n",
       "            2.5708e-01, -3.1836e-01],\n",
       "          [ 1.8848e-01, -1.1726e-02, -2.7051e-01,  ...,  5.2338e-02,\n",
       "            3.5767e-01, -3.9111e-01],\n",
       "          [ 1.8652e-01,  1.9054e-03, -4.4067e-01,  ...,  1.4795e-01,\n",
       "            1.2286e-01, -3.3569e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.6216e-01, -1.7078e-01,  2.0645e-02,  ..., -1.8103e-01,\n",
       "            3.9429e-01,  2.5732e-01],\n",
       "          [-5.6348e-01,  4.0741e-02, -3.4009e-01,  ..., -1.9141e-01,\n",
       "            3.3228e-01,  7.0459e-01],\n",
       "          [-4.4189e-01, -1.4783e-01,  3.7567e-02,  ...,  2.0129e-01,\n",
       "            5.0342e-01, -1.6983e-02],\n",
       "          ...,\n",
       "          [ 3.6841e-01,  6.5491e-02, -2.4609e-01,  ..., -1.8848e-01,\n",
       "            1.3818e-01, -5.6641e-02],\n",
       "          [ 3.4253e-01, -2.0251e-01, -2.9468e-01,  ..., -2.7856e-01,\n",
       "            1.4075e-01,  9.1064e-02],\n",
       "          [ 2.5659e-01,  1.9958e-02, -1.8054e-01,  ..., -1.3745e-01,\n",
       "            1.3696e-01, -3.5431e-02]],\n",
       "\n",
       "         [[-1.1304e-01,  3.6450e-01,  6.1719e-01,  ..., -5.8105e-01,\n",
       "           -7.1594e-02, -2.4292e-01],\n",
       "          [ 1.4381e-02,  1.4229e-03,  7.0850e-01,  ..., -4.4922e-01,\n",
       "           -3.9771e-01, -1.5735e-01],\n",
       "          [-2.2681e-01, -5.6793e-02,  8.2568e-01,  ..., -4.7998e-01,\n",
       "            4.1406e-01, -3.1494e-01],\n",
       "          ...,\n",
       "          [ 2.4011e-01,  1.1987e-01,  8.5645e-01,  ...,  7.6416e-02,\n",
       "            1.1066e-01, -1.6284e-01],\n",
       "          [ 1.4941e-01,  1.8738e-01,  7.0996e-01,  ..., -2.7026e-01,\n",
       "            1.8219e-02, -1.5637e-01],\n",
       "          [ 7.2815e-02,  1.0736e-01,  7.8809e-01,  ...,  4.7760e-02,\n",
       "            1.6467e-01, -5.4657e-02]],\n",
       "\n",
       "         [[ 1.1206e-01,  4.4678e-01, -6.2744e-01,  ..., -9.7168e-02,\n",
       "           -6.2451e-01, -3.4766e-01],\n",
       "          [ 1.1316e-01,  7.1143e-01, -2.5391e-01,  ..., -1.5686e-01,\n",
       "           -2.6270e-01, -2.0532e-01],\n",
       "          [ 7.2693e-02,  8.0420e-01, -6.3086e-01,  ..., -3.2788e-01,\n",
       "           -6.0693e-01, -6.5527e-01],\n",
       "          ...,\n",
       "          [-2.1838e-01,  2.0142e-01, -2.8687e-01,  ..., -4.2648e-03,\n",
       "           -5.4718e-02, -1.1633e-01],\n",
       "          [-1.2512e-01,  2.5073e-01, -3.1909e-01,  ..., -3.2532e-02,\n",
       "           -1.2842e-01,  3.7079e-02],\n",
       "          [-1.1017e-01,  2.3779e-01, -2.7783e-01,  ..., -1.1755e-01,\n",
       "           -1.7505e-01, -3.0350e-02]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[ 5.1308e-03, -2.8687e-01,  4.7485e-01,  ..., -5.0391e-01,\n",
       "            1.1221e+00,  1.8145e+00],\n",
       "          [ 8.2764e-01,  4.2023e-02,  9.0820e-02,  ...,  5.9692e-02,\n",
       "            1.2607e+00,  2.6055e+00],\n",
       "          [ 8.7891e-01,  3.5986e-01, -1.3330e-01,  ..., -2.3788e-02,\n",
       "            1.0215e+00,  2.4336e+00],\n",
       "          ...,\n",
       "          [ 7.4219e-01, -1.7529e-01,  2.6270e-01,  ..., -1.5322e+00,\n",
       "            8.4863e-01,  1.9473e+00],\n",
       "          [ 1.3110e-01, -3.2202e-01, -2.5879e-02,  ..., -1.6445e+00,\n",
       "            9.0234e-01,  1.9258e+00],\n",
       "          [-5.5566e-01, -5.0635e-01, -3.7598e-01,  ..., -1.2695e+00,\n",
       "            7.7344e-01,  2.0508e+00]],\n",
       "\n",
       "         [[-3.0786e-01,  1.0321e-01, -1.8201e-01,  ..., -9.6289e-01,\n",
       "           -3.2070e+00,  1.3887e+00],\n",
       "          [ 5.0415e-02,  2.8687e-02, -3.8574e-01,  ..., -2.6836e+00,\n",
       "           -5.1172e+00,  2.0977e+00],\n",
       "          [ 3.2300e-01, -3.3398e-01, -1.3013e-01,  ..., -1.9736e+00,\n",
       "           -5.1172e+00,  1.7568e+00],\n",
       "          ...,\n",
       "          [ 2.3535e-01,  9.8694e-02, -3.4961e-01,  ..., -1.5488e+00,\n",
       "           -3.8945e+00,  3.0273e+00],\n",
       "          [ 4.7559e-01,  3.7085e-01, -1.7041e-01,  ..., -1.2480e+00,\n",
       "           -4.0234e+00,  2.8945e+00],\n",
       "          [ 2.6709e-01,  2.1167e-01, -1.4465e-02,  ..., -1.8438e+00,\n",
       "           -4.7656e+00,  2.5176e+00]],\n",
       "\n",
       "         [[-2.3279e-01,  4.5093e-01, -7.0947e-01,  ..., -6.0498e-01,\n",
       "           -1.7344e+00,  1.1064e+00],\n",
       "          [ 2.9492e-01,  2.5024e-01, -1.3672e+00,  ..., -2.0325e-01,\n",
       "           -2.0293e+00,  1.2344e+00],\n",
       "          [ 1.6650e-01,  3.8544e-02, -9.5752e-01,  ..., -5.6982e-01,\n",
       "           -2.5664e+00,  7.1094e-01],\n",
       "          ...,\n",
       "          [-1.2939e-02, -8.1348e-01, -8.8965e-01,  ..., -1.8037e+00,\n",
       "           -1.6514e+00,  1.3574e+00],\n",
       "          [ 6.7383e-01, -5.0537e-01, -7.2363e-01,  ..., -1.6611e+00,\n",
       "           -1.6602e+00,  1.3457e+00],\n",
       "          [ 2.3511e-01,  2.4756e-01, -2.9541e-01,  ..., -2.0801e+00,\n",
       "           -1.7295e+00,  1.0703e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.0933e-01, -3.1201e-01,  4.1138e-01,  ..., -6.8516e+00,\n",
       "           -1.5352e+00,  2.3169e-01],\n",
       "          [-2.0386e-01, -3.8501e-01,  1.3599e-01,  ..., -9.8672e+00,\n",
       "           -6.4014e-01,  4.6875e-01],\n",
       "          [-1.0571e-01,  2.9541e-02, -3.7842e-01,  ..., -9.7891e+00,\n",
       "           -6.4795e-01,  1.1621e+00],\n",
       "          ...,\n",
       "          [ 7.3486e-02,  3.2288e-02,  5.2002e-01,  ..., -8.6875e+00,\n",
       "           -9.3066e-01, -1.7273e-01],\n",
       "          [ 3.8867e-01, -3.9978e-02,  2.6318e-01,  ..., -8.7578e+00,\n",
       "           -9.2920e-01, -1.2561e-01],\n",
       "          [ 2.4023e-01, -3.1274e-01, -4.4214e-01,  ..., -9.1719e+00,\n",
       "           -5.1221e-01,  3.5303e-01]],\n",
       "\n",
       "         [[ 2.2571e-01,  6.9971e-01, -3.7427e-01,  ...,  6.8477e+00,\n",
       "           -3.1177e-01,  7.4902e-01],\n",
       "          [-7.2363e-01,  7.0374e-02, -2.2925e-01,  ...,  9.5938e+00,\n",
       "            1.8340e+00,  2.2793e+00],\n",
       "          [-5.2100e-01,  6.2744e-02, -3.3252e-01,  ...,  8.3984e+00,\n",
       "           -7.8369e-01,  2.0586e+00],\n",
       "          ...,\n",
       "          [-3.7964e-01, -1.8823e-01,  1.1194e-01,  ...,  8.3125e+00,\n",
       "           -2.4023e+00,  1.6055e+00],\n",
       "          [-8.9453e-01,  2.9688e-01,  4.5972e-01,  ...,  8.7500e+00,\n",
       "           -1.8633e+00,  2.0215e+00],\n",
       "          [-4.8828e-01,  5.5518e-01,  3.1812e-01,  ...,  8.6641e+00,\n",
       "           -2.4004e+00,  2.4082e+00]],\n",
       "\n",
       "         [[ 5.7080e-01,  3.4714e-04, -3.6011e-01,  ..., -5.2100e-01,\n",
       "           -4.4297e+00,  3.0977e+00],\n",
       "          [ 2.1960e-01, -1.6846e-01, -4.8926e-01,  ..., -1.3750e+00,\n",
       "           -5.5742e+00,  3.7734e+00],\n",
       "          [-3.8647e-01,  2.2498e-01, -3.3325e-01,  ..., -1.3154e+00,\n",
       "           -5.7969e+00,  3.1133e+00],\n",
       "          ...,\n",
       "          [ 2.9102e-01,  1.3269e-01, -7.3975e-02,  ..., -2.1406e+00,\n",
       "           -4.0078e+00,  2.8379e+00],\n",
       "          [-9.6802e-02,  1.6800e-02, -1.2128e-01,  ..., -2.3711e+00,\n",
       "           -4.1250e+00,  3.2852e+00],\n",
       "          [-1.6211e-01, -3.7354e-01, -2.9858e-01,  ..., -2.4609e+00,\n",
       "           -4.3125e+00,  3.2480e+00]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[[-2.5171e-01,  9.7534e-02,  3.5425e-01,  ...,  8.6121e-02,\n",
       "           -2.6489e-01,  3.0420e-01],\n",
       "          [-8.9661e-02,  2.6270e-01,  3.6523e-01,  ..., -2.8320e-02,\n",
       "            1.7188e-01,  2.6587e-01],\n",
       "          [-2.9663e-01, -6.7200e-02,  1.3306e-01,  ...,  1.6003e-01,\n",
       "            3.3447e-01, -1.0651e-02],\n",
       "          ...,\n",
       "          [ 2.0798e-02,  3.7308e-03,  1.8066e-01,  ...,  2.6685e-01,\n",
       "            2.5586e-01,  3.0981e-01],\n",
       "          [-1.7126e-01,  9.3323e-02,  8.9172e-02,  ...,  2.9614e-01,\n",
       "            2.0569e-01,  3.4473e-01],\n",
       "          [-2.0630e-01, -7.6599e-03,  1.9763e-01,  ...,  2.5098e-01,\n",
       "            3.2959e-01,  2.5146e-01]],\n",
       "\n",
       "         [[ 3.0249e-01,  3.8794e-01, -8.1970e-02,  ..., -2.0605e-01,\n",
       "            1.6983e-02,  2.9663e-02],\n",
       "          [-9.8047e-01, -2.2607e-01,  7.4707e-01,  ..., -1.1045e+00,\n",
       "            1.9177e-01,  5.9619e-01],\n",
       "          [-6.5735e-02,  2.2290e-01,  1.0339e-01,  ..., -6.1768e-01,\n",
       "            1.2598e-01, -2.4768e-01],\n",
       "          ...,\n",
       "          [-2.9932e-01,  5.4834e-01,  3.0811e-01,  ..., -2.9816e-02,\n",
       "            1.6907e-01, -1.3171e-01],\n",
       "          [-3.8574e-01,  5.5273e-01,  5.1270e-01,  ..., -3.3154e-01,\n",
       "            1.7700e-01, -2.9907e-02],\n",
       "          [-4.3066e-01,  3.7354e-01,  4.6436e-01,  ..., -1.1798e-01,\n",
       "            2.3239e-02, -1.2610e-01]],\n",
       "\n",
       "         [[-4.1748e-01,  1.9763e-01,  5.4016e-02,  ..., -6.7090e-01,\n",
       "            1.7838e-02, -3.1445e-01],\n",
       "          [-5.7373e-01,  1.1810e-01,  1.1377e-01,  ..., -2.2241e-01,\n",
       "            2.1191e-01, -5.4102e-01],\n",
       "          [ 2.2070e-01,  3.6182e-01, -7.9285e-02,  ..., -5.2002e-01,\n",
       "           -3.1421e-01, -4.7754e-01],\n",
       "          ...,\n",
       "          [ 4.8779e-01,  8.4375e-01, -3.9795e-01,  ..., -2.2974e-01,\n",
       "           -1.9568e-01, -4.3066e-01],\n",
       "          [ 4.5020e-01,  9.1309e-01, -4.9219e-01,  ..., -8.3313e-02,\n",
       "           -3.0469e-01, -5.7568e-01],\n",
       "          [ 5.6738e-01,  8.8477e-01, -4.8584e-01,  ..., -2.8687e-01,\n",
       "           -3.0298e-01, -5.4590e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-5.0720e-02,  6.2988e-02,  3.3374e-01,  ...,  5.3369e-01,\n",
       "           -5.7812e-01, -5.8496e-01],\n",
       "          [ 1.1774e-01, -1.4929e-01,  7.1240e-01,  ...,  3.6865e-01,\n",
       "           -3.4326e-01, -6.0352e-01],\n",
       "          [-3.1958e-01,  3.7549e-01,  3.9893e-01,  ...,  1.7212e-01,\n",
       "           -3.2764e-01, -6.6260e-01],\n",
       "          ...,\n",
       "          [-5.0537e-01,  5.6915e-02,  3.2031e-01,  ...,  2.0370e-02,\n",
       "           -7.4414e-01,  3.0624e-02],\n",
       "          [-3.5522e-01, -1.1523e-01,  2.2559e-01,  ...,  2.6660e-01,\n",
       "           -8.0469e-01,  9.0881e-02],\n",
       "          [-3.9575e-01,  7.9346e-02,  2.7539e-01,  ...,  4.7188e-03,\n",
       "           -5.9375e-01,  1.0400e-01]],\n",
       "\n",
       "         [[ 3.3032e-01, -6.4941e-02, -8.3191e-02,  ..., -2.1997e-01,\n",
       "            3.6841e-01,  5.2441e-01],\n",
       "          [-3.4497e-01, -1.3586e-01, -9.7473e-02,  ..., -3.0518e-01,\n",
       "           -8.2458e-02, -6.2793e-01],\n",
       "          [ 3.1638e-04,  2.3169e-01,  1.0608e-01,  ..., -4.4918e-04,\n",
       "            2.9492e-01,  6.8945e-01],\n",
       "          ...,\n",
       "          [-1.6089e-01,  1.2134e-01,  5.4248e-01,  ...,  3.5498e-01,\n",
       "            7.9712e-02, -6.4307e-01],\n",
       "          [-1.9299e-01,  1.7578e-01,  5.8057e-01,  ...,  1.5222e-01,\n",
       "           -9.1309e-02, -3.4375e-01],\n",
       "          [-2.1472e-01,  5.1514e-02,  6.4111e-01,  ...,  3.7769e-01,\n",
       "            1.2061e-01, -3.4717e-01]],\n",
       "\n",
       "         [[ 2.3669e-01,  1.9629e-01,  1.2000e-01,  ...,  1.3623e-01,\n",
       "            4.8004e-02,  1.0760e-01],\n",
       "          [-1.4624e-01,  3.3545e-01,  3.7964e-01,  ...,  6.2646e-01,\n",
       "            9.1064e-02,  1.1420e-01],\n",
       "          [ 1.5967e-01,  5.4932e-01,  3.8916e-01,  ..., -2.0190e-01,\n",
       "            2.3035e-01,  1.4868e-01],\n",
       "          ...,\n",
       "          [ 3.2812e-01,  2.3804e-01,  2.2644e-01,  ...,  3.3423e-01,\n",
       "            2.8247e-01,  4.4360e-01],\n",
       "          [ 1.7957e-01,  2.2656e-01,  2.9248e-01,  ...,  3.0078e-01,\n",
       "            1.9873e-01,  4.2651e-01],\n",
       "          [ 2.0178e-01,  4.1113e-01,  2.4524e-01,  ...,  2.3071e-01,\n",
       "            1.9543e-01,  4.3701e-01]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[  0.1522,   0.7583,   0.3223,  ...,   1.0566,  -0.4763,   0.8647],\n",
       "          [  0.1348,   0.2544,   0.3152,  ...,   1.1211,  -0.3030,   1.5928],\n",
       "          [ -0.1154,  -1.1113,  -0.6465,  ...,   1.7988,  -0.5791,   1.4766],\n",
       "          ...,\n",
       "          [ -1.0352,  -0.3257,   0.0322,  ...,   0.4216,  -0.5420,   0.8755],\n",
       "          [ -0.4451,   0.0674,  -0.8433,  ...,   0.7446,  -0.4902,   0.7759],\n",
       "          [  0.7061,   0.4568,  -1.5938,  ...,   0.7715,  -0.6113,   0.8130]],\n",
       "\n",
       "         [[  0.3564,   0.4182,  -0.2917,  ...,  -0.0710,  -1.2930,   0.3511],\n",
       "          [ -0.3843,   0.6826,   0.1111,  ...,  -0.2135,  -1.1104,   0.2864],\n",
       "          [ -0.2239,   0.1329,  -0.1082,  ...,   0.2900,  -0.0497,   0.9473],\n",
       "          ...,\n",
       "          [ -0.0688,  -0.3013,  -0.5449,  ...,   0.3140,  -1.7559,   0.0558],\n",
       "          [ -0.9761,  -1.2295,  -0.5767,  ...,   0.2261,  -2.0781,   0.4814],\n",
       "          [ -0.6758,  -1.4570,  -0.6157,  ...,   0.1588,  -1.9814,   0.1989]],\n",
       "\n",
       "         [[  1.3750,   0.5527,  -0.0421,  ...,  -0.3284,  -4.1328,   0.8311],\n",
       "          [  1.0625,   0.9966,  -0.0596,  ...,   0.3025,  -6.1602,   0.8477],\n",
       "          [ -1.0254,   0.6221,  -0.0603,  ...,  -0.5654,  -5.8672,   1.5645],\n",
       "          ...,\n",
       "          [  0.5664,   0.5420,   0.3638,  ...,   0.2280,  -5.5703,   1.0527],\n",
       "          [ -0.7080,  -0.1492,  -0.2411,  ...,   0.3567,  -5.8711,   0.9976],\n",
       "          [ -1.5801,  -0.6011,  -0.8115,  ...,   0.3513,  -5.7891,   1.3252]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[  0.1085,  -0.3000,   0.1871,  ...,   0.7104,   0.7549,   0.1379],\n",
       "          [ -0.0581,  -0.0377,  -0.1626,  ...,  -0.4346,   1.0039,   0.2834],\n",
       "          [ -0.6245,   0.2954,  -0.1128,  ...,  -0.5654,   1.6846,   0.6968],\n",
       "          ...,\n",
       "          [ -0.2272,  -0.4663,   0.2157,  ...,   0.7861,   1.9248,   1.8271],\n",
       "          [ -0.2737,  -0.9443,   0.3472,  ...,   0.1005,   2.0352,   2.1426],\n",
       "          [ -0.2164,  -0.9629,   0.3188,  ...,   0.0261,   2.1074,   2.0020]],\n",
       "\n",
       "         [[ -0.3350,   0.2362,   0.1102,  ...,  -7.4648,  -1.0928,  -2.3086],\n",
       "          [  0.5474,   0.4756,   0.4946,  ..., -10.1406,  -0.3225,  -5.0195],\n",
       "          [  0.5728,   0.1328,   0.3210,  ...,  -9.4141,  -1.6836,  -3.6641],\n",
       "          ...,\n",
       "          [  0.8174,  -0.3811,   0.3247,  ...,  -8.9141,  -2.0371,  -3.3379],\n",
       "          [  0.3201,  -0.0137,   0.2769,  ...,  -9.0547,  -2.0430,  -3.4746],\n",
       "          [ -0.3694,   0.3198,   0.1938,  ...,  -9.1172,  -2.0273,  -3.5215]],\n",
       "\n",
       "         [[ -0.2135,  -0.5029,  -0.2401,  ...,   5.2461,   1.3105,  -0.7812],\n",
       "          [ -0.2190,  -0.3584,  -0.3428,  ...,   6.4336,   2.2578,  -0.3259],\n",
       "          [ -0.2261,   0.0513,  -0.0431,  ...,   6.0781,   2.6523,  -0.6738],\n",
       "          ...,\n",
       "          [ -0.7007,   0.2131,   0.0351,  ...,   4.5195,   0.5654,  -0.9448],\n",
       "          [ -0.7061,  -0.1672,   0.0908,  ...,   4.8555,   0.4890,  -0.9180],\n",
       "          [  0.2220,  -0.5771,   0.1364,  ...,   4.6289,   0.6870,  -0.9590]]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[[-1.0999e-01, -4.0479e-01, -1.3057e+00,  ..., -4.1113e-01,\n",
       "            2.9907e-01,  1.1045e+00],\n",
       "          [-3.3276e-01, -4.5435e-01, -1.2461e+00,  ..., -4.9854e-01,\n",
       "            2.7173e-01,  1.1221e+00],\n",
       "          [-1.6125e-01, -2.0154e-01, -1.2451e+00,  ..., -4.0161e-01,\n",
       "            4.6460e-01,  1.2510e+00],\n",
       "          ...,\n",
       "          [-7.2021e-01, -7.1631e-01, -1.0918e+00,  ...,  1.1273e-01,\n",
       "           -1.4758e-01,  8.8379e-01],\n",
       "          [-7.2510e-01, -6.8213e-01, -1.0439e+00,  ...,  5.7106e-03,\n",
       "           -1.5356e-01,  8.8281e-01],\n",
       "          [-6.6260e-01, -7.4316e-01, -1.2734e+00,  ...,  5.6793e-02,\n",
       "            4.2938e-02,  8.3691e-01]],\n",
       "\n",
       "         [[ 7.5146e-01,  1.5344e-01, -2.1655e-01,  ...,  8.7830e-02,\n",
       "            3.5449e-01, -2.6807e-01],\n",
       "          [ 8.1592e-01,  4.2065e-01,  3.4149e-02,  ..., -2.6416e-01,\n",
       "            3.4082e-01, -2.5293e-01],\n",
       "          [ 9.2236e-01,  4.5630e-01,  6.2561e-04,  ...,  2.7695e-02,\n",
       "            9.4580e-01,  1.8298e-01],\n",
       "          ...,\n",
       "          [ 1.9031e-01,  3.1860e-01,  1.4270e-01,  ...,  3.8892e-01,\n",
       "            9.1309e-01,  6.6064e-01],\n",
       "          [ 3.2666e-01,  3.6670e-01,  2.5586e-01,  ...,  3.1689e-01,\n",
       "            9.6094e-01,  4.3213e-01],\n",
       "          [ 1.3721e-01,  3.6230e-01,  2.8906e-01,  ...,  4.8413e-01,\n",
       "            9.5654e-01,  6.2500e-01]],\n",
       "\n",
       "         [[ 7.4585e-02,  2.8613e-01, -3.5278e-01,  ...,  3.7671e-01,\n",
       "            2.3535e-01, -4.0234e-01],\n",
       "          [-2.0251e-01,  1.9446e-01, -2.3730e-01,  ...,  6.2354e-01,\n",
       "            2.7783e-01, -7.3730e-01],\n",
       "          [-2.7124e-01,  5.4150e-01, -2.6074e-01,  ...,  5.0342e-01,\n",
       "            1.1237e-01, -4.0430e-01],\n",
       "          ...,\n",
       "          [-6.2891e-01,  9.0771e-01, -7.2168e-01,  ...,  8.7646e-01,\n",
       "            8.0627e-02, -8.2275e-01],\n",
       "          [-5.2832e-01,  8.9209e-01, -6.2158e-01,  ...,  1.0732e+00,\n",
       "            1.8628e-01, -9.5117e-01],\n",
       "          [-5.1074e-01,  9.9365e-01, -6.9287e-01,  ...,  9.0625e-01,\n",
       "            6.3110e-02, -8.4473e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.0430e-01, -3.2764e-01,  1.3290e-02,  ...,  6.3086e-01,\n",
       "           -1.0244e+00,  5.4102e-01],\n",
       "          [ 9.1064e-02, -9.6924e-02,  1.7566e-01,  ...,  6.9824e-01,\n",
       "           -6.1328e-01,  9.7885e-03],\n",
       "          [-5.4883e-01, -3.4570e-01, -6.0516e-02,  ...,  1.7151e-02,\n",
       "           -4.8633e-01,  2.9370e-01],\n",
       "          ...,\n",
       "          [-1.8872e-01, -5.8105e-02, -1.6138e-01,  ...,  8.1592e-01,\n",
       "           -5.0830e-01, -5.2704e-02],\n",
       "          [ 1.9028e-02, -2.3901e-01,  2.9590e-01,  ...,  8.3789e-01,\n",
       "           -3.2788e-01,  7.8308e-02],\n",
       "          [-1.3293e-01,  1.4595e-02,  8.0505e-02,  ...,  6.7480e-01,\n",
       "           -4.7339e-01,  2.2598e-02]],\n",
       "\n",
       "         [[ 1.9714e-01, -2.2168e-01, -1.0332e+00,  ..., -5.2673e-02,\n",
       "           -3.9185e-01, -2.6440e-01],\n",
       "          [-3.7695e-01, -1.4746e-01, -9.3555e-01,  ...,  1.7102e-01,\n",
       "           -2.9077e-01, -1.8335e-01],\n",
       "          [-8.9905e-02,  2.1835e-02, -8.0469e-01,  ..., -2.6831e-01,\n",
       "           -4.9316e-01, -2.7808e-01],\n",
       "          ...,\n",
       "          [-2.6807e-01,  1.1806e-03, -1.1221e+00,  ..., -2.9102e-01,\n",
       "           -1.2195e-01,  9.3460e-03],\n",
       "          [-2.7856e-01,  2.4857e-02, -1.2236e+00,  ..., -2.7368e-01,\n",
       "           -2.2241e-01, -1.3831e-01],\n",
       "          [-1.6614e-01,  1.2622e-01, -1.2080e+00,  ..., -3.6230e-01,\n",
       "           -1.1798e-01, -1.8542e-01]],\n",
       "\n",
       "         [[-3.7500e-01,  8.7061e-01,  3.1348e-01,  ..., -4.1290e-02,\n",
       "            2.1399e-01, -2.0508e-01],\n",
       "          [-5.4535e-02,  7.2656e-01,  5.0964e-02,  ..., -1.9617e-01,\n",
       "            4.9463e-01,  7.2266e-01],\n",
       "          [-4.3506e-01,  8.5303e-01,  3.4180e-02,  ..., -9.8682e-01,\n",
       "           -1.1151e-01,  3.3740e-01],\n",
       "          ...,\n",
       "          [-6.0156e-01, -1.5759e-01, -4.1040e-01,  ..., -2.3669e-01,\n",
       "            4.1382e-01,  1.3599e-01],\n",
       "          [-5.2539e-01, -8.5571e-02, -3.9526e-01,  ..., -2.4597e-01,\n",
       "            6.7871e-01,  3.2593e-02],\n",
       "          [-2.8906e-01, -1.6968e-01, -4.2993e-01,  ..., -4.6948e-01,\n",
       "            4.8828e-01,  2.5293e-01]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[ 5.9326e-01,  2.6562e-01,  6.4160e-01,  ...,  9.0479e-01,\n",
       "            4.6851e-01,  2.8223e+00],\n",
       "          [ 9.3506e-02, -4.2236e-01,  6.0156e-01,  ...,  1.8652e+00,\n",
       "            7.6270e-01,  3.5078e+00],\n",
       "          [-2.8589e-01, -7.4902e-01,  4.0430e-01,  ...,  5.3857e-01,\n",
       "            5.1611e-01,  5.6680e+00],\n",
       "          ...,\n",
       "          [ 2.1033e-01, -1.2695e-01,  4.5215e-01,  ...,  4.7217e-01,\n",
       "            1.2178e+00,  4.1094e+00],\n",
       "          [ 3.3154e-01, -2.6245e-01,  6.1523e-01,  ...,  5.0293e-01,\n",
       "            1.2705e+00,  4.1875e+00],\n",
       "          [ 1.4014e-01, -2.5195e-01,  3.1860e-01,  ...,  3.7769e-01,\n",
       "            1.2637e+00,  4.5000e+00]],\n",
       "\n",
       "         [[-2.0645e+00,  6.5918e-01,  7.8796e-02,  ..., -1.7178e+00,\n",
       "           -1.8652e+00, -8.1445e-01],\n",
       "          [-3.5645e-01,  8.0273e-01,  3.8086e-02,  ..., -1.7861e+00,\n",
       "           -1.9707e+00, -6.4404e-01],\n",
       "          [ 1.3076e+00,  3.7500e-01, -3.5571e-01,  ..., -1.2090e+00,\n",
       "           -1.6621e+00, -7.2217e-01],\n",
       "          ...,\n",
       "          [-2.0605e+00, -6.9043e-01, -3.9087e-01,  ..., -1.6943e+00,\n",
       "           -2.0977e+00, -6.7444e-02],\n",
       "          [ 5.1562e-01, -5.0977e-01,  3.4570e-01,  ..., -2.1465e+00,\n",
       "           -1.8701e+00, -1.7310e-01],\n",
       "          [ 2.7148e+00, -1.0352e-01,  5.8496e-01,  ..., -1.6523e+00,\n",
       "           -1.9336e+00, -2.2335e-03]],\n",
       "\n",
       "         [[ 1.6907e-02, -7.0947e-01,  1.7725e-01,  ...,  8.3447e-01,\n",
       "            5.2686e-01, -9.7266e-01],\n",
       "          [-9.8242e-01, -8.6914e-01, -5.3516e-01,  ...,  1.5029e+00,\n",
       "            2.1692e-01, -1.2725e+00],\n",
       "          [-2.7856e-01, -7.8003e-02, -6.9580e-01,  ...,  1.2783e+00,\n",
       "           -2.9102e-01, -6.4355e-01],\n",
       "          ...,\n",
       "          [-9.3506e-01,  5.7471e-01, -4.6899e-01,  ...,  1.0752e+00,\n",
       "           -7.8918e-02, -1.9111e+00],\n",
       "          [ 2.4902e-02, -2.3999e-01, -4.3872e-01,  ...,  1.3887e+00,\n",
       "            1.6003e-01, -2.1055e+00],\n",
       "          [ 1.0039e+00, -8.5254e-01, -4.3823e-01,  ...,  1.0000e+00,\n",
       "           -2.3413e-01, -1.7734e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-5.1758e-02, -8.7646e-01, -7.5928e-01,  ..., -9.8877e-02,\n",
       "            9.6387e-01, -1.1465e+00],\n",
       "          [-1.3367e-01, -2.8076e-01, -3.0566e-01,  ..., -4.0405e-01,\n",
       "            2.9999e-02, -1.2500e+00],\n",
       "          [-2.7344e-01,  2.6709e-01,  6.9434e-01,  ..., -3.0273e-01,\n",
       "            6.7480e-01, -1.2900e+00],\n",
       "          ...,\n",
       "          [-1.9775e-02, -3.8147e-02, -5.8545e-01,  ...,  4.2773e-01,\n",
       "            1.1143e+00, -1.6143e+00],\n",
       "          [-2.3315e-01, -1.2085e-02,  4.7925e-01,  ...,  3.9526e-01,\n",
       "            9.1748e-01, -1.5967e+00],\n",
       "          [-2.8027e-01,  2.7856e-01,  1.3750e+00,  ...,  4.8413e-01,\n",
       "            1.1660e+00, -1.6006e+00]],\n",
       "\n",
       "         [[ 1.9434e-01,  2.7271e-01,  6.9824e-01,  ...,  1.1416e+00,\n",
       "           -2.5918e+00, -7.6807e-01],\n",
       "          [-3.0054e-01, -1.2439e-01,  8.4473e-02,  ...,  8.1006e-01,\n",
       "           -2.0059e+00, -9.7021e-01],\n",
       "          [-6.6992e-01, -6.7529e-01, -5.2734e-01,  ...,  1.0889e+00,\n",
       "           -2.2109e+00, -1.1338e+00],\n",
       "          ...,\n",
       "          [-4.1504e-02,  4.3701e-02,  2.3853e-01,  ...,  1.6748e+00,\n",
       "           -2.8242e+00, -1.4824e+00],\n",
       "          [-1.0234e+00,  2.1497e-01, -2.2339e-01,  ...,  1.6611e+00,\n",
       "           -2.8340e+00, -1.5557e+00],\n",
       "          [-9.2432e-01,  3.2568e-01, -5.7471e-01,  ...,  1.5039e+00,\n",
       "           -2.9551e+00, -1.5381e+00]],\n",
       "\n",
       "         [[-4.9316e-01,  3.0176e-01,  6.5002e-02,  ...,  7.8369e-01,\n",
       "           -3.3320e+00, -7.8320e-01],\n",
       "          [-3.7402e-01, -1.0052e-01, -1.7346e-01,  ...,  2.1011e-02,\n",
       "           -4.9688e+00, -1.6289e+00],\n",
       "          [ 7.0557e-02, -2.6245e-01, -2.0862e-01,  ..., -4.5312e-01,\n",
       "           -6.2852e+00, -2.3340e+00],\n",
       "          ...,\n",
       "          [-4.6777e-01,  1.2695e-02, -4.3945e-03,  ..., -3.7793e-01,\n",
       "           -4.8242e+00, -3.9355e+00],\n",
       "          [-4.9561e-02,  2.0825e-01, -3.3643e-01,  ..., -1.8250e-01,\n",
       "           -5.0391e+00, -3.8770e+00],\n",
       "          [ 3.4375e-01,  2.1497e-01, -3.8892e-01,  ..., -3.3618e-01,\n",
       "           -5.2188e+00, -4.0742e+00]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[[ 4.0845e-01, -1.5027e-01, -4.0063e-01,  ...,  2.7881e-01,\n",
       "            1.0185e-03,  7.3486e-01],\n",
       "          [ 2.0081e-01, -4.2847e-01, -7.5195e-01,  ...,  4.5703e-01,\n",
       "           -1.5479e-01,  4.2212e-01],\n",
       "          [ 7.1240e-01, -1.9434e-01, -7.7637e-01,  ...,  1.7200e-01,\n",
       "           -2.0154e-01,  3.6182e-01],\n",
       "          ...,\n",
       "          [ 4.6924e-01, -3.0371e-01, -2.3584e-01,  ..., -3.1543e-01,\n",
       "            2.5415e-01,  5.7617e-01],\n",
       "          [ 6.5234e-01, -3.3472e-01, -2.1387e-01,  ..., -4.1431e-01,\n",
       "            3.0176e-01,  4.0625e-01],\n",
       "          [ 5.2148e-01, -2.6123e-01, -2.8687e-01,  ..., -3.1201e-01,\n",
       "            3.5620e-01,  4.2139e-01]],\n",
       "\n",
       "         [[ 8.4106e-02, -5.4980e-01, -3.4863e-01,  ..., -3.0441e-02,\n",
       "           -3.5522e-01,  1.8384e-01],\n",
       "          [ 7.9529e-02, -3.5400e-01, -5.7159e-02,  ..., -3.0908e-01,\n",
       "           -2.7246e-01, -2.9150e-01],\n",
       "          [ 9.0881e-02, -7.0898e-01, -2.2620e-01,  ..., -3.0380e-02,\n",
       "           -2.7319e-01, -2.4918e-02],\n",
       "          ...,\n",
       "          [-1.5588e-01, -2.0374e-01, -2.1350e-01,  ...,  2.8345e-01,\n",
       "           -4.4708e-02,  3.6987e-01],\n",
       "          [-2.5781e-01, -3.3887e-01, -3.3936e-01,  ...,  1.4929e-01,\n",
       "           -1.0046e-01,  3.7866e-01],\n",
       "          [-1.0718e-01, -3.0737e-01, -3.3862e-01,  ...,  2.1692e-01,\n",
       "           -6.7017e-02,  1.7761e-01]],\n",
       "\n",
       "         [[ 8.4839e-02,  8.6865e-01,  6.3599e-02,  ..., -2.3047e-01,\n",
       "           -1.3733e-01,  5.6305e-02],\n",
       "          [-1.4612e-01,  8.3545e-01,  3.7109e-01,  ...,  1.4465e-01,\n",
       "            3.4644e-01, -3.5986e-01],\n",
       "          [-3.5229e-01,  9.3628e-02, -2.2839e-01,  ..., -2.1622e-02,\n",
       "           -4.5563e-02, -2.0190e-01],\n",
       "          ...,\n",
       "          [-3.4741e-01,  5.0049e-01, -5.5450e-02,  ..., -9.4141e-01,\n",
       "            3.6060e-01, -1.0571e-01],\n",
       "          [-1.6833e-01,  4.9902e-01,  7.5607e-03,  ..., -7.8955e-01,\n",
       "            1.6211e-01,  8.0811e-02],\n",
       "          [-1.8408e-01,  3.1226e-01, -1.3342e-01,  ..., -9.2041e-01,\n",
       "            2.3853e-01,  6.1462e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.3945e-01,  4.8413e-01,  2.6392e-01,  ...,  2.1692e-01,\n",
       "           -1.6125e-01, -3.0493e-01],\n",
       "          [-3.9966e-01,  2.6514e-01,  2.4451e-01,  ...,  1.2842e-01,\n",
       "           -1.2213e-01,  7.1594e-02],\n",
       "          [-1.5234e-01,  3.8989e-01,  7.0007e-02,  ..., -2.8027e-01,\n",
       "           -3.9864e-03, -7.6172e-01],\n",
       "          ...,\n",
       "          [-7.7490e-01, -3.0957e-01, -1.2256e-01,  ...,  2.5732e-01,\n",
       "           -1.9653e-01, -1.1826e+00],\n",
       "          [-8.1494e-01, -5.3369e-01, -1.0675e-01,  ...,  2.7002e-01,\n",
       "           -3.9001e-02, -8.5107e-01],\n",
       "          [-8.7598e-01, -2.4451e-01, -2.1362e-02,  ...,  4.0991e-01,\n",
       "           -9.7473e-02, -1.2217e+00]],\n",
       "\n",
       "         [[ 1.1469e-01,  5.8740e-01, -6.5552e-02,  ..., -1.4233e-01,\n",
       "           -6.6699e-01,  3.2349e-01],\n",
       "          [ 4.7314e-01,  8.4570e-01,  1.6321e-01,  ..., -2.0349e-01,\n",
       "           -7.0166e-01,  4.8926e-01],\n",
       "          [ 4.0308e-01,  6.0840e-01, -2.9556e-02,  ...,  1.1700e-01,\n",
       "           -5.2002e-01,  5.2795e-02],\n",
       "          ...,\n",
       "          [-2.4933e-02,  6.9238e-01,  4.2358e-01,  ...,  3.4326e-01,\n",
       "           -3.9185e-01,  2.0361e-01],\n",
       "          [-1.2769e-01,  5.8936e-01,  6.1523e-01,  ...,  1.8958e-01,\n",
       "           -1.9763e-01,  3.4082e-01],\n",
       "          [-5.4626e-02,  8.6865e-01,  4.7266e-01,  ...,  1.9592e-01,\n",
       "           -3.4595e-01,  1.2952e-01]],\n",
       "\n",
       "         [[ 2.0309e-02, -7.6514e-01, -5.9204e-02,  ...,  7.7881e-02,\n",
       "            3.9795e-01, -7.4316e-01],\n",
       "          [ 6.3818e-01, -3.6182e-01,  1.4844e-01,  ...,  4.5312e-01,\n",
       "            8.7891e-02, -5.3564e-01],\n",
       "          [ 4.0259e-01, -4.1772e-01, -1.0486e-01,  ..., -2.8662e-01,\n",
       "            4.3848e-01, -6.3867e-01],\n",
       "          ...,\n",
       "          [ 6.5186e-01, -6.9189e-01, -2.7197e-01,  ..., -5.9961e-01,\n",
       "            7.9150e-01, -5.4395e-01],\n",
       "          [ 4.8218e-01, -7.2559e-01, -1.6956e-01,  ..., -5.1758e-01,\n",
       "            8.1885e-01, -4.8169e-01],\n",
       "          [ 6.9141e-01, -7.2705e-01, -3.1421e-01,  ..., -6.1963e-01,\n",
       "            8.7695e-01, -6.2305e-01]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[ 0.2603,  0.0930, -0.1622,  ...,  0.6396,  0.2064, -0.5562],\n",
       "          [-0.3369,  0.7534, -0.3057,  ...,  1.3271,  0.6421, -0.2333],\n",
       "          [ 0.1327,  0.5229, -0.6787,  ...,  0.7568,  1.0557, -0.0123],\n",
       "          ...,\n",
       "          [-0.5020, -0.9385, -0.5674,  ..., -1.0410,  0.8198,  0.4658],\n",
       "          [-0.3215, -1.0693, -0.7773,  ..., -1.0039,  0.9512,  0.5532],\n",
       "          [ 0.4546, -0.4932, -0.8457,  ..., -0.7964,  1.0439,  0.7915]],\n",
       "\n",
       "         [[ 0.3206,  0.1205,  0.9131,  ..., -0.1995,  0.1203,  1.7881],\n",
       "          [-0.5957, -0.4937,  0.4998,  ...,  0.0854, -0.6528,  2.3340],\n",
       "          [-0.2394, -0.6094, -0.5547,  ..., -0.6104, -0.6792,  1.4922],\n",
       "          ...,\n",
       "          [-1.3564,  0.3945,  0.6338,  ..., -0.5024, -1.4795,  1.4873],\n",
       "          [-1.3496,  0.5024, -0.0938,  ..., -0.4121, -1.4551,  1.7920],\n",
       "          [ 0.3738, -0.0831, -0.6187,  ..., -0.4958, -1.3965,  1.4561]],\n",
       "\n",
       "         [[ 1.1738, -0.0800, -0.4751,  ...,  1.8066, -0.0495, -0.1436],\n",
       "          [-0.0283, -0.3582, -0.3999,  ...,  2.7441,  0.2710, -0.3271],\n",
       "          [-1.0020,  0.2498,  0.9268,  ...,  2.2363,  0.6006, -0.2969],\n",
       "          ...,\n",
       "          [ 0.1085,  0.5244, -0.1227,  ...,  2.4824,  0.4048, -1.2549],\n",
       "          [-0.1589,  0.7310,  0.0945,  ...,  2.5332,  0.4514, -0.8760],\n",
       "          [-0.3242,  0.5322,  0.3215,  ...,  2.5605,  0.3408, -1.1357]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.4822,  0.3606,  0.7437,  ..., -6.9375, -0.1735,  2.2969],\n",
       "          [-0.0374, -0.1807,  0.1260,  ..., -8.6328,  1.0449,  2.6816],\n",
       "          [-0.4077, -0.6772, -0.6113,  ..., -8.6562,  0.1304,  3.1641],\n",
       "          ...,\n",
       "          [-0.3350, -0.1152,  0.5312,  ..., -8.2734, -1.5273,  4.0156],\n",
       "          [-0.8232,  0.9634, -0.5713,  ..., -8.6094, -1.1865,  3.2754],\n",
       "          [-0.5000,  1.2939, -1.1846,  ..., -7.9688, -0.9663,  4.0352]],\n",
       "\n",
       "         [[-0.1437, -0.2820,  0.4492,  ...,  4.7188,  0.6519, -0.5571],\n",
       "          [-0.6958, -0.1520,  0.6973,  ...,  5.4453, -0.3049, -0.4624],\n",
       "          [-0.6436,  0.2306,  0.6899,  ...,  5.2891,  0.8413, -0.9771],\n",
       "          ...,\n",
       "          [-0.6494,  0.0924,  0.2727,  ...,  4.7969,  0.8760, -0.9658],\n",
       "          [-0.7119, -0.2300,  0.7305,  ...,  4.8984,  0.4099, -0.9771],\n",
       "          [-0.0562, -0.3721,  0.6675,  ...,  4.7812,  0.7202, -0.7681]],\n",
       "\n",
       "         [[ 0.5952,  0.7354, -0.7095,  ..., -0.7485, -0.1606,  1.0547],\n",
       "          [ 2.1270,  1.5742, -0.9751,  ..., -0.9282,  0.2937,  0.7856],\n",
       "          [ 1.0293,  1.0693, -0.2649,  ..., -1.6729,  0.0334,  1.0088],\n",
       "          ...,\n",
       "          [ 0.3765, -0.2737, -0.9883,  ..., -1.2256, -0.6416,  1.1680],\n",
       "          [ 0.3613, -0.3608, -0.6812,  ..., -1.6172, -0.5430,  1.0820],\n",
       "          [-0.1632, -0.1154, -0.1667,  ..., -1.4814, -0.5952,  0.9272]]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[[ 0.5239, -0.1686, -0.2397,  ..., -0.3677, -0.0975, -0.4333],\n",
       "          [ 0.6997,  0.1423, -0.3235,  ..., -0.8228, -0.1975, -0.5728],\n",
       "          [ 0.5737,  0.0456, -0.3181,  ..., -0.3171, -0.2399, -0.6870],\n",
       "          ...,\n",
       "          [ 0.8682, -0.3201, -0.3989,  ..., -0.9663, -0.6348, -0.1818],\n",
       "          [ 0.6519, -0.1962, -0.5312,  ..., -0.8359, -0.5537, -0.1061],\n",
       "          [ 0.7886, -0.3611, -0.5166,  ..., -0.9185, -0.5703, -0.2291]],\n",
       "\n",
       "         [[ 0.4465, -0.5918, -0.1449,  ...,  0.2876, -0.0506, -0.8521],\n",
       "          [ 0.2045, -0.5044, -0.3037,  ...,  0.3945, -0.0177, -1.1045],\n",
       "          [ 0.3413, -0.2515, -0.1890,  ...,  0.2112,  0.0679, -0.9038],\n",
       "          ...,\n",
       "          [ 0.4038, -1.0059,  0.1624,  ...,  0.3022,  0.5601, -0.3821],\n",
       "          [ 0.3999, -0.9043,  0.1285,  ...,  0.2798,  0.4827, -0.3323],\n",
       "          [ 0.4265, -0.9790,  0.0795,  ...,  0.2561,  0.6274, -0.4551]],\n",
       "\n",
       "         [[-0.2598,  0.2379,  0.3374,  ...,  0.9785,  0.3618,  0.5190],\n",
       "          [ 0.1699, -0.0432,  0.3940,  ...,  0.6450, -0.0051,  0.6758],\n",
       "          [-0.2527, -0.2810,  0.5200,  ...,  0.7104,  0.3608,  0.5020],\n",
       "          ...,\n",
       "          [ 0.0514, -0.0764,  0.1558,  ...,  0.7759,  0.4868, -0.0104],\n",
       "          [ 0.0116,  0.0544,  0.1355,  ...,  0.9102,  0.7734, -0.1572],\n",
       "          [-0.0443, -0.1252,  0.1116,  ...,  0.8599,  0.6021, -0.0428]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0469, -0.1261,  0.0107,  ..., -0.2681,  0.6943,  0.3896],\n",
       "          [-0.2325, -0.4038, -0.0767,  ..., -0.3284,  1.0752,  0.8608],\n",
       "          [-0.3440, -0.2418,  0.4656,  ..., -0.4060,  0.6733,  0.1587],\n",
       "          ...,\n",
       "          [-0.0807, -0.4744,  0.3508,  ..., -0.1417,  0.7822, -0.1499],\n",
       "          [-0.1145,  0.0518,  0.1237,  ..., -0.1008,  0.9604, -0.0120],\n",
       "          [-0.3792, -0.3723,  0.4382,  ..., -0.2825,  0.9038, -0.1169]],\n",
       "\n",
       "         [[ 0.1656, -0.1466,  0.7573,  ..., -0.6304,  0.5376, -0.6436],\n",
       "          [ 0.1122, -0.1124,  0.7046,  ..., -0.5190,  0.4258, -0.4915],\n",
       "          [ 0.5942,  0.1783,  0.8506,  ..., -0.5112,  0.3923, -0.0756],\n",
       "          ...,\n",
       "          [ 0.2644, -0.2974,  1.0762,  ..., -0.3843,  0.3174, -0.7085],\n",
       "          [ 0.1708, -0.3372,  1.1768,  ..., -0.3860,  0.4453, -0.6270],\n",
       "          [ 0.2888, -0.3132,  1.1875,  ..., -0.2896,  0.3303, -0.3801]],\n",
       "\n",
       "         [[ 0.3452, -0.1450,  0.4744,  ...,  0.6226,  0.2583, -0.4429],\n",
       "          [ 0.5024, -0.0728,  0.6118,  ...,  0.9990,  0.4365, -0.6719],\n",
       "          [ 0.4089, -0.0539,  0.3833,  ...,  0.9658,  0.3906, -0.1055],\n",
       "          ...,\n",
       "          [ 0.1708, -0.0748,  0.3650,  ...,  0.5781,  0.2642, -0.7793],\n",
       "          [ 0.3499,  0.1405,  0.3433,  ...,  0.5508,  0.2883, -0.8423],\n",
       "          [ 0.2328, -0.0435,  0.3699,  ...,  0.6104,  0.2927, -0.8335]]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<TransposeBackward0>)), (tensor([[[[ 4.9561e-02,  2.7710e-01, -4.4751e-01,  ...,  5.4688e-01,\n",
       "            1.8701e+00,  7.6641e+00],\n",
       "          [ 2.0886e-01, -2.4670e-01, -6.9434e-01,  ...,  6.0938e-01,\n",
       "            2.7773e+00,  1.0250e+01],\n",
       "          [ 3.3722e-02, -6.1279e-01, -2.9688e-01,  ...,  1.3965e+00,\n",
       "            3.1309e+00,  1.0898e+01],\n",
       "          ...,\n",
       "          [ 2.1948e-01,  3.0469e-01, -4.4580e-01,  ...,  1.0381e+00,\n",
       "            3.2188e+00,  1.2234e+01],\n",
       "          [ 1.3806e-01,  6.7725e-01, -2.3218e-01,  ...,  9.6973e-01,\n",
       "            3.2715e+00,  1.2227e+01],\n",
       "          [ 7.9956e-02,  4.3677e-01,  1.3403e-01,  ...,  1.1777e+00,\n",
       "            3.3984e+00,  1.2500e+01]],\n",
       "\n",
       "         [[ 2.2278e-01, -1.2031e+00, -5.2930e-01,  ...,  1.4570e+00,\n",
       "            3.0688e-01, -1.1914e+00],\n",
       "          [-2.7441e-01, -7.7637e-01, -3.7427e-01,  ...,  1.0146e+00,\n",
       "            3.9819e-01, -8.4619e-01],\n",
       "          [-1.1104e+00,  9.7754e-01,  6.4990e-01,  ...,  1.8232e+00,\n",
       "            5.6738e-01, -1.5830e+00],\n",
       "          ...,\n",
       "          [-5.2734e-01,  1.3750e+00, -6.6748e-01,  ...,  1.5869e+00,\n",
       "            1.7725e-01, -2.1094e+00],\n",
       "          [-1.1396e+00,  1.4941e-01,  1.1755e-01,  ...,  1.4141e+00,\n",
       "            1.8213e-01, -1.9258e+00],\n",
       "          [-8.8135e-01, -1.3018e+00,  1.1689e+00,  ...,  1.5566e+00,\n",
       "            2.8345e-01, -2.0020e+00]],\n",
       "\n",
       "         [[ 4.3091e-01, -9.5764e-02, -2.4597e-02,  ..., -4.4995e-01,\n",
       "            1.3457e+00,  1.2927e-01],\n",
       "          [-5.6641e-01, -7.3047e-01, -5.0635e-01,  ..., -2.9907e-01,\n",
       "            1.5918e+00,  5.3174e-01],\n",
       "          [-7.5195e-01, -1.0215e+00, -7.8174e-01,  ..., -5.0244e-01,\n",
       "            1.0303e+00,  4.7388e-01],\n",
       "          ...,\n",
       "          [-2.9736e-01,  5.4883e-01, -7.0605e-01,  ..., -4.2822e-01,\n",
       "            1.6895e+00,  1.1407e-01],\n",
       "          [-1.0029e+00,  9.3799e-01, -8.1934e-01,  ..., -3.8379e-01,\n",
       "            1.7656e+00,  3.0786e-01],\n",
       "          [-8.2373e-01,  7.9492e-01, -2.8687e-01,  ..., -5.0977e-01,\n",
       "            1.9570e+00, -4.7943e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.0908e-01, -3.2623e-02, -1.2354e+00,  ..., -4.7046e-01,\n",
       "           -1.4609e+00, -2.2925e-01],\n",
       "          [-6.6309e-01, -5.3906e-01, -5.6836e-01,  ..., -8.8281e-01,\n",
       "           -1.3525e+00, -2.1729e-01],\n",
       "          [-6.8066e-01, -9.9365e-01,  5.8496e-01,  ..., -1.9470e-01,\n",
       "           -1.4180e+00, -6.7236e-01],\n",
       "          ...,\n",
       "          [-4.7852e-02,  5.8887e-01, -6.0938e-01,  ...,  2.0435e-01,\n",
       "           -1.0576e+00, -1.3301e+00],\n",
       "          [-1.9150e+00,  4.2847e-01,  4.5227e-02,  ...,  2.4646e-01,\n",
       "           -1.2334e+00, -1.1367e+00],\n",
       "          [-1.3770e+00,  2.9956e-01,  4.1211e-01,  ...,  1.7834e-01,\n",
       "           -1.0566e+00, -1.2285e+00]],\n",
       "\n",
       "         [[-4.8926e-01,  2.3499e-01,  1.0413e-01,  ..., -3.1641e-01,\n",
       "            1.9053e+00, -3.9722e-01],\n",
       "          [-9.9121e-01,  1.6797e-01, -9.2676e-01,  ..., -4.4214e-01,\n",
       "            1.9131e+00,  3.1128e-01],\n",
       "          [-4.2236e-01, -4.1772e-01, -7.5586e-01,  ..., -4.1919e-01,\n",
       "            2.6543e+00, -4.4507e-01],\n",
       "          ...,\n",
       "          [-5.7959e-01, -1.9482e-01, -8.6243e-02,  ..., -1.7949e+00,\n",
       "            8.2422e-01, -9.3164e-01],\n",
       "          [-2.4268e-01,  1.5552e-01, -2.7100e-01,  ..., -1.8340e+00,\n",
       "            6.7383e-01, -4.0234e-01],\n",
       "          [ 3.0664e-01,  5.4688e-01, -1.2988e-01,  ..., -1.7197e+00,\n",
       "            1.1504e+00, -9.1650e-01]],\n",
       "\n",
       "         [[-1.8054e-01,  1.5320e-01,  5.8496e-01,  ..., -3.1641e-01,\n",
       "            5.0000e-01,  2.0068e-01],\n",
       "          [-8.1421e-02,  2.5562e-01,  1.9189e-01,  ..., -5.0439e-01,\n",
       "            1.0869e+00,  4.6582e-01],\n",
       "          [-5.2881e-01,  4.2969e-02, -5.6348e-01,  ..., -6.5137e-01,\n",
       "            8.8770e-01, -1.6499e-03],\n",
       "          ...,\n",
       "          [-2.3950e-01, -2.2693e-01,  7.7637e-02,  ...,  5.8887e-01,\n",
       "            6.3330e-01, -5.4883e-01],\n",
       "          [-2.8687e-01, -5.5420e-01, -1.0449e+00,  ...,  6.3574e-01,\n",
       "            1.3252e+00, -1.9763e-01],\n",
       "          [ 9.8755e-02, -2.9858e-01, -9.1650e-01,  ...,  5.4541e-01,\n",
       "            8.8379e-01, -5.6641e-01]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[[ 9.2590e-02,  4.8633e-01, -4.8218e-02,  ..., -8.3252e-01,\n",
       "           -5.5566e-01,  4.0527e-01],\n",
       "          [ 2.7759e-01,  7.1533e-02, -1.7761e-01,  ..., -7.4463e-01,\n",
       "           -1.1445e+00,  1.0098e+00],\n",
       "          [-1.2634e-01,  3.8062e-01, -5.7373e-02,  ..., -6.3281e-01,\n",
       "           -4.4727e-01,  1.9580e-01],\n",
       "          ...,\n",
       "          [-5.1074e-01,  3.8232e-01, -1.6284e-01,  ...,  4.5410e-02,\n",
       "           -7.7734e-01, -3.7012e-01],\n",
       "          [-3.8477e-01,  4.4214e-01, -2.0007e-01,  ..., -3.2471e-02,\n",
       "           -4.8047e-01, -1.3171e-01],\n",
       "          [-5.8252e-01,  3.5889e-01, -2.6709e-01,  ...,  1.2646e-01,\n",
       "           -9.4092e-01, -2.9761e-01]],\n",
       "\n",
       "         [[-6.6016e-01,  1.4514e-01,  3.5132e-01,  ...,  7.3290e-04,\n",
       "           -5.9967e-02, -2.0886e-01],\n",
       "          [-7.6123e-01,  7.4120e-03,  1.6174e-01,  ...,  6.2305e-01,\n",
       "           -2.7246e-01, -1.4734e-01],\n",
       "          [-3.6133e-01, -1.9398e-03,  2.8711e-01,  ...,  2.9614e-01,\n",
       "           -1.2207e-01, -3.1641e-01],\n",
       "          ...,\n",
       "          [-1.1289e+00,  3.5254e-01, -1.2985e-02,  ..., -2.3499e-02,\n",
       "           -4.6191e-01, -4.4824e-01],\n",
       "          [-1.1641e+00,  3.6377e-01,  7.8186e-02,  ..., -6.4636e-02,\n",
       "           -3.7061e-01, -5.4736e-01],\n",
       "          [-1.1221e+00,  4.4580e-01,  1.4929e-01,  ...,  3.2990e-02,\n",
       "           -4.3311e-01, -6.0547e-01]],\n",
       "\n",
       "         [[ 1.4734e-01, -5.0293e-01,  2.9248e-01,  ..., -1.4844e-01,\n",
       "            5.8496e-01,  5.5542e-02],\n",
       "          [ 2.2205e-01, -6.2402e-01,  1.1163e-01,  ..., -3.4009e-01,\n",
       "            2.4963e-01,  7.1350e-02],\n",
       "          [ 2.0642e-01, -8.6133e-01, -4.0503e-01,  ...,  1.0852e-01,\n",
       "            1.7578e-01, -9.6375e-02],\n",
       "          ...,\n",
       "          [ 1.6492e-01,  3.6719e-01, -4.5996e-01,  ..., -2.8979e-01,\n",
       "           -3.4912e-01,  1.6150e-01],\n",
       "          [ 3.6450e-01,  2.6074e-01, -5.1221e-01,  ..., -1.3843e-01,\n",
       "           -3.0249e-01,  1.6724e-01],\n",
       "          [ 2.6831e-01,  2.4011e-01, -5.5713e-01,  ..., -1.8726e-01,\n",
       "           -3.8696e-01,  1.8127e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.2471e+00,  2.4890e-01, -9.8438e-01,  ...,  1.1584e-01,\n",
       "            2.2510e-01, -4.4580e-01],\n",
       "          [ 1.2354e+00,  1.2744e-01, -7.5146e-01,  ..., -2.6758e-01,\n",
       "            1.7896e-01, -2.5635e-01],\n",
       "          [ 1.0293e+00,  4.0308e-01, -9.0967e-01,  ...,  3.0396e-01,\n",
       "            4.7607e-01, -6.4551e-01],\n",
       "          ...,\n",
       "          [ 1.0127e+00,  4.0137e-01, -3.2886e-01,  ...,  5.3223e-01,\n",
       "            7.2705e-01, -6.1670e-01],\n",
       "          [ 1.0791e+00,  3.2446e-01, -5.2051e-01,  ...,  5.5762e-01,\n",
       "            6.1426e-01, -5.8203e-01],\n",
       "          [ 9.6484e-01,  3.5278e-01, -3.3545e-01,  ...,  6.1572e-01,\n",
       "            6.3525e-01, -5.1465e-01]],\n",
       "\n",
       "         [[-8.1055e-02, -2.2754e-01, -4.9902e-01,  ..., -3.8354e-01,\n",
       "           -1.3159e-01, -1.7395e-01],\n",
       "          [-2.4609e-01, -4.7974e-01, -1.6748e-01,  ..., -6.5918e-01,\n",
       "            1.2830e-01, -2.9639e-01],\n",
       "          [ 5.4413e-02, -6.3574e-01, -4.1748e-01,  ..., -1.5808e-01,\n",
       "            3.7354e-02, -3.3936e-01],\n",
       "          ...,\n",
       "          [-3.0457e-02, -5.9180e-01,  4.1870e-02,  ..., -2.2400e-01,\n",
       "            6.1377e-01,  2.1741e-01],\n",
       "          [-2.7298e-02, -4.1040e-01,  4.2938e-02,  ..., -2.2241e-01,\n",
       "            3.9404e-01,  1.6565e-01],\n",
       "          [-4.6478e-02, -5.0098e-01,  4.6577e-03,  ..., -8.4106e-02,\n",
       "            5.6787e-01,  3.5986e-01]],\n",
       "\n",
       "         [[ 1.2422e+00, -4.2017e-01,  3.9307e-01,  ...,  6.0742e-01,\n",
       "           -1.1371e-01,  3.1201e-01],\n",
       "          [ 1.2139e+00,  1.1108e-01,  1.1902e-02,  ...,  2.7710e-01,\n",
       "           -1.4392e-01,  3.2275e-01],\n",
       "          [ 1.2422e+00, -9.0234e-01,  1.8713e-01,  ...,  4.2578e-01,\n",
       "            3.0811e-01, -2.2485e-01],\n",
       "          ...,\n",
       "          [ 3.7183e-01,  1.3992e-02, -7.1094e-01,  ...,  3.4766e-01,\n",
       "            1.4221e-01, -1.3115e-02],\n",
       "          [ 7.6855e-01,  3.4363e-02, -5.3760e-01,  ...,  3.3966e-02,\n",
       "            2.4622e-01,  1.9568e-01],\n",
       "          [ 5.8936e-01, -1.8237e-01, -6.7285e-01,  ...,  1.9678e-01,\n",
       "            2.2400e-01,  2.8625e-02]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[-8.3008e-01,  5.1660e-01, -1.7114e-01,  ..., -1.8105e+00,\n",
       "           -1.1670e+00,  1.6565e-01],\n",
       "          [-7.7295e-01, -2.2656e-01, -7.2266e-02,  ..., -1.5361e+00,\n",
       "           -1.8721e+00, -3.6060e-01],\n",
       "          [-2.2437e-01, -8.8086e-01, -2.4658e-01,  ..., -1.4219e+00,\n",
       "           -1.5908e+00,  3.9282e-01],\n",
       "          ...,\n",
       "          [-1.9434e-01,  5.2051e-01,  2.1362e-01,  ..., -1.8535e+00,\n",
       "           -2.3828e+00,  3.8428e-01],\n",
       "          [ 9.1602e-01,  1.1465e+00,  3.8721e-01,  ..., -1.6875e+00,\n",
       "           -2.5527e+00,  4.1260e-01],\n",
       "          [ 1.3057e+00,  6.5723e-01,  6.2744e-01,  ..., -1.7109e+00,\n",
       "           -2.1855e+00,  4.6094e-01]],\n",
       "\n",
       "         [[-5.3662e-01, -1.3545e+00,  5.9619e-01,  ...,  6.3818e-01,\n",
       "           -8.9600e-02,  2.0469e+00],\n",
       "          [-6.5527e-01, -5.5420e-01,  3.4863e-01,  ...,  4.0601e-01,\n",
       "            3.3984e-01,  2.6738e+00],\n",
       "          [ 4.4580e-01, -7.2632e-03,  2.7148e-01,  ...,  9.5459e-01,\n",
       "            1.4624e-01,  1.9404e+00],\n",
       "          ...,\n",
       "          [-7.9248e-01,  5.2393e-01,  1.0107e-01,  ...,  1.4219e+00,\n",
       "            1.4868e-01,  1.8760e+00],\n",
       "          [ 1.7456e-02, -9.6191e-02, -5.8252e-01,  ...,  1.3213e+00,\n",
       "            3.4106e-01,  2.0293e+00],\n",
       "          [ 8.6475e-01, -3.8965e-01, -4.8047e-01,  ...,  1.3379e+00,\n",
       "            1.0919e-01,  1.8594e+00]],\n",
       "\n",
       "         [[-5.0439e-01, -4.3091e-01,  6.5088e-01,  ...,  4.1016e-01,\n",
       "            7.2412e-01,  2.3262e+00],\n",
       "          [ 2.9663e-01, -3.4033e-01,  4.9756e-01,  ...,  6.3135e-01,\n",
       "            3.6084e-01,  2.3438e+00],\n",
       "          [ 1.1377e+00,  4.9902e-01, -1.4319e-01,  ...,  2.9126e-01,\n",
       "           -4.2816e-02,  2.8652e+00],\n",
       "          ...,\n",
       "          [-1.2183e-01,  1.7212e-01,  2.1851e-01,  ...,  1.4197e-01,\n",
       "            1.1484e+00,  1.5439e+00],\n",
       "          [ 5.3955e-01, -9.3994e-02, -2.7051e-01,  ...,  9.6802e-02,\n",
       "            9.3896e-01,  1.6436e+00],\n",
       "          [ 6.9922e-01, -3.5156e-01, -8.4766e-01,  ...,  5.1079e-03,\n",
       "            8.8867e-01,  1.4609e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.9468e-01, -8.8428e-01, -7.1777e-01,  ..., -9.7607e-01,\n",
       "           -6.1182e-01,  2.1309e+00],\n",
       "          [ 1.0918e+00, -7.2559e-01, -2.0264e-02,  ..., -8.5352e-01,\n",
       "           -1.5515e-01,  2.7285e+00],\n",
       "          [ 8.2861e-01,  3.0908e-01,  6.9775e-01,  ..., -1.0117e+00,\n",
       "           -8.9746e-01,  2.6895e+00],\n",
       "          ...,\n",
       "          [ 1.5645e+00,  4.4531e-01,  1.0425e-01,  ..., -2.0142e-01,\n",
       "           -1.3291e+00,  3.3027e+00],\n",
       "          [ 7.4561e-01, -2.7441e-01,  6.6895e-01,  ..., -2.1399e-01,\n",
       "           -1.1270e+00,  3.4766e+00],\n",
       "          [-6.7627e-01, -1.0029e+00,  9.5557e-01,  ..., -3.4546e-01,\n",
       "           -1.5938e+00,  3.1855e+00]],\n",
       "\n",
       "         [[-2.2498e-01,  1.5840e+00,  3.7402e-01,  ..., -1.4773e+01,\n",
       "           -6.2598e-01,  1.1250e+00],\n",
       "          [-5.6250e-01,  6.5674e-01,  1.0205e+00,  ..., -1.8766e+01,\n",
       "           -6.9043e-01,  2.8359e+00],\n",
       "          [ 6.1084e-01, -1.0586e+00,  2.7710e-01,  ..., -1.7922e+01,\n",
       "           -7.4072e-01,  9.6387e-01],\n",
       "          ...,\n",
       "          [-5.3613e-01, -2.9492e-01,  4.0405e-01,  ..., -1.9609e+01,\n",
       "           -3.6548e-01,  1.2871e+00],\n",
       "          [ 7.8564e-01,  1.1572e+00,  8.8184e-01,  ..., -1.9781e+01,\n",
       "           -6.6162e-01,  1.0195e+00],\n",
       "          [ 1.6201e+00,  1.5234e+00,  6.0107e-01,  ..., -1.9844e+01,\n",
       "           -8.0566e-01,  1.0547e+00]],\n",
       "\n",
       "         [[-1.4294e-01, -2.4536e-01, -5.4785e-01,  ...,  1.7656e+01,\n",
       "           -1.9897e-01, -1.4297e+00],\n",
       "          [-3.7671e-01, -4.7437e-01, -8.9258e-01,  ...,  2.0641e+01,\n",
       "           -9.9561e-01, -1.6445e+00],\n",
       "          [-1.3611e-01, -5.1880e-03, -8.5498e-01,  ...,  2.0094e+01,\n",
       "           -1.8387e-02, -1.4180e+00],\n",
       "          ...,\n",
       "          [-6.2256e-02, -6.7200e-02, -9.0967e-01,  ...,  2.4219e+01,\n",
       "           -2.4939e-01, -1.8584e+00],\n",
       "          [-3.5986e-01, -6.3820e-03, -6.2939e-01,  ...,  2.4375e+01,\n",
       "           -6.9238e-01, -1.5811e+00],\n",
       "          [-3.8525e-01, -1.7969e-01, -1.2695e-01,  ...,  2.4000e+01,\n",
       "           -4.5825e-01, -1.5312e+00]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[[ 1.6525e-02,  3.9893e-01,  5.6982e-01,  ...,  5.1074e-01,\n",
       "           -2.4353e-01,  2.8784e-01],\n",
       "          [ 2.8394e-01,  4.5972e-01,  4.8389e-01,  ...,  5.8691e-01,\n",
       "           -3.6255e-01,  3.8135e-01],\n",
       "          [-1.4246e-01,  6.3232e-01,  7.4707e-01,  ...,  6.3135e-01,\n",
       "           -1.6736e-01,  3.5303e-01],\n",
       "          ...,\n",
       "          [-6.8701e-01,  5.8643e-01,  9.2432e-01,  ...,  3.7659e-02,\n",
       "           -1.1066e-01,  5.7648e-02],\n",
       "          [-5.1025e-01,  7.3145e-01,  8.2324e-01,  ...,  3.1250e-01,\n",
       "           -1.8652e-01,  8.2092e-02],\n",
       "          [-5.7617e-01,  8.8232e-01,  8.5059e-01,  ...,  6.4575e-02,\n",
       "           -1.5002e-01,  1.4307e-01]],\n",
       "\n",
       "         [[-1.3164e+00, -7.0374e-02,  4.4727e-01,  ..., -2.0667e-01,\n",
       "            4.9585e-01,  9.7559e-01],\n",
       "          [-1.0986e+00,  1.8408e-01,  3.3447e-01,  ..., -2.0410e-01,\n",
       "            4.9829e-01,  8.7598e-01],\n",
       "          [-1.1914e+00, -6.4209e-02,  3.1372e-01,  ..., -7.4219e-02,\n",
       "            9.6582e-01,  5.8789e-01],\n",
       "          ...,\n",
       "          [-6.8994e-01,  4.9072e-01,  3.2935e-01,  ..., -3.9648e-01,\n",
       "            2.9443e-01,  4.6167e-01],\n",
       "          [-8.5547e-01,  4.1333e-01,  1.7236e-01,  ..., -1.9763e-01,\n",
       "            3.6743e-01,  3.5449e-01],\n",
       "          [-8.8379e-01,  4.8071e-01,  3.3105e-01,  ..., -1.7883e-01,\n",
       "            4.3652e-01,  2.9346e-01]],\n",
       "\n",
       "         [[-4.7546e-02, -1.0977e+00,  8.3740e-01,  ...,  3.1445e-01,\n",
       "           -1.0166e+00, -8.7402e-02],\n",
       "          [-1.3257e-01, -1.2139e+00,  3.2910e-01,  ...,  4.7046e-01,\n",
       "           -3.0469e-01,  9.7595e-02],\n",
       "          [-1.1749e-01, -1.1543e+00,  8.4521e-01,  ..., -1.3220e-01,\n",
       "           -8.8818e-01,  1.2756e-02],\n",
       "          ...,\n",
       "          [-7.7515e-02, -4.6021e-01,  1.9404e+00,  ...,  5.1025e-01,\n",
       "           -1.1377e+00, -3.4912e-01],\n",
       "          [-1.6907e-01, -3.5986e-01,  1.8037e+00,  ...,  5.4297e-01,\n",
       "           -1.2656e+00, -5.2979e-01],\n",
       "          [-3.2715e-01, -3.1665e-01,  1.7227e+00,  ...,  4.6313e-01,\n",
       "           -1.1758e+00, -4.8096e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.6216e-01, -8.2861e-01, -2.3145e-01,  ..., -3.9307e-01,\n",
       "            3.7915e-01, -7.5537e-01],\n",
       "          [-1.4722e-01, -6.9873e-01, -4.7577e-02,  ..., -3.7524e-01,\n",
       "            4.4727e-01, -7.3047e-01],\n",
       "          [-9.6875e-01, -7.6416e-01, -9.7473e-02,  ..., -4.7803e-01,\n",
       "            6.7920e-01, -4.2212e-01],\n",
       "          ...,\n",
       "          [ 1.0061e-03,  2.4216e-02, -1.5393e-01,  ..., -2.0691e-01,\n",
       "            5.3662e-01, -3.6084e-01],\n",
       "          [-1.8036e-02, -1.0229e-01, -1.9189e-01,  ..., -2.6270e-01,\n",
       "            4.5654e-01, -3.4399e-01],\n",
       "          [-1.9824e-01, -2.3523e-01, -4.3945e-02,  ..., -3.0615e-01,\n",
       "            6.8701e-01, -9.5520e-02]],\n",
       "\n",
       "         [[ 6.8848e-02, -1.9849e-01,  8.1238e-02,  ...,  3.4277e-01,\n",
       "           -6.4600e-01, -6.9199e-03],\n",
       "          [-3.7207e-01, -3.3740e-01,  1.9666e-01,  ..., -1.6675e-01,\n",
       "           -5.9375e-01,  3.2080e-01],\n",
       "          [-1.4417e-01, -4.0918e-01,  1.2524e-01,  ..., -2.8656e-02,\n",
       "           -4.5679e-01, -4.0710e-02],\n",
       "          ...,\n",
       "          [ 4.0015e-01, -2.9102e-01, -5.4395e-01,  ...,  3.3643e-01,\n",
       "           -7.9041e-02,  2.1680e-01],\n",
       "          [ 2.2095e-01, -4.0698e-01, -4.9121e-01,  ...,  4.1064e-01,\n",
       "           -1.2018e-01,  1.0431e-01],\n",
       "          [ 3.2959e-01, -2.7002e-01, -5.9033e-01,  ...,  3.1738e-01,\n",
       "           -7.1045e-02,  2.5391e-02]],\n",
       "\n",
       "         [[ 1.5371e+00,  2.6642e-02, -5.9912e-01,  ...,  4.3213e-02,\n",
       "           -5.4834e-01,  4.2944e-01],\n",
       "          [ 1.1855e+00, -2.5528e-02, -8.0029e-01,  ..., -5.9570e-02,\n",
       "           -3.7402e-01,  3.3765e-01],\n",
       "          [ 1.0361e+00,  8.7708e-02, -5.5615e-01,  ..., -1.0199e-01,\n",
       "           -4.8950e-01,  1.3281e-01],\n",
       "          ...,\n",
       "          [ 9.9268e-01, -3.7891e-01, -3.9990e-01,  ...,  4.8047e-01,\n",
       "            9.3689e-02, -2.0911e-01],\n",
       "          [ 9.5020e-01, -4.1309e-01, -4.5044e-01,  ...,  4.2407e-01,\n",
       "           -3.4546e-02, -2.1802e-01],\n",
       "          [ 9.2383e-01, -3.3203e-01, -5.4492e-01,  ...,  5.4443e-01,\n",
       "            2.8003e-01, -2.0508e-01]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[-1.1025e+00,  1.0195e+00,  7.1838e-02,  ..., -9.1846e-01,\n",
       "            7.8076e-01,  1.4561e+00],\n",
       "          [-1.1270e+00,  5.3027e-01, -1.6357e-01,  ..., -1.3955e+00,\n",
       "            1.2510e+00,  6.9287e-01],\n",
       "          [ 1.0034e-01, -5.0098e-01,  7.4121e-01,  ..., -7.9590e-01,\n",
       "            1.4473e+00,  1.2451e+00],\n",
       "          ...,\n",
       "          [-1.3525e+00, -2.5757e-01,  2.5195e-01,  ..., -9.6387e-01,\n",
       "            1.5576e+00, -3.2202e-01],\n",
       "          [-7.1387e-01,  5.3662e-01,  4.0796e-01,  ..., -9.5752e-01,\n",
       "            1.9668e+00, -1.4893e-02],\n",
       "          [ 9.1797e-01,  1.0293e+00,  4.8389e-01,  ..., -7.4658e-01,\n",
       "            1.8271e+00, -5.8838e-02]],\n",
       "\n",
       "         [[-9.7217e-01,  4.2188e-01,  9.9072e-01,  ...,  1.2520e+00,\n",
       "           -2.2500e+00, -5.7129e-01],\n",
       "          [-2.2705e-01,  5.5859e-01,  6.1572e-01,  ...,  6.4551e-01,\n",
       "           -2.4336e+00, -8.8623e-01],\n",
       "          [ 8.3350e-01, -1.9019e-01, -1.9226e-02,  ...,  1.2832e+00,\n",
       "           -2.7266e+00, -3.6108e-01],\n",
       "          ...,\n",
       "          [-3.7109e-02, -1.8164e-01,  1.5234e+00,  ...,  1.5977e+00,\n",
       "           -1.6084e+00, -4.0698e-01],\n",
       "          [ 1.2324e+00,  7.0679e-02,  4.6680e-01,  ...,  1.4785e+00,\n",
       "           -1.6650e+00, -3.5010e-01],\n",
       "          [ 1.1865e+00,  2.3486e-01, -1.0713e+00,  ...,  1.3252e+00,\n",
       "           -1.8154e+00, -2.1558e-01]],\n",
       "\n",
       "         [[-1.1406e+00,  9.8730e-01,  1.6270e+00,  ...,  1.4316e+00,\n",
       "           -6.4551e-01,  2.7559e+00],\n",
       "          [-1.4961e+00,  4.2480e-02,  1.6914e+00,  ...,  3.7451e-01,\n",
       "           -8.9966e-02,  2.9043e+00],\n",
       "          [ 4.1504e-01, -1.7402e+00,  7.2363e-01,  ...,  1.1436e+00,\n",
       "           -7.7734e-01,  2.8242e+00],\n",
       "          ...,\n",
       "          [-2.0312e+00, -8.7451e-01,  1.8926e+00,  ..., -1.1304e-01,\n",
       "           -1.6904e+00,  4.9844e+00],\n",
       "          [-5.8496e-01,  7.9492e-01,  9.2285e-01,  ..., -2.4536e-01,\n",
       "           -1.5107e+00,  4.6367e+00],\n",
       "          [ 1.3721e+00,  1.9014e+00, -4.9023e-01,  ...,  1.4420e-03,\n",
       "           -1.5039e+00,  4.7422e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.8213e-01, -3.5791e-01, -7.1449e-03,  ...,  4.6948e-01,\n",
       "            8.3691e-01, -6.8994e-01],\n",
       "          [-5.2441e-01,  3.1934e-01,  4.0869e-01,  ...,  9.4727e-01,\n",
       "            7.3486e-02, -2.7539e-01],\n",
       "          [-5.5566e-01,  9.1748e-01, -1.1444e-05,  ..., -7.2168e-01,\n",
       "            3.8672e-01, -4.1626e-01],\n",
       "          ...,\n",
       "          [-8.8965e-01,  3.4521e-01, -6.3843e-02,  ..., -6.5381e-01,\n",
       "            8.6621e-01,  3.2837e-02],\n",
       "          [-1.7764e+00, -9.5703e-02, -2.9144e-02,  ..., -9.1602e-01,\n",
       "            1.0596e+00,  3.1274e-01],\n",
       "          [-8.0371e-01, -4.2480e-01, -1.2030e-01,  ..., -1.2578e+00,\n",
       "            9.1699e-01, -5.0110e-02]],\n",
       "\n",
       "         [[ 1.6006e+00,  2.1570e-01,  5.3125e-01,  ..., -1.5439e+00,\n",
       "           -1.4258e-01, -5.4785e-01],\n",
       "          [ 8.2324e-01,  1.0205e+00,  1.3789e+00,  ..., -1.8457e+00,\n",
       "           -7.8076e-01, -4.6338e-01],\n",
       "          [-3.9771e-01,  5.3564e-01,  1.0039e+00,  ..., -1.6895e+00,\n",
       "           -1.3269e-01, -8.6426e-01],\n",
       "          ...,\n",
       "          [ 2.0957e+00, -3.0005e-01,  1.0195e+00,  ..., -1.3008e+00,\n",
       "           -2.6025e-01, -1.9297e+00],\n",
       "          [ 2.2559e-01, -1.4082e+00,  1.5127e+00,  ..., -1.1631e+00,\n",
       "           -1.6431e-01, -1.9629e+00],\n",
       "          [-1.8926e+00, -1.3672e+00,  1.4609e+00,  ..., -1.1660e+00,\n",
       "           -1.2042e-01, -1.9609e+00]],\n",
       "\n",
       "         [[ 1.2266e+00,  1.9604e-01,  2.3254e-01,  ...,  7.3291e-01,\n",
       "           -2.1484e+00,  1.2148e+01],\n",
       "          [ 1.0840e+00,  9.9121e-02,  5.8887e-01,  ...,  5.0439e-01,\n",
       "           -2.0781e+00,  1.4305e+01],\n",
       "          [ 6.0059e-01,  1.6724e-01,  5.7520e-01,  ...,  3.4009e-01,\n",
       "           -1.5586e+00,  1.4156e+01],\n",
       "          ...,\n",
       "          [ 2.2109e+00, -4.1821e-01,  7.9688e-01,  ..., -5.4810e-02,\n",
       "           -3.7832e+00,  1.7250e+01],\n",
       "          [ 1.1426e+00, -1.8335e-01,  8.4570e-01,  ...,  1.4746e-01,\n",
       "           -3.7832e+00,  1.7266e+01],\n",
       "          [-9.1895e-01,  1.4343e-01,  3.1543e-01,  ..., -1.0706e-01,\n",
       "           -3.5098e+00,  1.7547e+01]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[[-0.3445, -0.1282, -0.2312,  ..., -0.1921,  0.3506, -0.0053],\n",
       "          [-0.3569, -0.3931,  0.2008,  ..., -0.0106,  0.2054, -0.1731],\n",
       "          [-0.4280, -0.3682, -0.3821,  ..., -0.1515,  0.0735, -0.4631],\n",
       "          ...,\n",
       "          [-0.3875,  0.2228, -0.3523,  ..., -0.0459,  0.2686,  0.1080],\n",
       "          [-0.4883,  0.0261, -0.2773,  ...,  0.1179,  0.1506,  0.2625],\n",
       "          [-0.4409,  0.0780, -0.3354,  ..., -0.0436,  0.3047,  0.1019]],\n",
       "\n",
       "         [[ 0.7500,  0.3286, -0.4885,  ..., -0.6968, -0.3711, -0.0973],\n",
       "          [ 0.9951,  0.1426, -0.6191,  ..., -0.6689, -0.2776,  0.0606],\n",
       "          [ 0.6323,  0.6294, -0.4197,  ..., -0.4895,  0.0532, -0.1814],\n",
       "          ...,\n",
       "          [ 0.7573, -0.0863,  0.0160,  ..., -0.8091,  0.5737, -0.4600],\n",
       "          [ 0.8027, -0.0759, -0.0903,  ..., -0.8828,  0.6001, -0.4822],\n",
       "          [ 0.7485, -0.0630, -0.1257,  ..., -0.7793,  0.5210, -0.6260]],\n",
       "\n",
       "         [[ 0.3152,  1.0762, -0.2527,  ...,  0.4980, -0.6196, -0.8735],\n",
       "          [ 0.1318,  0.9297,  0.0379,  ...,  0.6216, -0.5742, -0.9722],\n",
       "          [ 0.2266,  1.1758, -0.0945,  ...,  0.6572, -0.7310, -0.9590],\n",
       "          ...,\n",
       "          [ 0.3247,  1.4453, -0.3452,  ...,  0.7690, -0.3821, -0.2927],\n",
       "          [ 0.2510,  1.6797, -0.2944,  ...,  0.7100, -0.5273, -0.4658],\n",
       "          [ 0.0113,  1.4336, -0.3459,  ...,  0.7383, -0.5498, -0.3428]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0994, -0.2303, -0.0867,  ..., -0.0882, -0.0938,  0.4592],\n",
       "          [ 0.0475, -0.1708,  0.0827,  ...,  0.7090,  0.0929,  0.6958],\n",
       "          [ 0.3159, -0.1425, -0.1857,  ...,  0.1288,  0.1927, -0.1249],\n",
       "          ...,\n",
       "          [ 0.1750, -0.8081, -0.5010,  ..., -0.5117,  0.7188,  0.2120],\n",
       "          [ 0.1221, -0.9795, -0.6621,  ..., -0.1221,  0.6011,  0.2041],\n",
       "          [ 0.2001, -0.8975, -0.4294,  ..., -0.4138,  0.9131, -0.0177]],\n",
       "\n",
       "         [[ 0.1519, -0.5464, -0.3464,  ..., -0.8071,  0.7891,  0.4910],\n",
       "          [-0.0248, -0.4812, -0.0770,  ..., -0.4990,  0.6602,  0.5298],\n",
       "          [ 0.6226, -0.4849, -0.0721,  ..., -0.7056,  0.5044,  0.3164],\n",
       "          ...,\n",
       "          [ 1.0273,  0.0098,  0.0623,  ..., -0.4719,  0.8257,  0.5571],\n",
       "          [ 0.8940, -0.0864,  0.2588,  ..., -0.2678,  0.7363,  0.7944],\n",
       "          [ 1.0293,  0.1271,  0.0978,  ..., -0.4651,  0.6875,  0.3352]],\n",
       "\n",
       "         [[ 0.9907,  1.2002, -0.3591,  ...,  0.2834,  0.3069,  0.1349],\n",
       "          [ 1.0381,  0.9512, -0.3647,  ...,  0.3787, -0.0423,  0.0401],\n",
       "          [ 1.0908,  0.9077, -0.2766,  ...,  0.1736,  0.5254, -0.1065],\n",
       "          ...,\n",
       "          [ 0.4951,  0.8770, -0.8442,  ..., -0.5752,  0.0577,  0.2170],\n",
       "          [ 0.6196,  0.7344, -0.8413,  ..., -0.6230,  0.2036,  0.0624],\n",
       "          [ 0.6377,  0.8428, -0.7788,  ..., -0.6431,  0.2534, -0.1066]]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<TransposeBackward0>)), (tensor([[[[ 1.6211e-01, -4.9976e-01,  1.7761e-02,  ..., -1.8242e+00,\n",
       "           -2.6738e+00,  1.0850e+00],\n",
       "          [ 7.6172e-01, -1.0537e+00, -1.5723e-01,  ..., -1.7314e+00,\n",
       "           -2.7207e+00,  9.1357e-01],\n",
       "          [ 3.3789e-01, -7.1289e-01, -5.2930e-01,  ..., -1.8086e+00,\n",
       "           -1.9316e+00,  1.0938e+00],\n",
       "          ...,\n",
       "          [ 1.0039e+00,  9.1943e-01, -2.9761e-01,  ..., -2.5391e+00,\n",
       "           -3.4746e+00,  6.1768e-01],\n",
       "          [ 5.4785e-01,  9.9072e-01, -3.0249e-01,  ..., -2.4238e+00,\n",
       "           -3.6055e+00,  4.0625e-01],\n",
       "          [-6.0010e-01,  2.9053e-01, -1.5649e-01,  ..., -2.3555e+00,\n",
       "           -3.0430e+00,  4.3677e-01]],\n",
       "\n",
       "         [[-6.3574e-01, -4.5215e-01, -2.7783e-01,  ...,  2.0156e+00,\n",
       "           -3.9795e-01,  1.0781e+00],\n",
       "          [-2.3767e-01, -6.5820e-01,  5.7495e-02,  ...,  1.6445e+00,\n",
       "           -2.3511e-01,  9.0723e-01],\n",
       "          [ 3.4448e-01, -2.7002e-01,  2.0813e-01,  ...,  2.4277e+00,\n",
       "            2.9810e-01,  7.3486e-01],\n",
       "          ...,\n",
       "          [-4.2969e-01,  5.8594e-01,  7.8613e-02,  ...,  1.7725e+00,\n",
       "           -9.6729e-01,  6.3232e-01],\n",
       "          [-1.5576e-01,  2.6245e-01,  2.5366e-01,  ...,  1.4424e+00,\n",
       "           -9.8486e-01,  6.1328e-01],\n",
       "          [ 2.2461e-01, -3.6621e-01,  2.7979e-01,  ...,  1.8926e+00,\n",
       "           -9.0674e-01,  7.2900e-01]],\n",
       "\n",
       "         [[-1.2900e+00,  4.7363e-01,  5.3741e-02,  ..., -1.6680e+00,\n",
       "           -5.1697e-02,  1.3857e+00],\n",
       "          [-3.2495e-01,  1.7100e+00, -6.4209e-02,  ..., -1.4512e+00,\n",
       "           -3.6426e-01,  1.7363e+00],\n",
       "          [ 1.1074e+00,  1.3398e+00, -3.2031e-01,  ..., -2.0293e+00,\n",
       "           -8.7463e-02,  1.2119e+00],\n",
       "          ...,\n",
       "          [-6.4893e-01,  1.9678e-01,  8.0078e-01,  ..., -3.0879e+00,\n",
       "           -1.2422e+00,  2.3965e+00],\n",
       "          [ 1.5098e+00, -6.7480e-01,  6.1133e-01,  ..., -2.8340e+00,\n",
       "           -1.0400e+00,  2.2402e+00],\n",
       "          [ 2.3496e+00, -8.4473e-01,  2.0764e-01,  ..., -3.0625e+00,\n",
       "           -1.2461e+00,  2.4492e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.2571e-01,  6.7472e-04,  1.0541e-01,  ...,  7.7148e+00,\n",
       "           -6.2561e-02,  2.4622e-01],\n",
       "          [-3.9917e-01, -4.9976e-01, -1.8143e-02,  ...,  9.2812e+00,\n",
       "           -5.9814e-01, -9.6008e-02],\n",
       "          [-4.4751e-01, -4.2920e-01,  5.1367e-01,  ...,  8.4844e+00,\n",
       "            1.7639e-01, -1.2550e-03],\n",
       "          ...,\n",
       "          [ 1.9653e-01,  4.1504e-01, -5.8301e-01,  ...,  9.5312e+00,\n",
       "           -8.5596e-01, -1.1426e+00],\n",
       "          [-2.7588e-01,  6.5430e-01, -3.3545e-01,  ...,  9.9844e+00,\n",
       "           -9.8389e-01, -9.6436e-01],\n",
       "          [-4.8242e-01,  1.8677e-01,  4.9316e-02,  ...,  9.4141e+00,\n",
       "           -4.9805e-01, -8.8477e-01]],\n",
       "\n",
       "         [[-1.3291e+00,  5.6055e-01,  3.1281e-03,  ...,  9.6484e-01,\n",
       "           -2.0166e-01,  1.1367e+00],\n",
       "          [ 2.6587e-01,  5.3564e-01,  1.3271e+00,  ...,  8.2959e-01,\n",
       "           -3.4229e-01,  1.2002e+00],\n",
       "          [ 3.1494e-01, -4.3750e-01,  1.5996e+00,  ...,  8.3789e-01,\n",
       "           -2.7710e-01,  9.3018e-01],\n",
       "          ...,\n",
       "          [-6.2842e-01, -1.3403e-01,  1.8809e+00,  ...,  1.9277e+00,\n",
       "           -9.4824e-01,  1.5977e+00],\n",
       "          [ 1.3867e+00,  5.9277e-01,  2.3594e+00,  ...,  1.9268e+00,\n",
       "           -1.0293e+00,  1.5117e+00],\n",
       "          [ 1.8330e+00,  6.8555e-01,  7.1533e-01,  ...,  1.9570e+00,\n",
       "           -1.0127e+00,  1.5635e+00]],\n",
       "\n",
       "         [[ 1.8340e+00, -6.2744e-01,  1.4258e+00,  ...,  2.4121e+00,\n",
       "            4.9414e-01,  7.8613e-01],\n",
       "          [ 5.2637e-01, -1.3145e+00,  3.0127e-01,  ...,  2.6289e+00,\n",
       "            1.0703e+00,  1.0928e+00],\n",
       "          [-1.3086e+00, -2.2876e-01, -7.2412e-01,  ...,  2.1113e+00,\n",
       "            7.4805e-01,  3.0688e-01],\n",
       "          ...,\n",
       "          [ 1.0000e+00,  1.3027e+00,  1.1279e+00,  ...,  3.3691e+00,\n",
       "            1.5063e-01,  2.3262e+00],\n",
       "          [-1.5410e+00,  8.8867e-01, -3.9429e-01,  ...,  3.2109e+00,\n",
       "            3.1274e-01,  2.0723e+00],\n",
       "          [-2.6523e+00, -3.6450e-01, -1.5820e+00,  ...,  3.2949e+00,\n",
       "            1.6687e-01,  2.1543e+00]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[[ 0.0322, -0.4978,  0.2135,  ...,  0.0287, -0.4785, -0.6284],\n",
       "          [ 0.0171, -0.5225, -0.2292,  ..., -0.0298, -0.1636, -0.4688],\n",
       "          [ 0.1818, -0.3647,  0.3455,  ..., -0.5352, -0.2532, -0.2603],\n",
       "          ...,\n",
       "          [-0.0334, -0.4412,  0.2935,  ..., -0.4260, -0.1633,  0.0420],\n",
       "          [-0.1509, -0.3030,  0.0660,  ..., -0.4905,  0.0141, -0.0230],\n",
       "          [-0.0899, -0.1960,  0.2473,  ..., -0.5879,  0.0448, -0.0420]],\n",
       "\n",
       "         [[ 0.2786,  0.2837,  0.2466,  ...,  0.3335, -0.8887,  1.3223],\n",
       "          [ 0.5073,  0.1940,  0.2240,  ...,  0.2595, -0.8296,  1.2900],\n",
       "          [ 0.4746,  0.1049,  0.4050,  ...,  0.1942, -0.5039,  1.6924],\n",
       "          ...,\n",
       "          [ 0.0710,  0.2202,  0.2820,  ...,  0.0243, -0.9951,  1.3145],\n",
       "          [ 0.2170,  0.2676,  0.2732,  ..., -0.0160, -0.9038,  1.3408],\n",
       "          [ 0.1776,  0.2717,  0.3252,  ..., -0.0267, -0.7563,  1.4209]],\n",
       "\n",
       "         [[ 1.5010, -0.6377, -0.7754,  ..., -0.9727,  0.2593,  0.3323],\n",
       "          [ 1.0967, -0.2266, -0.5215,  ..., -0.9365,  0.6401,  0.0950],\n",
       "          [ 1.0605, -0.3420, -0.5332,  ..., -0.8804,  0.4807, -0.1296],\n",
       "          ...,\n",
       "          [ 0.9482,  0.0197,  0.6553,  ..., -0.5254,  0.4209, -0.4724],\n",
       "          [ 0.9873,  0.1182,  0.4626,  ..., -0.4697,  0.2949, -0.3245],\n",
       "          [ 0.8271,  0.0800,  0.4004,  ..., -0.5767,  0.4146, -0.5488]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0172, -0.0540, -0.1658,  ...,  0.3806, -0.0095,  0.3718],\n",
       "          [ 0.4382, -0.0146,  0.0438,  ...,  0.5225,  0.4250,  0.6528],\n",
       "          [-0.0695,  0.0122, -0.3962,  ...,  0.4822,  0.0414,  0.4573],\n",
       "          ...,\n",
       "          [ 0.0044,  0.6787, -0.3025,  ..., -0.1156,  0.2463,  0.4636],\n",
       "          [ 0.1146,  0.5361, -0.3867,  ..., -0.0071,  0.2271,  0.5254],\n",
       "          [-0.1263,  0.5571, -0.4893,  ..., -0.1685,  0.2383,  0.3157]],\n",
       "\n",
       "         [[-1.2021,  0.2632, -0.3079,  ...,  0.4060,  0.0274, -0.2294],\n",
       "          [-1.2432,  0.2898,  0.0636,  ...,  0.4668,  0.4143, -0.4187],\n",
       "          [-2.0430,  0.6348, -0.3833,  ...,  0.3135, -0.2861, -0.3662],\n",
       "          ...,\n",
       "          [-0.5171, -0.8862, -0.4314,  ...,  0.2681, -0.0098, -0.7158],\n",
       "          [-0.7627, -0.8931, -0.4189,  ..., -0.0225,  0.2411, -0.4380],\n",
       "          [-0.7681, -0.6387, -0.3796,  ...,  0.1506, -0.0591, -0.5542]],\n",
       "\n",
       "         [[-1.1611, -0.4050,  0.3965,  ..., -0.7529, -0.1418,  1.8135],\n",
       "          [-0.8950, -0.4600,  0.2708,  ..., -1.1152, -0.1094,  1.9492],\n",
       "          [-0.8867, -0.1304,  0.3491,  ..., -1.0293, -0.0032,  1.8320],\n",
       "          ...,\n",
       "          [-0.6997,  0.2323,  0.3245,  ..., -0.8179, -0.2351,  1.6904],\n",
       "          [-0.6221,  0.1887,  0.4592,  ..., -0.7842, -0.2183,  1.7783],\n",
       "          [-0.5063,  0.2412,  0.3284,  ..., -1.0215, -0.1893,  1.5820]]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<TransposeBackward0>)), (tensor([[[[ 2.2229e-01,  2.8857e-01, -4.2505e-01,  ...,  1.8692e-02,\n",
       "           -1.9121e+00,  2.2314e-01],\n",
       "          [-4.6875e-01,  2.0850e-01, -1.2097e-01,  ..., -5.3271e-01,\n",
       "           -1.7598e+00,  4.7046e-01],\n",
       "          [-3.2861e-01, -1.5778e-02,  3.2935e-01,  ..., -7.5000e-01,\n",
       "           -1.7861e+00, -1.4587e-01],\n",
       "          ...,\n",
       "          [-7.6416e-02,  1.0693e-01, -5.7910e-01,  ..., -3.2202e-01,\n",
       "           -7.9688e-01, -1.4526e-01],\n",
       "          [-3.1323e-01,  5.1953e-01,  5.9387e-02,  ..., -3.6304e-01,\n",
       "           -9.7754e-01, -1.3147e-01],\n",
       "          [-2.0593e-01,  4.8779e-01,  3.2129e-01,  ..., -6.5625e-01,\n",
       "           -9.1064e-01, -1.4661e-01]],\n",
       "\n",
       "         [[ 3.7891e-01, -1.6492e-01, -8.0371e-01,  ..., -4.2500e+00,\n",
       "           -2.9663e-01, -2.9512e+00],\n",
       "          [ 5.1270e-01, -5.7666e-01, -2.2705e-01,  ..., -4.7578e+00,\n",
       "           -3.9966e-01, -3.7344e+00],\n",
       "          [-4.8145e-01, -7.0898e-01,  2.4219e-01,  ..., -4.4297e+00,\n",
       "            3.8135e-01, -3.0469e+00],\n",
       "          ...,\n",
       "          [ 1.6956e-01,  4.7144e-01, -3.1128e-01,  ..., -4.6211e+00,\n",
       "           -4.0137e-01, -4.8711e+00],\n",
       "          [ 2.1191e-01,  5.1074e-01,  4.9414e-01,  ..., -4.9766e+00,\n",
       "           -5.2979e-01, -4.7852e+00],\n",
       "          [-1.0352e-01,  3.6133e-01,  1.0742e+00,  ..., -4.6328e+00,\n",
       "           -1.5161e-01, -4.6562e+00]],\n",
       "\n",
       "         [[ 6.0693e-01,  3.7354e-02, -1.6992e-01,  ..., -2.0020e+00,\n",
       "           -6.8438e+00,  4.8047e+00],\n",
       "          [-3.6011e-01,  3.9062e-02,  2.7954e-02,  ..., -2.7227e+00,\n",
       "           -8.3672e+00,  6.2422e+00],\n",
       "          [-6.7871e-01,  1.5747e-02,  2.4158e-01,  ..., -2.2246e+00,\n",
       "           -7.6719e+00,  5.7734e+00],\n",
       "          ...,\n",
       "          [-1.1597e-02, -6.2256e-03, -1.2622e-01,  ..., -2.4629e+00,\n",
       "           -8.1875e+00,  6.3750e+00],\n",
       "          [-3.9893e-01, -1.4050e-01,  3.6719e-01,  ..., -2.3770e+00,\n",
       "           -8.4453e+00,  6.5391e+00],\n",
       "          [-4.4067e-01, -3.5156e-01,  5.8789e-01,  ..., -2.6738e+00,\n",
       "           -8.0312e+00,  6.5781e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.2842e+00, -3.4644e-01,  5.7220e-02,  ...,  1.9727e+00,\n",
       "            1.8018e+00, -7.9285e-02],\n",
       "          [ 8.4717e-01,  3.4180e-03,  2.6978e-02,  ...,  1.4541e+00,\n",
       "            1.1943e+00, -3.4547e-04],\n",
       "          [-2.5977e-01, -1.1743e-01,  6.8542e-02,  ...,  1.3721e+00,\n",
       "            8.7305e-01, -1.7627e-01],\n",
       "          ...,\n",
       "          [ 1.3633e+00,  5.7275e-01,  6.4893e-01,  ...,  3.2793e+00,\n",
       "            2.3340e+00, -5.3619e-02],\n",
       "          [ 2.6123e-02, -1.3123e-01,  4.2773e-01,  ...,  3.4336e+00,\n",
       "            2.1230e+00,  1.0429e-02],\n",
       "          [-1.2412e+00, -5.8496e-01,  3.1592e-01,  ...,  3.1797e+00,\n",
       "            1.6934e+00,  6.7688e-02]],\n",
       "\n",
       "         [[ 1.1621e+00, -8.8867e-01, -9.5312e-01,  ..., -6.0234e+00,\n",
       "            1.7490e+00, -1.5059e+00],\n",
       "          [ 6.4502e-01,  2.0508e-02, -1.3281e-01,  ..., -7.5547e+00,\n",
       "            2.0781e+00, -2.0859e+00],\n",
       "          [-6.6553e-01,  9.6777e-01,  5.2588e-01,  ..., -7.2070e+00,\n",
       "            1.7422e+00, -2.2676e+00],\n",
       "          ...,\n",
       "          [ 1.5752e+00, -9.8145e-02, -3.0103e-01,  ..., -7.0039e+00,\n",
       "            2.4922e+00, -2.4824e+00],\n",
       "          [-4.1553e-01, -9.6729e-01,  6.9189e-01,  ..., -7.1562e+00,\n",
       "            2.6465e+00, -2.4316e+00],\n",
       "          [-2.0703e+00, -1.0176e+00,  1.0391e+00,  ..., -7.2344e+00,\n",
       "            2.7109e+00, -2.5762e+00]],\n",
       "\n",
       "         [[ 1.4199e+00,  4.2285e-01,  5.9906e-02,  ..., -1.8193e+00,\n",
       "           -4.9658e-01,  8.7344e+00],\n",
       "          [ 1.2764e+00,  2.6660e-01, -2.4854e-01,  ..., -2.6758e+00,\n",
       "           -1.9531e-01,  9.0781e+00],\n",
       "          [-6.6016e-01,  3.8647e-01,  2.9517e-01,  ..., -2.4707e+00,\n",
       "           -1.3340e+00,  8.4453e+00],\n",
       "          ...,\n",
       "          [ 7.2119e-01, -2.6270e-01, -3.9746e-01,  ..., -1.3555e+00,\n",
       "           -1.2812e+00,  8.5234e+00],\n",
       "          [ 1.6309e-01,  1.5015e-01, -2.2998e-01,  ..., -1.7168e+00,\n",
       "           -1.2969e+00,  8.6953e+00],\n",
       "          [-8.7207e-01,  4.5703e-01,  4.7876e-01,  ..., -1.4775e+00,\n",
       "           -1.5537e+00,  8.6875e+00]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[[-0.1565, -1.0713, -0.2152,  ...,  0.4006, -0.7642, -0.3428],\n",
       "          [-0.1375, -0.8359, -0.2549,  ...,  0.6621, -0.7930, -0.6147],\n",
       "          [-0.2629, -1.0898,  0.1837,  ...,  0.1989, -0.5957, -0.4861],\n",
       "          ...,\n",
       "          [-0.8755, -1.3271,  0.7427,  ...,  0.2050, -0.6519, -0.2900],\n",
       "          [-0.8301, -1.2559,  0.7773,  ...,  0.1414, -0.5645, -0.2167],\n",
       "          [-0.7148, -1.1211,  0.7632,  ...,  0.0648, -0.5391, -0.2983]],\n",
       "\n",
       "         [[-0.1313,  0.3347, -0.5698,  ..., -0.7529, -1.0166,  0.9688],\n",
       "          [-0.0412,  0.6470, -0.4531,  ..., -0.6997, -1.3770,  0.8013],\n",
       "          [ 0.0969,  0.1371, -0.6743,  ..., -0.7959, -0.9692,  0.4380],\n",
       "          ...,\n",
       "          [ 0.1221, -1.1250, -1.6748,  ..., -0.4573, -0.6934,  0.4802],\n",
       "          [-0.0417, -1.0039, -1.6123,  ..., -0.6284, -0.7158,  0.5322],\n",
       "          [ 0.0467, -1.2393, -1.6992,  ..., -0.5029, -0.6548,  0.4717]],\n",
       "\n",
       "         [[-0.9175,  0.4641, -0.0430,  ...,  0.4780, -0.8950,  0.0254],\n",
       "          [-1.1963,  0.3169,  0.1602,  ...,  0.7271, -0.9727, -0.3652],\n",
       "          [-0.7695,  0.3142, -0.4150,  ...,  0.5288, -1.1719,  0.0272],\n",
       "          ...,\n",
       "          [-0.5161,  0.4558, -0.0884,  ...,  0.1144, -0.8823, -0.0959],\n",
       "          [-0.5952,  0.1898,  0.0289,  ...,  0.1622, -0.8687, -0.1021],\n",
       "          [-0.5034,  0.2771, -0.2297,  ...,  0.0686, -0.9009,  0.1163]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.4507, -0.6104, -0.3408,  ..., -0.5811,  0.1359, -0.3508],\n",
       "          [ 0.4612, -0.6992, -0.6489,  ..., -0.2957,  0.0439, -0.3506],\n",
       "          [ 0.4834, -0.7910, -0.4546,  ..., -0.2495,  0.4585, -0.3374],\n",
       "          ...,\n",
       "          [ 0.5322, -0.3823, -0.6675,  ..., -0.6724,  0.0047, -0.9395],\n",
       "          [ 0.4509, -0.5117, -0.6484,  ..., -0.7061, -0.0848, -0.8208],\n",
       "          [ 0.5361, -0.4753, -0.6836,  ..., -0.5894, -0.0327, -0.9585]],\n",
       "\n",
       "         [[ 1.1641,  0.7642,  0.3975,  ...,  0.2048, -0.8687,  0.4912],\n",
       "          [ 1.2900,  0.8491, -0.1068,  ...,  0.3110, -1.2607,  0.5273],\n",
       "          [ 1.4385,  0.5474, -1.1416,  ...,  0.2563, -0.8560,  0.4429],\n",
       "          ...,\n",
       "          [ 1.2236,  0.7739, -0.0957,  ...,  0.1119, -1.2148,  0.2627],\n",
       "          [ 1.2031,  0.8389, -0.2490,  ...,  0.0173, -1.2461,  0.2490],\n",
       "          [ 1.1406,  0.6812, -0.4026,  ...,  0.1381, -1.3262,  0.2469]],\n",
       "\n",
       "         [[ 0.1331,  0.1736, -0.4268,  ..., -0.8145,  0.2842, -0.7236],\n",
       "          [ 0.3020,  0.4253, -0.1206,  ..., -0.8887,  0.2291, -0.8804],\n",
       "          [-0.0454,  0.4519, -0.2742,  ..., -0.3987,  0.5503, -0.6274],\n",
       "          ...,\n",
       "          [ 0.0709, -0.0820, -0.1964,  ..., -0.7935, -0.4446, -0.0842],\n",
       "          [ 0.2102,  0.0654, -0.0895,  ..., -0.7095, -0.4778, -0.1783],\n",
       "          [ 0.0349, -0.0246,  0.0634,  ..., -0.6831, -0.3152, -0.1044]]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<TransposeBackward0>)), (tensor([[[[-0.3811,  0.6118,  0.2942,  ..., -0.5630, -1.0156, -1.5322],\n",
       "          [-0.4004,  0.3823, -0.0583,  ..., -0.4939, -0.9141, -1.7432],\n",
       "          [-0.0831, -0.0820, -0.6763,  ..., -0.1251, -1.9102, -2.0586],\n",
       "          ...,\n",
       "          [-0.7314, -0.4209,  0.0710,  ...,  0.8569, -0.1736, -1.2061],\n",
       "          [-0.3003,  0.1748,  0.4746,  ...,  0.6875, -0.2883, -1.2080],\n",
       "          [ 0.5088,  0.4883,  0.3477,  ...,  0.6782, -0.2107, -1.1289]],\n",
       "\n",
       "         [[ 0.5342, -0.2922,  0.8506,  ..., -0.5312,  0.5088, -0.2322],\n",
       "          [ 0.3989, -0.3354,  0.5635,  ..., -0.9839,  0.8672, -0.0092],\n",
       "          [-0.1414, -0.6123,  0.2583,  ..., -1.3115,  0.8662, -0.2632],\n",
       "          ...,\n",
       "          [ 0.6162,  0.1985,  0.3633,  ..., -0.1853,  1.1992,  0.8511],\n",
       "          [ 0.3330,  0.3589, -0.2993,  ..., -0.2205,  1.1396,  0.9780],\n",
       "          [-0.5679,  0.1827, -0.7627,  ..., -0.5610,  1.3691,  1.0586]],\n",
       "\n",
       "         [[ 1.1045,  0.3870,  0.4290,  ...,  0.9360, -0.3364, -1.9707],\n",
       "          [ 2.3789,  0.7920,  1.2109,  ..., -0.1963, -1.0439, -2.1074],\n",
       "          [ 0.9243,  0.6133,  1.1963,  ...,  0.5728, -0.6284, -1.6494],\n",
       "          ...,\n",
       "          [ 3.0234, -0.9326,  1.2324,  ...,  1.0146, -0.6284, -3.4531],\n",
       "          [ 1.2598, -1.2148,  1.1875,  ...,  0.7373, -0.8008, -3.2734],\n",
       "          [-1.8184, -0.5410,  0.6465,  ...,  0.7778, -0.5527, -3.2109]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.1074,  0.5601,  0.5010,  ...,  1.3408,  0.3416,  0.4006],\n",
       "          [-0.2949,  0.3647,  1.3154,  ...,  1.2002,  0.2786,  0.4646],\n",
       "          [-1.3730, -0.2515,  1.0059,  ...,  1.3613,  0.3933,  0.4497],\n",
       "          ...,\n",
       "          [-1.1172, -0.6963,  0.3640,  ...,  2.3164,  1.4473,  0.0376],\n",
       "          [-2.0312, -0.3115,  0.4067,  ...,  2.1680,  1.5020,  0.3491],\n",
       "          [-1.0625,  0.2427, -0.0277,  ...,  2.3945,  1.1797,  0.1825]],\n",
       "\n",
       "         [[ 0.3423, -0.0660,  0.2322,  ...,  0.4590, -1.4961,  0.2351],\n",
       "          [-0.6147,  0.0044,  0.2369,  ...,  0.5405, -1.5400, -0.1931],\n",
       "          [-1.0332,  0.4111,  0.4670,  ...,  0.2242, -1.6846,  0.1771],\n",
       "          ...,\n",
       "          [-0.8857,  0.2378,  0.5977,  ...,  0.1133, -0.9028, -0.1621],\n",
       "          [-1.5547, -0.4556,  0.8135,  ...,  0.2283, -0.9390, -0.1202],\n",
       "          [-0.7593, -0.7510,  0.6064,  ...,  0.2710, -0.7217, -0.0631]],\n",
       "\n",
       "         [[ 1.3428, -0.4761,  0.2844,  ...,  0.8149, -0.9331,  0.3086],\n",
       "          [ 1.1875,  0.3462, -0.8877,  ...,  0.4155, -0.3916, -0.0231],\n",
       "          [ 0.0527,  1.5479, -1.3506,  ...,  1.3896, -0.2769,  0.0814],\n",
       "          ...,\n",
       "          [ 2.2266, -1.0049, -1.7520,  ...,  1.1953, -1.6377, -0.2957],\n",
       "          [ 1.3652, -2.3359, -2.4453,  ...,  0.9731, -1.4443, -0.1553],\n",
       "          [-1.1680, -1.9795, -1.9102,  ...,  1.2529, -1.4023, -0.3718]]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>), tensor([[[[-1.2622e-01,  8.0127e-01,  8.0371e-01,  ..., -6.4941e-01,\n",
       "            8.1641e-01, -5.4541e-01],\n",
       "          [-2.5610e-01,  1.1602e+00,  9.3066e-01,  ..., -1.0068e+00,\n",
       "            4.5532e-01, -1.0723e+00],\n",
       "          [-4.5166e-01,  9.3848e-01,  8.7744e-01,  ..., -1.2109e+00,\n",
       "            2.0410e-01, -7.1289e-01],\n",
       "          ...,\n",
       "          [-5.0049e-01,  5.8868e-02,  1.1396e+00,  ..., -9.0625e-01,\n",
       "           -8.5498e-01, -4.0503e-01],\n",
       "          [-8.3496e-01,  1.2250e-01,  1.0107e+00,  ..., -1.0723e+00,\n",
       "           -9.2529e-01, -4.5483e-01],\n",
       "          [-7.0605e-01, -5.0995e-02,  9.0723e-01,  ..., -1.0791e+00,\n",
       "           -8.4717e-01, -3.6157e-01]],\n",
       "\n",
       "         [[ 5.9229e-01,  5.4688e-01, -5.8594e-02,  ...,  4.0283e-01,\n",
       "           -1.2854e-01, -3.7476e-02],\n",
       "          [ 5.5469e-01,  6.4307e-01,  7.9575e-03,  ...,  6.5869e-01,\n",
       "           -4.6509e-01,  9.8206e-02],\n",
       "          [ 4.6533e-01,  6.6797e-01,  1.6016e-01,  ...,  2.8296e-01,\n",
       "           -2.4194e-01,  1.1560e-01],\n",
       "          ...,\n",
       "          [ 3.4570e-01,  4.3774e-01,  2.7969e-02,  ..., -3.2666e-01,\n",
       "           -4.0924e-02, -2.5513e-01],\n",
       "          [ 2.8052e-01,  4.6826e-01, -2.1460e-01,  ..., -1.5967e-01,\n",
       "           -1.7810e-01, -2.3169e-01],\n",
       "          [ 3.2764e-01,  4.1870e-01,  2.7817e-02,  ..., -1.7432e-01,\n",
       "           -1.0083e-01, -2.1448e-01]],\n",
       "\n",
       "         [[-1.7188e-01, -4.8779e-01, -3.5571e-01,  ..., -4.3701e-01,\n",
       "           -3.3228e-01,  3.8477e-01],\n",
       "          [-3.0835e-01, -4.8950e-01, -3.2202e-01,  ..., -2.9248e-01,\n",
       "           -3.7817e-01,  3.4546e-01],\n",
       "          [-1.7383e-01, -9.1919e-02, -3.7329e-01,  ..., -3.3618e-01,\n",
       "           -2.9492e-01,  4.1016e-02],\n",
       "          ...,\n",
       "          [ 3.4595e-01, -6.7529e-01, -7.4316e-01,  ..., -5.4834e-01,\n",
       "           -3.0200e-01,  3.1445e-01],\n",
       "          [ 2.5610e-01, -6.5918e-01, -6.8359e-01,  ..., -7.2168e-01,\n",
       "           -3.0347e-01,  3.0908e-01],\n",
       "          [ 2.2620e-01, -6.7188e-01, -8.0078e-01,  ..., -5.9668e-01,\n",
       "           -2.6221e-01,  3.1665e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 9.4482e-01, -1.1279e+00, -9.4421e-02,  ..., -1.0088e+00,\n",
       "           -1.8982e-01, -5.0732e-01],\n",
       "          [ 1.0186e+00, -8.4131e-01,  8.9905e-02,  ..., -1.0664e+00,\n",
       "           -2.8589e-01, -5.8838e-01],\n",
       "          [ 1.1113e+00, -9.1260e-01, -7.9834e-02,  ..., -9.7070e-01,\n",
       "            1.1743e-01, -3.6890e-01],\n",
       "          ...,\n",
       "          [ 7.8857e-01, -3.9722e-01, -2.6880e-01,  ..., -7.5439e-01,\n",
       "           -3.8940e-01, -8.1250e-01],\n",
       "          [ 8.4570e-01, -5.9521e-01, -2.1130e-01,  ..., -5.6982e-01,\n",
       "           -4.3799e-01, -7.6367e-01],\n",
       "          [ 7.6465e-01, -3.9209e-01, -2.9639e-01,  ..., -7.0703e-01,\n",
       "           -2.0947e-01, -7.9248e-01]],\n",
       "\n",
       "         [[ 9.3164e-01, -3.0493e-01, -1.8176e-01,  ...,  5.9473e-01,\n",
       "           -5.8057e-01, -8.7451e-01],\n",
       "          [ 1.4375e+00, -2.2290e-01, -1.3159e-01,  ...,  5.0195e-01,\n",
       "           -4.8413e-01, -1.0947e+00],\n",
       "          [ 9.7656e-01, -3.7622e-01, -4.4336e-01,  ...,  7.0898e-01,\n",
       "           -4.7534e-01, -1.0938e+00],\n",
       "          ...,\n",
       "          [ 9.3848e-01, -8.3350e-01, -2.4719e-01,  ...,  8.3740e-01,\n",
       "           -7.0557e-01, -6.0791e-01],\n",
       "          [ 1.0312e+00, -7.1680e-01, -3.5303e-01,  ...,  7.8320e-01,\n",
       "           -5.6543e-01, -7.6514e-01],\n",
       "          [ 8.5547e-01, -7.5928e-01, -2.7490e-01,  ...,  8.7109e-01,\n",
       "           -6.9434e-01, -8.0078e-01]],\n",
       "\n",
       "         [[ 5.9700e-04,  9.4727e-01, -9.1943e-01,  ...,  1.1406e+00,\n",
       "           -3.4912e-02,  1.7603e-01],\n",
       "          [ 4.7070e-01,  7.5000e-01, -7.8516e-01,  ...,  6.5723e-01,\n",
       "            5.3760e-01, -6.0669e-02],\n",
       "          [ 2.7328e-02,  8.7939e-01, -1.2998e+00,  ...,  1.0801e+00,\n",
       "            4.8248e-02,  3.0298e-01],\n",
       "          ...,\n",
       "          [ 7.3914e-02,  3.8770e-01, -6.8359e-01,  ...,  1.2549e+00,\n",
       "            2.7124e-01,  2.4268e-01],\n",
       "          [ 1.8250e-01,  3.1641e-01, -6.1768e-01,  ...,  1.3369e+00,\n",
       "            3.4619e-01,  3.2544e-01],\n",
       "          [-1.2561e-01,  5.3320e-01, -7.7539e-01,  ...,  1.2686e+00,\n",
       "            3.8770e-01,  2.3889e-01]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[ 6.0352e-01,  9.6240e-01, -5.9619e-01,  ...,  1.6846e+00,\n",
       "            1.4365e+00,  5.3711e-01],\n",
       "          [ 5.8154e-01,  3.8110e-01, -7.6074e-01,  ...,  1.9834e+00,\n",
       "            1.5645e+00,  8.5693e-01],\n",
       "          [ 7.2510e-02, -6.2305e-01, -1.2188e+00,  ...,  2.1660e+00,\n",
       "            1.0840e+00,  1.0576e+00],\n",
       "          ...,\n",
       "          [ 8.6133e-01, -7.3828e-01, -7.9785e-01,  ...,  1.6572e+00,\n",
       "            1.8359e+00,  6.3379e-01],\n",
       "          [ 8.6914e-02, -2.8687e-02, -7.0020e-01,  ...,  1.7979e+00,\n",
       "            1.7646e+00,  7.3340e-01],\n",
       "          [-6.9775e-01,  7.7881e-01, -5.7471e-01,  ...,  1.8389e+00,\n",
       "            1.6416e+00,  6.1719e-01]],\n",
       "\n",
       "         [[ 9.0479e-01,  4.1040e-01,  1.5596e+00,  ..., -1.3535e+00,\n",
       "            3.5962e-01,  7.1680e-01],\n",
       "          [-2.7881e-01, -2.9395e-01,  1.8926e+00,  ..., -2.0254e+00,\n",
       "           -2.2595e-01,  7.0410e-01],\n",
       "          [-1.3604e+00, -1.4668e+00,  9.1553e-01,  ..., -1.9053e+00,\n",
       "            3.0542e-01,  9.3115e-01],\n",
       "          ...,\n",
       "          [ 5.1611e-01, -1.5869e-01,  9.9512e-01,  ..., -1.4863e+00,\n",
       "            2.8125e-01,  9.1895e-01],\n",
       "          [-7.0703e-01,  1.1143e+00,  8.3887e-01,  ..., -1.5586e+00,\n",
       "            1.1139e-01,  6.5820e-01],\n",
       "          [-1.4512e+00,  1.7246e+00,  1.1670e-01,  ..., -1.5820e+00,\n",
       "            2.8906e-01,  8.5986e-01]],\n",
       "\n",
       "         [[-2.2876e-01,  2.8955e-01, -9.9072e-01,  ..., -9.7168e-01,\n",
       "           -1.7695e+00,  2.9062e+00],\n",
       "          [-3.5889e-01,  2.7344e-01, -6.8115e-01,  ..., -1.3760e+00,\n",
       "           -1.3369e+00,  3.4023e+00],\n",
       "          [-2.3083e-01,  3.8208e-02,  8.5754e-02,  ..., -1.7080e+00,\n",
       "           -1.7969e+00,  3.1094e+00],\n",
       "          ...,\n",
       "          [-8.6377e-01,  5.9174e-02, -5.1367e-01,  ..., -1.0400e+00,\n",
       "           -1.5684e+00,  3.4062e+00],\n",
       "          [-5.7031e-01, -6.6345e-02, -1.8530e-01,  ..., -1.2197e+00,\n",
       "           -1.5566e+00,  3.4414e+00],\n",
       "          [ 2.7832e-01, -5.8075e-02,  2.5830e-01,  ..., -1.2930e+00,\n",
       "           -1.4551e+00,  3.3438e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.4902e-02, -2.8247e-01, -6.6162e-02,  ..., -7.9053e-01,\n",
       "            4.3286e-01, -2.2812e+00],\n",
       "          [ 1.5491e-01, -7.9688e-01, -3.9990e-01,  ..., -7.8320e-01,\n",
       "            3.7183e-01, -3.0664e+00],\n",
       "          [ 5.7910e-01, -8.7988e-01, -4.2773e-01,  ..., -6.7188e-01,\n",
       "            5.5615e-01, -2.7168e+00],\n",
       "          ...,\n",
       "          [ 5.1270e-03, -4.0698e-01,  4.6899e-01,  ..., -1.3936e+00,\n",
       "            9.5020e-01, -2.2617e+00],\n",
       "          [ 8.6133e-01, -6.6064e-01, -5.9753e-02,  ..., -1.3965e+00,\n",
       "            8.5840e-01, -2.4785e+00],\n",
       "          [ 8.9648e-01, -2.7271e-01, -3.5693e-01,  ..., -1.4688e+00,\n",
       "            8.8232e-01, -2.4082e+00]],\n",
       "\n",
       "         [[ 1.1145e-01,  8.1250e-01,  4.8608e-01,  ...,  4.8438e+00,\n",
       "            2.1855e+00,  1.1865e+00],\n",
       "          [ 1.0986e-01,  7.4707e-01,  6.6992e-01,  ...,  4.6172e+00,\n",
       "            1.9268e+00,  1.0938e+00],\n",
       "          [-2.1582e-01, -1.3672e-01,  8.0273e-01,  ...,  4.2578e+00,\n",
       "            1.9512e+00,  1.6680e+00],\n",
       "          ...,\n",
       "          [ 1.0449e-01, -4.9316e-01,  4.9902e-01,  ...,  5.2305e+00,\n",
       "            2.0332e+00,  2.4048e-01],\n",
       "          [-9.8022e-02,  2.5293e-01,  6.2256e-03,  ...,  4.9336e+00,\n",
       "            1.9395e+00,  1.5771e-01],\n",
       "          [-3.0151e-01,  8.5547e-01, -2.1680e-01,  ...,  4.9570e+00,\n",
       "            1.7646e+00,  4.0112e-01]],\n",
       "\n",
       "         [[ 3.0933e-01,  1.6821e-01, -4.0955e-02,  ..., -3.8354e-01,\n",
       "            9.5557e-01,  9.7119e-01],\n",
       "          [-1.3965e+00, -3.5156e-02,  4.4019e-01,  ..., -6.2695e-01,\n",
       "            8.1787e-01,  6.7041e-01],\n",
       "          [-1.7637e+00, -8.3252e-01,  1.4736e+00,  ..., -4.7461e-01,\n",
       "            1.5420e+00,  1.0273e+00],\n",
       "          ...,\n",
       "          [-1.7686e+00, -2.7295e-01,  2.4512e-01,  ..., -3.5229e-01,\n",
       "            1.2461e+00,  8.9453e-01],\n",
       "          [-2.1367e+00,  8.7500e-01,  1.0557e+00,  ..., -3.8745e-01,\n",
       "            1.0762e+00,  8.6035e-01],\n",
       "          [-5.3076e-01,  1.4434e+00,  1.3145e+00,  ..., -2.4829e-01,\n",
       "            1.3750e+00,  8.1494e-01]]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddBackward0>), tensor([[[[-0.0845,  0.4600,  0.5996,  ...,  0.2454,  0.2216, -0.3579],\n",
       "          [ 0.0114,  0.3904,  0.3469,  ...,  0.1448,  0.1439, -0.4604],\n",
       "          [-0.2108,  0.1604,  0.4951,  ...,  0.0852,  0.3425, -0.2090],\n",
       "          ...,\n",
       "          [ 0.0571,  0.4026,  0.3779,  ...,  0.3064,  0.1134, -0.2358],\n",
       "          [ 0.1455,  0.2189,  0.3250,  ...,  0.2292,  0.2061, -0.1813],\n",
       "          [-0.0181,  0.3748,  0.2417,  ...,  0.2440,  0.1786, -0.1832]],\n",
       "\n",
       "         [[ 0.1157, -0.5522,  0.4746,  ...,  0.0708,  0.4541, -0.2996],\n",
       "          [ 0.0812, -0.5317,  0.5923,  ...,  0.3101,  0.3711, -0.0527],\n",
       "          [ 0.3303, -0.5542,  0.6670,  ...,  0.1246,  0.3684, -0.1748],\n",
       "          ...,\n",
       "          [ 0.1729, -0.3889,  1.0156,  ...,  0.6577,  0.0922, -0.2283],\n",
       "          [ 0.1697, -0.4832,  0.9912,  ...,  0.6631,  0.1813, -0.2340],\n",
       "          [ 0.2306, -0.4578,  1.1104,  ...,  0.6284,  0.1127, -0.2028]],\n",
       "\n",
       "         [[ 0.7480,  0.8696,  0.0586,  ..., -0.6938,  0.1819, -0.1632],\n",
       "          [ 0.5410,  0.8662, -0.1482,  ..., -0.7422,  0.2457,  0.0478],\n",
       "          [ 0.4478,  0.6382, -0.0318,  ..., -0.6172,  0.2203, -0.1500],\n",
       "          ...,\n",
       "          [ 0.2620,  0.4006,  0.1682,  ..., -0.7666, -0.5464,  0.3369],\n",
       "          [ 0.2688,  0.3137,  0.0953,  ..., -0.8320, -0.4944,  0.3962],\n",
       "          [ 0.2595,  0.3650,  0.1107,  ..., -0.8477, -0.4883,  0.2529]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1550, -0.0904,  0.7197,  ..., -0.4050, -0.1193,  0.0330],\n",
       "          [-0.1015, -0.0658,  0.3269,  ..., -0.5713, -0.1136,  0.2561],\n",
       "          [-0.0989,  0.0369,  0.9058,  ..., -0.2686, -0.2324,  0.2556],\n",
       "          ...,\n",
       "          [-0.1987, -0.6084,  0.8618,  ..., -0.2300, -0.0654,  0.2583],\n",
       "          [-0.0934, -0.7524,  0.6504,  ..., -0.2815, -0.0970,  0.1606],\n",
       "          [-0.1326, -0.6636,  1.1230,  ..., -0.1085, -0.1517,  0.2617]],\n",
       "\n",
       "         [[-0.2549,  0.2827, -0.0160,  ..., -0.3628,  0.0231,  0.5996],\n",
       "          [-0.2568,  0.2786, -0.1785,  ..., -0.4800,  0.0038,  0.3420],\n",
       "          [ 0.3020,  0.2156,  0.1897,  ..., -0.9702, -0.2568,  0.2881],\n",
       "          ...,\n",
       "          [-0.0859,  0.6582, -0.2559,  ...,  0.2690,  0.5938,  0.5293],\n",
       "          [-0.0784,  0.6367, -0.5166,  ...,  0.2874,  0.6968,  0.6567],\n",
       "          [ 0.1605,  0.6172, -0.3613,  ...,  0.1002,  0.5459,  0.5776]],\n",
       "\n",
       "         [[-0.5054, -0.0119,  0.2539,  ...,  0.0646, -0.2546,  0.0898],\n",
       "          [-0.3267,  0.0831,  0.1122,  ..., -0.1355, -0.1912,  0.1953],\n",
       "          [-0.1893,  0.0211,  0.1917,  ..., -0.0628,  0.0287,  0.2014],\n",
       "          ...,\n",
       "          [-0.8120, -0.3760,  0.2390,  ...,  0.0111,  0.1995,  0.3345],\n",
       "          [-0.8481, -0.3857,  0.3103,  ..., -0.0274,  0.1323,  0.3347],\n",
       "          [-0.8320, -0.3391,  0.3040,  ..., -0.0206,  0.1615,  0.2969]]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<TransposeBackward0>))), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layer_prob_increase_storage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m plt\u001b[38;5;241m.\u001b[39mbar(\u001b[38;5;28mrange\u001b[39m(n_layers), \u001b[43mlayer_prob_increase_storage\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskyblue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLog probability increase of different layers\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mattention \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLayers\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'layer_prob_increase_storage' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "visualize the top layers, and show the top heads\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(range(n_layers), layer_prob_increase_storage.detach().cpu().numpy(), color='skyblue')\n",
    "plt.title('Log probability increase of different layers\\'attention ')\n",
    "plt.xlabel('Layers')\n",
    "plt.ylabel('Log probability increase')\n",
    "plt.grid(True)\n",
    "plt.savefig('./visualization/prob_increase/prob_increase_layers_attn_O_'+task_name+spec_str+'.jpg')\n",
    "topk_layer_vals, topk_layer_inds  = torch.topk(layer_prob_increase_storage.view(-1), k=n_top_layers, largest=True)\n",
    "topk_vals, topk_inds  = torch.topk(head_prob_increase_storage.view(-1), k=n_top_heads, largest=True)\n",
    "topk_ids_result=torch.zeros(n_top_heads, 2)\n",
    "l_ids=topk_inds//n_layers\n",
    "h_ids=topk_inds%n_heads\n",
    "topk_ids_result[:,0]=l_ids\n",
    "topk_ids_result[:,1]=h_ids\n",
    "print(topk_ids_result) # [n_top_heads, 2]. [:,0]: layer ids; [:,1]: head ids.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "compute the attention score of the last token's Q and the label's K.\n",
    "'''\n",
    "\n",
    "\n",
    "tks=get_tokens(model, tokenizer, prompt, device).squeeze(0)\n",
    "if target_word=='bar':\n",
    "    contras_word='foo'\n",
    "    target_label_poss=torch.where(tks==2594)[0]\n",
    "    contras_label_poss=torch.where(tks==7953)[0]\n",
    "elif target_word=='foo':\n",
    "    contras_word='bar'\n",
    "    target_label_poss=torch.where(tks==7953)[0]\n",
    "    contras_label_poss=torch.where(tks==2594)[0]\n",
    "elif target_word=='positive':\n",
    "    contras_word='negative'\n",
    "    target_label_poss=torch.where(tks==6374)[0]\n",
    "    contras_label_poss=torch.where(tks==8178)[0]\n",
    "elif target_word=='negative':\n",
    "    contras_word='positive'\n",
    "    target_label_poss=torch.where(tks==8178)[0]\n",
    "    contras_label_poss=torch.where(tks==6374)[0]\n",
    "\n",
    "\n",
    "if ana_module=='by_head':\n",
    "    num_top_heads_to_avgs=[1,3,5,8,10,15,20]\n",
    "    if attn_obj=='labels':\n",
    "        for num_top_heads_to_avg in num_top_heads_to_avgs:\n",
    "        # if samples are seperated by '\\n' and every label words are one-token, then the label tokens' positions are \n",
    "        # the ones before the '\\n' token (13).\n",
    "            label_poss=torch.where(tks==13)[0]-1\n",
    "            avg_atten_scores=torch.zeros(num_top_heads_to_avg, len(label_poss)+1).to(device)\n",
    "            for i in range(num_top_heads_to_avg):\n",
    "                top_head_l, top_head_h=topk_ids_result[i,0].int(), topk_ids_result[i,1].int()\n",
    "                last_token_Q=rep[attn_Q[top_head_l]].output.squeeze(0)[-1, top_head_h*head_dim:(top_head_h+1)*head_dim] # print(last_token_Q.shape) = [128], i.e., [head_dim]\n",
    "                last_token_K=rep[attn_K[top_head_l]].output.squeeze(0)[-1, top_head_h*head_dim:(top_head_h+1)*head_dim]\n",
    "                label_K=rep[attn_K[top_head_l]].output.squeeze(0)[label_poss, top_head_h*head_dim:(top_head_h+1)*head_dim] # label_K.shape = torch.Size([4, 128]), i.e., [num_examples, head_dim]\n",
    "                attn_scores=torch.cat((torch.mm(label_K, last_token_Q.view(-1,1)), torch.dot(last_token_Q, last_token_K).view(1,1)), dim=0).view(len(label_poss)+1)\n",
    "                \n",
    "                avg_atten_scores[i]=attn_scores\n",
    "            avg_atten_scores=avg_atten_scores.mean(dim=0)\n",
    "            #print(avg_atten_scores)\n",
    "\n",
    "            if task_name=='antonym':\n",
    "                context_label_words = ['easy', 'right', 'bad', 'lose', 'safe', 'last tk']\n",
    "            elif 'sentiment' in task_name:\n",
    "                context_label_words = ['t1', 'z1', 't2', 'z2', 't3', 'z3', 'last tk']\n",
    "            elif 'classification' in task_name:\n",
    "                context_label_words = ['foo1', 'foo2', 'foo3', 'bar1', 'bar2', 'bar3', 'last tk']\n",
    "\n",
    "            plt.bar(context_label_words, avg_atten_scores.detach().cpu().numpy(), color='skyblue')\n",
    "            plt.title(f'Avg attn scores of top-{num_top_heads_to_avg} heads, Last token Attention')\n",
    "            plt.xlabel('Context labels')\n",
    "            plt.ylabel('Q*K')\n",
    "            plt.grid(True)\n",
    "            plt.savefig(f'./visualization/attn/by_head/last_tk_labels_attn_score/avg_top_{num_top_heads_to_avg}_heads_attn_score_'+task_name+spec_str+'.jpg')\n",
    "            plt.show()\n",
    "\n",
    "    elif attn_obj=='all':\n",
    "        for num_top_heads_to_avg in num_top_heads_to_avgs:\n",
    "            avg_atten_scores=torch.zeros(num_top_heads_to_avg, len(tks)).to(device)\n",
    "            for i in range(num_top_heads_to_avg):\n",
    "                top_head_l, top_head_h=topk_ids_result[i,0].int(), topk_ids_result[i,1].int()\n",
    "                last_token_Q=rep[attn_Q[top_head_l]].output.squeeze(0)[-1, top_head_h*head_dim:(top_head_h+1)*head_dim] # print(last_token_Q.shape) = [128], i.e., [head_dim]\n",
    "                context_K=rep[attn_K[top_head_l]].output.squeeze(0)[:, top_head_h*head_dim:(top_head_h+1)*head_dim] # label_K.shape = torch.Size([4, 128]), i.e., [num_examples, head_dim]\n",
    "                #print(torch.dot(last_token_Q, last_token_K).view(1,1))\n",
    "                attn_scores=torch.mm(context_K, last_token_Q.view(-1,1)).view(len(tks))\n",
    "                avg_atten_scores[i]=attn_scores\n",
    "\n",
    "            avg_atten_scores=avg_atten_scores.mean(dim=0)\n",
    "            #print(avg_atten_scores)\n",
    "\n",
    "\n",
    "            context_label_words = get_tk_words(tokenizer, tks)\n",
    "            print(context_label_words)\n",
    "            plt.figure(figsize=(25, 7))\n",
    "            plt.bar(range(len(context_label_words)), avg_atten_scores.detach().cpu().numpy(), tick_label=context_label_words, color='skyblue')\n",
    "            plt.title(f'Avg attn scores of top-{num_top_heads_to_avg} heads, Last token Attention')\n",
    "            plt.xlabel('Input prompt')\n",
    "            plt.ylabel('Q*K')\n",
    "            plt.grid(True)\n",
    "            plt.savefig(f'./visualization/attn/by_head/last_tk_all_attn_score/avg_top_{num_top_heads_to_avg}_heads_attn_score_'+task_name+spec_str+'.jpg')\n",
    "            plt.show()\n",
    "elif ana_module=='all_heads':\n",
    "    num_top_layers_to_avgs=[1,3,5]\n",
    "    label_poss=torch.where(tks==13)[0]-1\n",
    "    for num_top_layers_to_avg in num_top_layers_to_avgs:\n",
    "        avg_atten_scores=torch.zeros(num_top_layers_to_avg, len(label_poss)+1).to(device)\n",
    "        if attn_obj=='labels':\n",
    "            label_poss=torch.where(tks==13)[0]-1\n",
    "            avg_atten_scores=torch.zeros(num_top_layers_to_avg, len(label_poss)+1).to(device)\n",
    "        elif attn_obj=='all':\n",
    "            avg_atten_scores=torch.zeros(num_top_layers_to_avg, len(tks)).to(device)\n",
    "        for l in range(num_top_layers_to_avg):\n",
    "            last_token_Q=rep[attn_Q[topk_layer_inds[l]]].output.squeeze(0)[-1, :] # print(last_token_Q.shape) = [128], i.e., [head_dim]\n",
    "            if attn_obj=='labels':\n",
    "                label_K=rep[attn_K[topk_layer_inds[l]]].output.squeeze(0)[label_poss, :]\n",
    "                last_token_K=rep[attn_K[topk_layer_inds[l]]].output.squeeze(0)[-1, :]\n",
    "                attn_scores=torch.cat((torch.mm(label_K, last_token_Q.view(-1,1)), torch.dot(last_token_Q, last_token_K).view(1,1)), dim=0).view(len(label_poss)+1)\n",
    "                if task_name=='antonym':\n",
    "                    context_label_words = ['easy', 'right', 'bad', 'lose', 'safe', 'last tk']\n",
    "                elif 'sentiment' in task_name:\n",
    "                    context_label_words = ['t1', 'z1', 't2', 'z2', 't3', 'z3', 'last tk']\n",
    "            elif attn_obj=='all':\n",
    "                context_K=rep[attn_K[topk_layer_inds[l]]].output.squeeze(0)[:, :] # label_K.shape = torch.Size([4, 128]), i.e., [num_examples, head_dim]\n",
    "                attn_scores=torch.mm(context_K, last_token_Q.view(-1,1)).view(len(tks))\n",
    "                context_label_words = get_tk_words(tokenizer, tks)\n",
    "            avg_atten_scores[l]=attn_scores\n",
    "        avg_atten_scores=avg_atten_scores.mean(dim=0)\n",
    "        \n",
    "        plt.figure(figsize=(25, 7))\n",
    "        plt.bar(range(len(context_label_words)), avg_atten_scores.detach().cpu().numpy(), tick_label=context_label_words, color='skyblue')\n",
    "        plt.title(f'Avg attn scores of top-{num_top_layers_to_avg} layers, Last token Attention')\n",
    "        plt.xlabel('Input prompt')\n",
    "        plt.ylabel('Q*K')\n",
    "        plt.grid(True)\n",
    "        plt.savefig('./visualization/attn/all_heads/last_tk_'+attn_obj+f'_attn_score/avg_top_{num_top_layers_to_avg}_heads_attn_score_'+task_name+spec_str+'.jpg')\n",
    "        plt.show()\n",
    "elif ana_module=='spec_head':\n",
    "    attn_score_storage=torch.zeros(n_heads, n_layers).to(device)\n",
    "    for l in range(n_layers):\n",
    "        for h in range(n_heads):\n",
    "            last_token_Q=rep[attn_Q[l]].output.squeeze(0)[-1, h*head_dim:(h+1)*head_dim]\n",
    "            target_label_K=rep[attn_K[l]].output.squeeze(0)[target_label_poss, h*head_dim:(h+1)*head_dim] \n",
    "            contras_label_K=rep[attn_K[l]].output.squeeze(0)[contras_label_poss, h*head_dim:(h+1)*head_dim]\n",
    "            target_attn_score=torch.mm(target_label_K, last_token_Q.view(-1, 1)).view(target_label_poss.shape[0]).sum(0)\n",
    "            contras_attn_score=torch.mm(contras_label_K, last_token_Q.view(-1, 1)).view(contras_label_poss.shape[0]).sum(0)\n",
    "            attn_score=torch.softmax(torch.cat((target_attn_score.unsqueeze(0), contras_attn_score.unsqueeze(0))),0)\n",
    "            \n",
    "            attn_score_storage[l,h]=attn_score[0] - attn_score[1]\n",
    "            \n",
    "            '''label_words=[target_word, contras_word]\n",
    "            values=attn_score.detach().cpu().numpy()\n",
    "            bar=plt.bar(label_words, values, color='skyblue')\n",
    "            plt.bar_label(bar, label_type='edge')'''\n",
    "    \n",
    "    plt.imshow(attn_score_storage.detach().cpu().numpy(), cmap='hot', interpolation='nearest')\n",
    "    plt.colorbar()  \n",
    "    plt.xlabel('heads')\n",
    "    plt.ylabel('layers')\n",
    "    plt.title('Attention on target label - contras label (after sftmx)')\n",
    "    plt.savefig(f'./visualization/attn/by_head/traverse/target-contras_attn_'+task_name+spec_str+'.jpg')\n",
    "    plt.savefig(f'./visualization/attn/by_head/traverse/target-contras_attn_'+task_name+spec_str+'.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "elif ana_module=='spec_layer':\n",
    "    l=10\n",
    "    label_poss=torch.where(tks==13)[0]-1\n",
    "    if attn_obj=='labels':\n",
    "        label_poss=torch.where(tks==13)[0]-1\n",
    "    last_token_Q=rep[attn_Q[l]].output.squeeze(0)[-1, :] # print(last_token_Q.shape) = [128], i.e., [head_dim]\n",
    "    if attn_obj=='labels':\n",
    "        label_K=rep[attn_K[l]].output.squeeze(0)[label_poss, :]\n",
    "        last_token_K=rep[attn_K[l]].output.squeeze(0)[-1, :]\n",
    "        attn_scores=torch.cat((torch.mm(label_K, last_token_Q.view(-1,1)), torch.dot(last_token_Q, last_token_K).view(1,1)), dim=0).view(len(label_poss)+1)\n",
    "        if task_name=='antonym':\n",
    "            context_label_words = ['easy', 'right', 'bad', 'lose', 'safe', 'last tk']\n",
    "        elif 'sentiment' in task_name:\n",
    "            context_label_words = ['t1', 'z1', 't2', 'z2', 't3', 'z3', 'last tk']\n",
    "    elif attn_obj=='all':\n",
    "        context_K=rep[attn_K[l]].output.squeeze(0)[:, :] # label_K.shape = torch.Size([4, 128]), i.e., [num_examples, head_dim]\n",
    "        attn_scores=torch.mm(context_K, last_token_Q.view(-1,1)).view(len(tks))\n",
    "        context_label_words = get_tk_words(tokenizer, tks)\n",
    "\n",
    "    attn_score_sftmx=torch.softmax(attn_scores, dim=0)\n",
    "    if attn_obj=='all':\n",
    "        spec_str+='_all'\n",
    "    elif attn_obj=='labels':\n",
    "        spec_str+='_labels'\n",
    "    \n",
    "    plt.figure(figsize=(25, 7))\n",
    "    plt.bar(range(len(context_label_words)), attn_score_sftmx.detach().cpu().numpy(), tick_label=context_label_words, color='skyblue')\n",
    "    plt.title(f'Attn scores of layer {l}, Last token Attention')\n",
    "    plt.xlabel('Input prompt')\n",
    "    plt.ylabel('Q*K sftmx')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('./visualization/attn/all_heads/last_tk_'+attn_obj+f'_attn_score/attn_score_layer_{l}_'+task_name+spec_str+'.jpg')\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
